---
title: "<center> <h1>***EEG ANALYSIS***</h1> </center>"
author: '[Antonio Schettino](https://osf.io/zbv65/ "Antonio Schettino")'
date: '`r Sys.Date()`'
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

In this project we will investigate the electrophysiological correlates of the combined processing of basic visual properties (i.e., size and contrast) and the emotional content of simple words. 

```{r setup_environment, echo = FALSE, warning = FALSE, message = FALSE}
# set RNG seed
set.seed(36) # 'e castagnelle

# use pacman to install and load relevant packages
library(pacman)
pacman::p_load(
  "rmarkdown",
  "knitr",
  "here",
  "tidyverse",
  "Rmisc",
  "viridis",
  "eegUtils",
  "yarrr",
  "BayesFactor"
)

# setup report output
options(
  width = 120, # change output width (for better printing)
  scipen = 999, # disable scientific notation (default: scipen=0)
  digits = 3 # constrain output to 3 decimals
)

# chunk options
opts_chunk$set(
  echo = FALSE, # display the output but not the R code
  warning = FALSE, # no package warnings
  message = FALSE, # no package messages
  fig.width = 10, # figure width
  fig.height = 6 # figure height
)

# custom color palettes for graphs (from "viridis")
# viridis(5, alpha = 1, begin = 0, end = 1, option = "D")
waveforms.palette <- c("#440154FF", # purple
                       "#3B528BFF", # blue
                       "#000000", # black
                       "#21908CFF", # aquamarine
                       "#FDE725FF") # yellow

pirateplot.palette <- c("#440154FF", # purple
                        "#440154FF",
                        "#3B528BFF", # blue
                        "#3B528BFF",
                        "#21908CFF", # aquamarine
                        "#21908CFF",
                        "#FDE725FF", # yellow
                        "#FDE725FF")

niter <- 100000 # number of MCMC iterations for calculation of Bayes Factors
scaling.factor <- c(.5, .707, 1) # scaling factors of JZS prior: narrow, medium, wide
```

# GRAPHS

```{r graph_grandavg, fig.cap = "Butterfly plot"}
grand.avg.localizer <- read_csv(here::here("/EEG/main/main_grandEEG_localizer.csv")) %>%
  select(-condition) %>% # drop condition column
  gather( # convert to long format
    key = timepoint, # name of new column
    value = amplitude, # value of new column
    -c(participant, electrode) # keep participants and electrodes as columns
  )

# summarized data from each time point (& within-subject 95% CI)
grand.avg.localizer.pointsummary <- grand.avg.localizer %>%
  summarySEwithin(
    data = .,
    measurevar = "amplitude",
    withinvars = c("electrode", "timepoint"),
    idvar = "participant"
  ) %>%
  mutate(
    timepoint = as.numeric(levels(timepoint))[timepoint] # re-convert time points to numeric
  )

# plot
ggplot(
  grand.avg.localizer.pointsummary,
  aes(
    x = timepoint,
    y = amplitude,
    group = electrode
  )
) +
  geom_vline( # vertical reference line
    xintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_hline( # horizontal reference line
    yintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_vline( # vertical reference lines
    xintercept = seq(-200, 1000, 100),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_hline( # horizontal reference lines
    yintercept = seq(-3, 3, 1),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_line( # one line per electrode
    size = 1.2,
    color = "#494847",
    alpha = .8
  ) +
  geom_ribbon( # 95% CI
    aes(
      ymin = amplitude - ci,
      ymax = amplitude + ci
    ),
    linetype = "dotted",
    size = .1,
    alpha = .1,
    show.legend = FALSE
  ) +
  labs(
    title = "", # title & axes labels
    x = "time (ms)",
    y = expression(paste("amplitude (", mu, "V)"))
  ) +
  scale_x_continuous(breaks = seq(-200, 1000, 100)) + # x-axis: tick marks
  scale_y_reverse(
    breaks = seq(-3, 3, 1), # y-axis: tick marks
    limits = c(3, -3)
  ) +
  theme_classic(base_size = 20) +
  theme(
    plot.title = element_text(
      size = 28,
      hjust = .5,
      face = "bold"
    ),
    legend.position = "none"
  )
```

Prepare data for:

* topographies
* waveforms
* (RDI plots) pirateplots

```{r data_topo}
# load electrode locations
electrodeLocs <- read_delim(here::here("/EEG/main/elecLocs_BioSemi64.locs"),
  "\t",
  col_names = c("chanNo", "theta", "radius", "electrode"),
  escape_double = FALSE, trim_ws = TRUE
) %>%
  mutate(
    radianTheta = pi / 180 * theta, # convert theta values from degrees to radians
    # Cartesian coordinates
    x = radius * sin(radianTheta),
    y = radius * cos(radianTheta)
  ) %>%
  .[order(.$electrode, decreasing = FALSE), ] # re-order according to topos

# load topographies
topos <- read_csv(paste0(getwd(), "/EEG/main/main_topoEEG.csv")) %>%
  group_by(bin, electrode) %>% # average across participants
  dplyr::summarize(
    P1 = mean(P1),
    N1 = mean(N1),
    EPN = mean(EPN),
    LPP = mean(LPP)
  ) 
```

```{r data_grandavg_comps}
grand.avg.comps <- read_csv(here::here("/EEG/main/main_avgERP.csv")) %>%
  gather( # convert to long format
    key = timepoint,
    value = amplitude,
    -c(participant, elec_cluster, condition)
  ) %>%
  # rename levels
  mutate(
    condition = revalue(
      as.factor(condition),
      c(
        "all" = "localizer",
        "negative" = "negative",
        "negative minus neutral" = "negative minus neutral",
        "negativeLargeBright" = "negative large bright",
        "negativeLargeDark" = "negative large dark",
        "negativeSmallBright" = "negative small bright",
        "negativeSmallDark" = "negative small dark",
        "neutral" = "neutral",
        "neutralLargeBright" = "neutral large bright",
        "neutralLargeDark" = "neutral large dark",
        "neutralSmallBright" = "neutral small bright",
        "neutralSmallDark" = "neutral small dark"
      )
    ),
    # variable with main effect of size
    size = revalue(
      condition,
      c(
        "localizer" = NA,
        "negative" = NA,
        "negative minus neutral" = NA,
        "negative large bright" = "large",
        "negative large dark" = "large",
        "negative small bright" = "small",
        "negative small dark" = "small",
        "neutral" = NA,
        "neutral large bright" = "large",
        "neutral large dark" = "large",
        "neutral small bright" = "small",
        "neutral small dark" = "small"
      )
    ),
    # variable with main effect of contrast
    cont = revalue(
      condition,
      c(
        "localizer" = NA,
        "negative" = NA,
        "negative minus neutral" = NA,
        "negative large bright" = "bright",
        "negative large dark" = "dark",
        "negative small bright" = "bright",
        "negative small dark" = "dark",
        "neutral" = NA,
        "neutral large bright" = "bright",
        "neutral large dark" = "dark",
        "neutral small bright" = "bright",
        "neutral small dark" = "dark"
      )
    ),
    # variable with main effect of emotion
    emo = revalue(
      condition,
      c(
        "localizer" = NA,
        "negative" = NA,
        "negative minus neutral" = NA,
        "negative large bright" = "negative",
        "negative large dark" = "negative",
        "negative small bright" = "negative",
        "negative small dark" = "negative",
        "neutral" = NA,
        "neutral large bright" = "neutral",
        "neutral large dark" = "neutral",
        "neutral small bright" = "neutral",
        "neutral small dark" = "neutral"
      )
    )
  )
```

```{r data_trial_comps}
# trial-wise words presented to each participant
data.EEG.trialWords <- read_csv(here::here("/EEG/main/main_words.csv"))

data.EEG.trial <- read_csv(here::here("/EEG/main/main_trialEEG.csv")) %>%
  mutate(
    condition = factor(condition),
    # variable with main effect of size
    size = revalue(
      condition, c(
        "1" = "large",
        "2" = "small",
        "3" = "large",
        "4" = "small",
        "5" = "large",
        "6" = "small",
        "7" = "large",
        "8" = "small"
      )
    ),
    # variable with main effect of contrast
    cont = revalue(
      condition, c(
        "1" = "dark",
        "2" = "dark",
        "3" = "bright",
        "4" = "bright",
        "5" = "dark",
        "6" = "dark",
        "7" = "bright",
        "8" = "bright"
      )
    ),
    # variable with main effect of emotion
    emo = revalue(
      condition, c(
        "1" = "negative",
        "2" = "negative",
        "3" = "negative",
        "4" = "negative",
        "5" = "neutral",
        "6" = "neutral",
        "7" = "neutral",
        "8" = "neutral"
      )
    ),
    cond = paste(emo, size, cont, sep = " ") # rename condition levels
  ) %>%
  bind_cols(., data.EEG.trialWords) %>% # include words in EEG data frame
  dplyr::select( # re-order variables
    participant,
    word,
    size,
    cont,
    emo,
    cond,
    P1,
    N1,
    EPN,
    LPP
  )
```

### P1

```{r P1_topo}
topos %>%
  dplyr::filter(bin == "localizer") %>%
  dplyr::select(electrode, amplitude = "P1") %>%
  bind_cols(., electrodeLocs) %>% # bind electrode locations and amplitudes (necessary)
  topoplot(.,
           limits = c(-.8, .8), # min-max amplitude
           chanLocs = electrodeLocs,
           method = "Biharmonic",
           palette = "viridis",
           interp_limit = "skirt",
           contour = TRUE,
           chan_marker = "point",
           quantity = "amplitude"
  ) +
  ggtitle("P1 (localizer)") +
  theme(
    plot.title = element_text(size = 28, 
                              hjust = .5, 
                              face = "bold"),
    plot.margin = unit(c(6, 0, 6, 0), "pt") # decrease plot margins
  )
```

Amplitude extracted from the following electrode cluster: P7 P9 PO7 O1 O2 PO8 P8 P10.

```{r P1_waveforms}
# summarized data from each time point, including within-subject 95% CIs
P1.grand.avg.comps.pointsummary <- grand.avg.comps %>% # data frame
  filter( # filter out unused conditions
    elec_cluster == "P1",
    condition != "negative",
    condition != "negative minus neutral",
    condition != "neutral"
  ) %>%
  summarySEwithin(
    data = .,
    measurevar = "amplitude",
    withinvars = c("size", "cont", "emo", "condition", "timepoint"),
    idvar = "participant"
  ) %>%
  unite(visualfeats, c("size", "cont"), sep = " ") %>% # for graph
  mutate(visualfeats = as.factor(ifelse(visualfeats == "NA NA", "localizer", visualfeats)),
    timepoint = as.numeric(levels(timepoint))[timepoint]
  )

# plot waveforms
ggplot(
  data = filter(
    P1.grand.avg.comps.pointsummary,
    condition != "localizer"
  ),
  aes(
    x = timepoint,
    y = amplitude,
    linetype = emo,
    color = visualfeats
  )
) +
  geom_vline( # vertical reference line
    xintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_hline( # horizontal reference line
    yintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_vline( # vertical reference lines
    xintercept = seq(-200, 1000, 50),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_hline( # horizontal reference lines
    yintercept = seq(-3, 3, 1),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_line( # one line per condition
    size = 2.5,
    alpha = .6
  ) +
  geom_line( # thick black line (localizer)
    data = filter(
      P1.grand.avg.comps.pointsummary,
      visualfeats == "localizer"
    ),
    aes(
      x = timepoint,
      y = amplitude
    ),
    size = 5,
    show.legend = FALSE,
    inherit.aes = FALSE
  ) +
  geom_ribbon( # localizer 95% CI
    data = filter(
      P1.grand.avg.comps.pointsummary,
      visualfeats == "localizer"
    ),
    aes(
      ymin = amplitude - ci,
      ymax = amplitude + ci
    ),
    linetype = "dotted",
    size = .1,
    alpha = .3,
    show.legend = FALSE
  ) +
  scale_color_manual(
    breaks = c(
      "localizer", "large bright", # re-order conditions
      "large dark", "small bright", "small dark"
    ),
    values = waveforms.palette
  ) + # line colors
  scale_fill_manual(values = waveforms.palette) + # ribbon colors
  labs(
    title = "P1 (66-148 ms)", # title & axes labels
    x = "time (ms)",
    y = expression(paste("amplitude (", mu, "V)"))
  ) +
  scale_x_continuous(
    breaks = seq(-200, 1000, 50), # x-axis: tick marks
    limits = c(-100, 250)
  ) +
  scale_y_reverse(
    breaks = seq(-3, 3, 1), # y-axis: tick marks
    limits = c(3, -3)
  ) +
  annotate("rect", # highlight time window used for analysis
    xmin = 66,
    xmax = 148,
    ymin = -.5,
    ymax = 3,
    linetype = "solid",
    size = 2,
    color = "#de1d1d",
    alpha = 0
  ) +
  theme_classic(base_size = 20) +
  theme(
    plot.title = element_text(
      size = 28,
      hjust = .5,
      face = "bold"
    ),
    legend.position = "none"
  )
```

```{r P1_pirateplot}
summarySEwithin(data.EEG.trial, 
                "P1", 
                withinvars = c("participant", "size", "cont", "emo"), 
                idvar = "word") %>%
  unite(visualfeats, c("size", "cont"), sep = " ") %>% # for graph
  pirateplot(
    formula = P1 ~ emo + visualfeats, # dependent~independent variables
    data = ., # data frame
    main = "P1", # main title
    xlim = NULL, # x-axis: limits
    xlab = "", # x-axis: label
    ylim = c(-4, 6), # y-axis: limits
    ylab = expression(paste("amplitude (", mu, "V)")), # y-axis: label
    inf.method = "hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
    inf.within = "participant", # ID variable in within-subject designs
    hdi.iter = 5000, # number of iterations for 95% HDI
    cap.beans = TRUE, # bean densities capped at data limits
    point.cex = 1.3, # point size
    pal = pirateplot.palette # color palette
  ) 
```

### N1

```{r N1_topo}
topos %>%
  dplyr::filter(bin == "localizer") %>%
  dplyr::select(electrode, amplitude = "N1") %>%
  bind_cols(., electrodeLocs) %>%
  topoplot(.,
           limits = c(-1, 1),
           chanLocs = electrodeLocs,
           method = "Biharmonic",
           palette = "viridis",
           interp_limit = "skirt",
           contour = TRUE,
           chan_marker = "point",
           quantity = "amplitude"
  ) +
  ggtitle("N1 (localizer)") +
  theme(
    plot.title = element_text(size = 28, 
                              hjust = .5, 
                              face = "bold"),
    plot.margin = unit(c(6, 0, 6, 0), "pt") # decrease plot margins
  )
```

Amplitude extracted from the following electrode cluster: TP7 P7 P9 TP8 P8 P10.

```{r N1_waveforms}
N1.grand.avg.comps.pointsummary <- grand.avg.comps %>%
  filter(
    elec_cluster == "N1",
    condition != "negative",
    condition != "negative minus neutral",
    condition != "neutral"
  ) %>%
  summarySEwithin(
    data = .,
    measurevar = "amplitude",
    withinvars = c("size", "cont", "emo", "condition", "timepoint"),
    idvar = "participant"
  ) %>%
  unite(visualfeats, c("size", "cont"), sep = " ") %>%
  mutate(visualfeats = as.factor(ifelse(visualfeats == "NA NA", "localizer", visualfeats)),
    timepoint = as.numeric(levels(timepoint))[timepoint]
  )

# plot waveforms
ggplot(
  data = filter(
    N1.grand.avg.comps.pointsummary,
    condition != "localizer"
  ),
  aes(
    x = timepoint,
    y = amplitude,
    linetype = emo,
    color = visualfeats
  )
) +
  geom_vline(
    xintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_hline(
    yintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_vline(
    xintercept = seq(-200, 1000, 50),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_hline(
    yintercept = seq(-3, 3, 1),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_line(
    size = 2.5,
    alpha = .6
  ) +
  geom_line(
    data = filter(
      N1.grand.avg.comps.pointsummary,
      visualfeats == "localizer"
    ),
    aes(
      x = timepoint,
      y = amplitude
    ),
    size = 5,
    show.legend = FALSE,
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = filter(
      N1.grand.avg.comps.pointsummary,
      visualfeats == "localizer"
    ),
    aes(
      ymin = amplitude - ci,
      ymax = amplitude + ci
    ),
    linetype = "solid",
    size = .1,
    alpha = .3,
    show.legend = FALSE
  ) +
  scale_color_manual(
    breaks = c(
      "localizer", "large bright",
      "large dark", "small bright", "small dark"
    ),
    values = waveforms.palette
  ) +
  scale_fill_manual(values = waveforms.palette) +
  labs(
    title = "N1 (150-260 ms)",
    x = "time (ms)",
    y = expression(paste("amplitude (", mu, "V)"))
  ) +
  scale_x_continuous(
    breaks = seq(-200, 1000, 50),
    limits = c(-100, 400)
  ) +
  scale_y_reverse(
    breaks = seq(-3, 3, 1),
    limits = c(3, -3)
  ) +
  annotate("rect",
    xmin = 150,
    xmax = 260,
    ymin = -2.5,
    ymax = 1,
    linetype = "solid",
    size = 2,
    color = "#de1d1d",
    alpha = 0
  ) +
  theme_classic(base_size = 20) +
  theme(
    plot.title = element_text(
      size = 28,
      hjust = .5,
      face = "bold"
    ),
    legend.position = "none"
  )
```

```{r N1_pirateplot}
summarySEwithin(data.EEG.trial, 
                "N1", 
                withinvars = c("participant", "size", "cont", "emo"), 
                idvar = "word") %>%
  unite(visualfeats, c("size", "cont"), sep = " ") %>%
  pirateplot(
    formula = N1 ~ emo + visualfeats,
    data = .,
    main = "N1",
    xlim = NULL,
    xlab = "",
    ylim = c(-7, 3),
    ylab = expression(paste("amplitude (", mu, "V)")),
    inf.method = "hdi",
    inf.within = "participant",
    hdi.iter = 5000,
    cap.beans = TRUE,
    point.cex = 1.3, 
    pal = pirateplot.palette
  ) 
```

### EPN

```{r EPN_topo}
topos %>%
  dplyr::filter(bin == "localizer") %>%
  dplyr::select(electrode, amplitude = "EPN") %>%
  bind_cols(., electrodeLocs) %>%
  topoplot(.,
           limits = c(-1, 1), # min-max amplitude
           chanLocs = electrodeLocs,
           method = "Biharmonic",
           palette = "viridis",
           interp_limit = "skirt",
           contour = TRUE,
           chan_marker = "point",
           quantity = "amplitude"
  ) +
  ggtitle("EPN (localizer)") +
  theme(
    plot.title = element_text(size = 28, 
                              hjust = .5, 
                              face = "bold"),
    plot.margin = unit(c(6, 0, 6, 0), "pt") # decrease plot margins
  )
```  

Because the topography differs from the classical EPN topography published in the literature, we identified this component by calculating the difference between negative and neutral conditions (averaged across size and contrast). This is in accordance with our pre-registered protocol.   
   
Note that this was not necessary when identifying the LPP. 

```{r EPN_topo_NegMinNeut}
topos %>%
  dplyr::filter(bin == "NegMinNeut") %>%
  dplyr::select(electrode, amplitude = "EPN") %>%
  bind_cols(., electrodeLocs) %>%
  topoplot(.,
           limits = c(-.25, .25), # min-max amplitude
           chanLocs = electrodeLocs,
           method = "Biharmonic",
           palette = "viridis",
           interp_limit = "skirt",
           contour = TRUE,
           chan_marker = "point",
           quantity = "amplitude"
  ) +
  ggtitle("EPN (negative minus neutral)") +
  theme(
    plot.title = element_text(size = 28, 
                              hjust = .5, 
                              face = "bold"),
    plot.margin = unit(c(6, 0, 6, 0), "pt") # decrease plot margins
  )
```

Amplitude extracted from the following electrode cluster: P7 P9 PO7 PO3 O1 Oz Iz O2 PO4 PO8 P8 P10.

```{r EPN_waveforms}
EPN.grand.avg.comps.pointsummary <- grand.avg.comps %>%
  filter(
    elec_cluster == "EPN",
    condition == "negative minus neutral" |
      condition == "negative large bright" |
      condition == "negative large dark" |
      condition == "negative small bright" |
      condition == "negative small dark" |
      condition == "neutral large bright" |
      condition == "neutral large dark" |
      condition == "neutral small bright" |
      condition == "neutral small dark"
  ) %>%
  summarySEwithin(
    data = .,
    measurevar = "amplitude",
    withinvars = c("size", "cont", "emo", "condition", "timepoint"),
    idvar = "participant"
  ) %>%
  unite(visualfeats, c("size", "cont"), sep = " ") %>% # for graph
  mutate(
    visualfeats = as.factor(ifelse(visualfeats == "NA NA", "negative minus neutral", visualfeats)),
    timepoint = as.numeric(levels(timepoint))[timepoint]
  )

# plot waveforms
ggplot(
  data = EPN.grand.avg.comps.pointsummary,
  aes(
    x = timepoint,
    y = amplitude,
    linetype = emo,
    color = visualfeats
  )
) +
  geom_vline(
    xintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_hline(
    yintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_vline(
    xintercept = seq(-200, 1000, 50),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_hline(
    yintercept = seq(-3, 3, 1),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_line(
    size = 2.5,
    alpha = .6
  ) +
  geom_line(
    data = filter(
      EPN.grand.avg.comps.pointsummary,
      visualfeats == "negative minus neutral"
    ),
    aes(
      x = timepoint,
      y = amplitude
    ),
    size = 5,
    show.legend = FALSE,
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = filter(
      EPN.grand.avg.comps.pointsummary,
      visualfeats == "negative minus neutral"
    ),
    aes(
      ymin = amplitude - ci,
      ymax = amplitude + ci
    ),
    linetype = "dotted",
    size = .1,
    alpha = .3,
    show.legend = FALSE
  ) +
  scale_color_manual(
    breaks = c(
      "negative minus neutral", "large bright",
      "large dark", "small bright", "small dark"
    ),
    values = waveforms.palette
  ) +
  scale_fill_manual(values = waveforms.palette) +
  labs(
    title = "EPN (300-500 ms)",
    x = "time (ms)",
    y = expression(paste("amplitude (", mu, "V)"))
  ) +
  scale_x_continuous(
    breaks = seq(-200, 1000, 50),
    limits = c(-100, 600)
  ) +
  scale_y_reverse(
    breaks = seq(-2, 3, 1),
    limits = c(3, -2)
  ) +
  annotate("rect",
    xmin = 300,
    xmax = 500,
    ymin = -1,
    ymax = 2,
    linetype = "solid",
    size = 2,
    color = "#de1d1d",
    alpha = 0
  ) +
theme_classic(base_size = 20) +
  theme(
    plot.title = element_text(
      size = 28,
      hjust = .5,
      face = "bold"
    ),
    legend.position = "none"
  )
```

```{r EPN_pirateplot}
summarySEwithin(data.EEG.trial, 
                "EPN", 
                withinvars = c("participant", "size", "cont", "emo"), 
                idvar = "word") %>%
  unite(visualfeats, c("size", "cont"), sep = " ") %>%
  pirateplot(
    formula = EPN ~ emo + visualfeats,
    data = .,
    main = "EPN",
    xlim = NULL,
    xlab = "",
    ylim = c(-5, 5),
    ylab = expression(paste("amplitude (", mu, "V)")),
    inf.method = "hdi",
    inf.within = "participant",
    hdi.iter = 5000,
    cap.beans = TRUE,
    point.cex = 1.3, 
    pal = pirateplot.palette
  ) 
```

### LPP

```{r LPP_topo}
topos %>%
  dplyr::filter(bin == "localizer") %>%
  dplyr::select(electrode, amplitude = "LPP") %>%
  bind_cols(., electrodeLocs) %>%
  topoplot(.,
           limits = c(-1, 1), # min-max amplitude
           chanLocs = electrodeLocs,
           method = "Biharmonic",
           palette = "viridis",
           interp_limit = "skirt",
           contour = TRUE,
           chan_marker = "point",
           quantity = "amplitude"
  ) +
  ggtitle("LPP (localizer)") +
  theme(
    plot.title = element_text(size = 28, 
                              hjust = .5, 
                              face = "bold"),
    plot.margin = unit(c(6, 0, 6, 0), "pt") # decrease plot margins
  )
```  

Amplitude extracted from the following electrode cluster: P1 Pz P2 P4 P6 P8 P10 POz PO4 PO8.

```{r LPP_waveforms}
LPP.grand.avg.comps.pointsummary <- grand.avg.comps %>%
    filter(
    elec_cluster == "LPP",
    condition == "localizer" |
      condition == "negative large bright" |
      condition == "negative large dark" |
      condition == "negative small bright" |
      condition == "negative small dark" |
      condition == "neutral large bright" |
      condition == "neutral large dark" |
      condition == "neutral small bright" |
      condition == "neutral small dark"
  ) %>%
  summarySEwithin(
    data = .,
    measurevar = "amplitude",
    withinvars = c("size", "cont", "emo", "condition", "timepoint"),
    idvar = "participant"
  ) %>%
  unite(visualfeats, c("size", "cont"), sep = " ") %>% # for graph
  mutate(
    visualfeats = as.factor(ifelse(visualfeats == "NA NA", "localizer", visualfeats)),
    timepoint = as.numeric(levels(timepoint))[timepoint]
  )

# plot waveforms
ggplot(
  data = LPP.grand.avg.comps.pointsummary,
  aes(
    x = timepoint,
    y = amplitude,
    linetype = emo,
    color = visualfeats
  )
) +
  geom_vline(
    xintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_hline(
    yintercept = 0,
    linetype = "dashed",
    color = "black",
    size = 1.2,
    alpha = .8
  ) +
  geom_vline(
    xintercept = seq(-200, 1000, 50),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_hline(
    yintercept = seq(-3, 3, 1),
    linetype = "dotted",
    color = "#999999",
    size = .8,
    alpha = .5
  ) +
  geom_line(
    size = 2.5,
    alpha = .6
  ) +
  geom_line(
    data = filter(
      LPP.grand.avg.comps.pointsummary,
      visualfeats == "localizer"
    ),
    aes(
      x = timepoint,
      y = amplitude
    ),
    size = 5,
    show.legend = FALSE,
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = filter(
      LPP.grand.avg.comps.pointsummary,
      visualfeats == "localizer"
    ),
    aes(
      ymin = amplitude - ci,
      ymax = amplitude + ci
    ),
    linetype = "dotted",
    size = .1,
    alpha = .3,
    show.legend = FALSE
  ) +
  scale_color_manual(
    breaks = c(
      "localizer", "large bright",
      "large dark", "small bright", "small dark"
    ),
    values = waveforms.palette
  ) +
  scale_fill_manual(values = waveforms.palette) +
  labs(
    title = "LPP (402-684 ms)",
    x = "time (ms)",
    y = expression(paste("amplitude (", mu, "V)"))
  ) +
  scale_x_continuous(
    breaks = seq(-200, 1000, 50),
    limits = c(-100, 800)
  ) +
  scale_y_reverse(
    breaks = seq(-2, 3, 1),
    limits = c(3, -2)
  ) +
  annotate("rect",
    xmin = 402,
    xmax = 684,
    ymin = -.5,
    ymax = 2.5,
    linetype = "solid",
    size = 2,
    color = "#de1d1d",
    alpha = 0
  ) +
  theme_classic(base_size = 20) +
  theme(
    plot.title = element_text(
      size = 28,
      hjust = .5,
      face = "bold"
    ),
    legend.position = "none"
  )
```

```{r LPP_pirateplot}
summarySEwithin(data.EEG.trial, 
                "LPP", 
                withinvars = c("participant", "size", "cont", "emo"), 
                idvar = "word") %>%
  unite(visualfeats, c("size", "cont"), sep = " ") %>%
  pirateplot(
    formula = LPP ~ emo + visualfeats,
    data = .,
    main = "LPP",
    xlim = NULL,
    xlab = "",
    ylim = c(-2, 4),
    ylab = expression(paste("amplitude (", mu, "V)")),
    inf.method = "hdi",
    inf.within = "participant",
    hdi.iter = 5000,
    cap.beans = TRUE,
    point.cex = 1.3, 
    pal = pirateplot.palette
  ) 
```

***
***

# CONFIRMATORY ANALYSIS

Calculate and compare the Bayes Factor of different linear mixed-effects models. The random factors are participants and the individual word per trial. Their variance is set as nuisance.   

Compare (against the null model) the following models:   

1. main effects of size and emotion   
2. interactive effects of size and emotion   
3. main effects of contrast and emotion   
4. interactive effects of contrast and emotion   
5. main effects of size, contrast, and emotion   
6. interactive effects of size, contrast, and emotion   

Then, compare the best competing models to understand which one should be preferred overall.

## P1

```{r P1_summary}
summarySEwithin(data.EEG.trial, 
                "P1", 
                withinvars = c("size", "cont", "emo"), 
                idvar = "participant") %>%
  kable(., digits = 2)
```

```{r P1_models}
# preallocate matrix with all BFs
compare.P1.BF <- matrix(NA, 6, length(scaling.factor))
# preallocate matrix with all % errors
compare.P1.perc.err <- matrix(NA, 6, length(scaling.factor))

# ### uncomment to recompute models ###
# for (k in 1:length(scaling.factor)) { # loop through scaling factors
# 
#   ### main effects of size and emotion
#   P1.sizeplusemo.BF <- lmBF(
#     P1 ~ size + emo, # formula
#     data.EEG.trial, # data
#     whichRandom = c("participant", "word"), # random effects
#     rscaleFixed = scaling.factor[k], # scaling factor of prior on effect size
#     rscaleRandom = "nuisance", # prior scale for standardized random effects
#     rscaleCont = "medium", # prior scale for standardized slopes
#     iterations = niter # number of MCMC iterations
#   )
#   
#   saveRDS(P1.sizeplusemo.BF,  # save model
#           file = paste0(getwd(), "/EEG/main/models/P1_sizeplusemo_BF_", scaling.factor[k], ".rds"))
#   
#   ### interactive effects of size and emotion
#   P1.sizebyemo.BF <- lmBF(
#     P1 ~ size * emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(P1.sizebyemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/P1_sizebyemo_BF_", scaling.factor[k], ".rds"))
# 
#   ### main effects of contrast and emotion
#   P1.contplusemo.BF <- lmBF(
#     P1 ~ cont + emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(P1.contplusemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/P1_contplusemo_BF_", scaling.factor[k], ".rds")) 
#   
#   ### interactive effects of contrast and emotion
#   P1.contbyemo.BF <- lmBF(
#     P1 ~ cont * emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(P1.contbyemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/P1_contbyemo_BF_", scaling.factor[k], ".rds")) 
#   
#   ### main effects of size, contrast, and emotion
#   P1.sizepluscontplusemo.BF <- lmBF(
#     P1 ~ size + cont + emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(P1.sizepluscontplusemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/P1_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) 
#   
#   ### interactive effects of size, contrast, and emotion
#   P1.sizebycontbyemo.BF <- lmBF(
#     P1 ~ size * cont * emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(P1.sizebycontbyemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/P1_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) 
# }

### model comparison across scaling factors
for (k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### load models
  P1.sizeplusemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_sizeplusemo_BF_", scaling.factor[k], ".rds"))
  
  P1.sizebyemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_sizebyemo_BF_", scaling.factor[k], ".rds"))
  
  P1.contplusemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_contplusemo_BF_", scaling.factor[k], ".rds"))
  
  P1.contbyemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_contbyemo_BF_", scaling.factor[k], ".rds")) 
  
  P1.sizepluscontplusemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) 
  
  P1.sizebycontbyemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) 
  
  # BFs
  compare.P1.BF[, k] <- c(
    exp(P1.sizeplusemo.BF@bayesFactor$bf[1]),
    exp(P1.sizebyemo.BF@bayesFactor$bf[1]),
    exp(P1.contplusemo.BF@bayesFactor$bf[1]),
    exp(P1.contbyemo.BF@bayesFactor$bf[1]),
    exp(P1.sizepluscontplusemo.BF@bayesFactor$bf[1]),
    exp(P1.sizebycontbyemo.BF@bayesFactor$bf[1])
  )
  # percentage of error
  compare.P1.perc.err[, k] <- c(
    P1.sizeplusemo.BF@bayesFactor$error[1] * 100,
    P1.sizebyemo.BF@bayesFactor$error[1] * 100,
    P1.contplusemo.BF@bayesFactor$error[1] * 100,
    P1.contbyemo.BF@bayesFactor$error[1] * 100,
    P1.sizepluscontplusemo.BF@bayesFactor$error[1] * 100,
    P1.sizebycontbyemo.BF@bayesFactor$error[1] * 100
  )
}

# summary confirmatory analysis
compare.P1 <- data.frame(
  "model" = c("size + emo", "size x emo", "contr + emo", "cont x emo", "size + cont + emo", "size x cont x emo"),
  "nar" = compare.P1.BF[, 1], "nar.p.err" = compare.P1.perc.err[, 1],
  "med" = compare.P1.BF[, 2], "med.p.err" = compare.P1.perc.err[, 2],
  "wid" = compare.P1.BF[, 3], "wid.p.err" = compare.P1.perc.err[, 3]
)

# sort according to medium scaling factor (in descending order)
compare.P1 <- compare.P1[order(compare.P1$med, decreasing = TRUE), ]

# nicer table
kable(format(compare.P1, scientific = TRUE))
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.P1[1, 4] < 1, "null", as.character(compare.P1[1, 1]))` ought to be preferred.   
The best model (`r as.character(compare.P1[1, 1])`) explains the observed data `r format(ifelse(compare.P1[1, 4]>1, compare.P1[1, 4]/compare.P1[2, 4], 1/compare.P1[1, 4]), scientific = TRUE)` times better than the second best model (`r as.character(compare.P1[2, 1])`).   

### Paired comparisons

```{r P1_posthoc}
# interactions of interest (i.e., always negative vs. neutral)
P1.posthocBF <- data.EEG.trial %>%
  select(participant, cond, P1) %>%
  summarySEwithin(data = ., measurevar = "P1", withinvars = c("participant", "cond")) %>%
  split(.$cond) # split according to condition

# preallocate matrix with all BF10
compare.P1.posthocBF <- matrix(NA, 4, length(scaling.factor))
# preallocate matrix with all % errors
compare.P1.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor)) 

# ### uncomment to recompute models ###
# for (k in 1:length(scaling.factor)) { # loop through scaling factors
#   
#   ### large, dark, negative vs. neutral
#   P1.posthocBF.large.dark.negVSneut <- ttestBF(
#     P1.posthocBF$`negative large dark`$P1, # first condition
#     P1.posthocBF$`neutral large dark`$P1, # second condition
#     mu = 0, # null hypothesis (mean difference = 0)
#     paired = TRUE, # paired sample test
#     iterations = niter, # number of MCMC iterations
#     rscale = scaling.factor[k] # scaling factor
#   )
#   
#   saveRDS(P1.posthocBF.large.dark.negVSneut, # save model
#           file = paste0(getwd(), "/EEG/main/models/P1_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds"))
#   
#   ### small, dark, negative vs. neutral
#   P1.posthocBF.small.dark.negVSneut <- ttestBF(
#     P1.posthocBF$`negative small dark`$P1,
#     P1.posthocBF$`neutral small dark`$P1,
#     mu = 0,
#     paired = TRUE,
#     iterations = niter,
#     rscale = scaling.factor[k]
#   )
#   
#   saveRDS(P1.posthocBF.small.dark.negVSneut,
#           file = paste0(getwd(), "/EEG/main/models/P1_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds"))
#   
#   ### large, bright, negative vs. neutral
#   P1.posthocBF.large.bright.negVSneut <- ttestBF(
#     P1.posthocBF$`negative large bright`$P1,
#     P1.posthocBF$`neutral large bright`$P1,
#     mu = 0,
#     paired = TRUE,
#     iterations = niter,
#     rscale = scaling.factor[k]
#   )
#   
#   saveRDS(P1.posthocBF.large.bright.negVSneut,
#           file = paste0(getwd(), "/EEG/main/models/P1_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds"))
# 
#   ### small, bright, negative vs. neutral
#   P1.posthocBF.small.bright.negVSneut <- ttestBF(
#     P1.posthocBF$`negative small bright`$P1,
#     P1.posthocBF$`neutral small bright`$P1,
#     mu = 0,
#     iterations = niter,
#     paired = TRUE,
#     rscale = scaling.factor[k]
#   )
#   
#   saveRDS(P1.posthocBF.small.bright.negVSneut,
#           file = paste0(getwd(), "/EEG/main/models/P1_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds"))
#   
# }

### model comparison across scaling factors
for (k in 1:length(scaling.factor)) {
  
  ### load models
  P1.posthocBF.large.dark.negVSneut <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds"))
  
  P1.posthocBF.small.dark.negVSneut <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds"))
  
  P1.posthocBF.large.bright.negVSneut <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds"))
  
  P1.posthocBF.small.bright.negVSneut <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds"))
  
  ### model comparison
  compare.P1.posthocBF[, k] <- c(
    exp(P1.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
    exp(P1.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
    exp(P1.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
    exp(P1.posthocBF.small.bright.negVSneut@bayesFactor$bf[1])
  )

  # percentage of error
  compare.P1.posthocBF.perc.err[, k] <- c(
    P1.posthocBF.large.dark.negVSneut@bayesFactor$error[1] * 100,
    P1.posthocBF.small.dark.negVSneut@bayesFactor$error[1] * 100,
    P1.posthocBF.large.bright.negVSneut@bayesFactor$error[1] * 100,
    P1.posthocBF.small.bright.negVSneut@bayesFactor$error[1] * 100
  )
}

# summary
compare.P1.posthocBF <- data.frame(
  "comparison" = c("large.dark.negVSneut", "small.dark.negVSneut", "large.bright.negVSneut", "small.bright.negVSneut"),
  "nar" = compare.P1.posthocBF[, 1], "nar.p.err" = compare.P1.posthocBF.perc.err[, 1],
  "med" = compare.P1.posthocBF[, 2], "med.p.err" = compare.P1.posthocBF.perc.err[, 2],
  "wid" = compare.P1.posthocBF[, 3], "wid.p.err" = compare.P1.posthocBF.perc.err[, 3]
)

# nicer table
kable(format(compare.P1.posthocBF, scientific = TRUE), digits = 2)
```

Follow-up contrasts reveal that the effect of *emotion* does not explain changes in P1 amplitude.

### Exploratory model selection

```{r P1_expl_modelselect}
# preallocate matrix with all BF10
compare.P1.anovaBF.temp <- matrix(NA, 7, length(scaling.factor))
# preallocate matrix with all % errors
compare.P1.anovaBF.perc.err.temp <- matrix(NA, 7, length(scaling.factor))

# ### uncomment to recompute models ###
# ### How important is each effect/interaction if we remove it from the full model?
# for (k in 1:length(scaling.factor)) { # loop through scaling factors
# 
#   P1.anovaBF <- anovaBF(
#     P1 ~ size * cont * emo, # formula
#     data.EEG.trial, # data
#     whichModels = "top", # test all models created by removing a main effect or interaction from the full model
#     whichRandom = c("participant", "word"), # random effects
#     rscaleFixed = scaling.factor[k], # scaling factor of prior on effect size
#     rscaleRandom = "nuisance", # prior scale for standardized random effects
#     iterations = niter # number of MCMC iterations
#   )
#   
#   saveRDS(P1.anovaBF,
#           file = paste0(getwd(), "/EEG/main/models/P1_anovaBF_", scaling.factor[k], ".rds"))
# 
# }


### model comparison across scaling factors
for (k in 1:length(scaling.factor)) {
  
  ### load model
  P1.anovaBF <- readRDS(
    paste0(getwd(), "/EEG/main/models/P1_anovaBF_", scaling.factor[k], ".rds"))
  
  # BFs
  compare.P1.anovaBF.temp[, k] <- exp(P1.anovaBF@bayesFactor$bf)
  
  # percentage of error
  compare.P1.anovaBF.perc.err.temp[, k] <- P1.anovaBF@bayesFactor$error * 100
  
}

# summary exploratory analysis
compare.P1.anovaBF <- data.frame(
  "omit from full model" = c("cont:emo:size", "cont:emo", "emo:size", "cont:size", "emo", "cont", "size"),
  "nar" = compare.P1.anovaBF.temp[, 1], "nar.p.err" = compare.P1.anovaBF.perc.err.temp[, 1],
  "med" = compare.P1.anovaBF.temp[, 2], "med.p.err" = compare.P1.anovaBF.perc.err.temp[, 2],
  "wid" = compare.P1.anovaBF.temp[, 3], "wid.p.err" = compare.P1.anovaBF.perc.err.temp[, 3]
)

# sort according to medium scaling factor (in descending order)
compare.P1.anovaBF <- compare.P1.anovaBF[order(compare.P1.anovaBF$med, decreasing = TRUE), ]

# nicer table
kable(format(compare.P1.anovaBF, scientific = TRUE), digits = 2)
```

Exploratory analyses suggest that omitting the factor *emotion* from the full model improves fitting by `r compare.P1.anovaBF$med[1]` times. Removing the interactions *size x contrast x emotion*, *contrast x emotion*, and *emotion x size* also improves fitting by at least `r compare.P1.anovaBF$med[2]`, `r compare.P1.anovaBF$med[3]`, and `r compare.P1.anovaBF$med[4]` times, respectively.   
Conversely, omitting the factor *contrast* or the *contrast x size* interaction lowers the explanatory value of the resulting model by at least `r 1/compare.P1.anovaBF$med[5]` and `r format(1/compare.P1.anovaBF$med[6], scientific = TRUE)` times. Finally, omitting the factor *size* is maximally detrimental, as it would lower the explanatory value of the resulting model by at least `r format(1/compare.P1.anovaBF$med[7], scientific = TRUE)` times.

## N1

```{r N1_summary}
summarySEwithin(data.EEG.trial, 
                "N1", 
                withinvars = c("size", "cont", "emo"), 
                idvar = "participant") %>%
  kable(., digits = 2)
```

```{r N1_models}
# preallocate matrix with all BFs
compare.N1.BF <- matrix(NA, 6, length(scaling.factor))
# preallocate matrix with all % errors
compare.N1.perc.err <- matrix(NA, 6, length(scaling.factor))

# ### uncomment to recompute models ###
# for (k in 1:length(scaling.factor)) { # loop through scaling factors
# 
#   ### main effects of size and emotion
#   N1.sizeplusemo.BF <- lmBF(
#     N1 ~ size + emo, # formula
#     data.EEG.trial, # data
#     whichRandom = c("participant", "word"), # random effects
#     rscaleFixed = scaling.factor[k], # scaling factor of prior on effect size
#     rscaleRandom = "nuisance", # prior scale for standardized random effects
#     rscaleCont = "medium", # prior scale for standardized slopes
#     iterations = niter # number of MCMC iterations
#   )
#   
#   saveRDS(N1.sizeplusemo.BF,  # save model
#           file = paste0(getwd(), "/EEG/main/models/N1_sizeplusemo_BF_", scaling.factor[k], ".rds"))
#   
#   ### interactive effects of size and emotion
#   N1.sizebyemo.BF <- lmBF(
#     N1 ~ size * emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(N1.sizebyemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/N1_sizebyemo_BF_", scaling.factor[k], ".rds"))
# 
#   ### main effects of contrast and emotion
#   N1.contplusemo.BF <- lmBF(
#     N1 ~ cont + emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(N1.contplusemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/N1_contplusemo_BF_", scaling.factor[k], ".rds")) 
#   
#   ### interactive effects of contrast and emotion
#   N1.contbyemo.BF <- lmBF(
#     N1 ~ cont * emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(N1.contbyemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/N1_contbyemo_BF_", scaling.factor[k], ".rds")) 
#   
#   ### main effects of size, contrast, and emotion
#   N1.sizepluscontplusemo.BF <- lmBF(
#     N1 ~ size + cont + emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(N1.sizepluscontplusemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/N1_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) 
#   
#   ### interactive effects of size, contrast, and emotion
#   N1.sizebycontbyemo.BF <- lmBF(
#     N1 ~ size * cont * emo,
#     data.EEG.trial,
#     whichRandom = c("participant", "word"),
#     rscaleFixed = scaling.factor[k],
#     rscaleRandom = "nuisance",
#     rscaleCont = "medium",
#     iterations = niter
#   )
#   
#   saveRDS(N1.sizebycontbyemo.BF, # save model
#           file = paste0(getwd(), "/EEG/main/models/N1_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) 
# }

### model comparison across scaling factors
for (k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### load models
  N1.sizeplusemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_sizeplusemo_BF_", scaling.factor[k], ".rds"))
  
  N1.sizebyemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_sizebyemo_BF_", scaling.factor[k], ".rds"))
  
  N1.contplusemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_contplusemo_BF_", scaling.factor[k], ".rds"))
  
  N1.contbyemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_contbyemo_BF_", scaling.factor[k], ".rds")) 
  
  N1.sizepluscontplusemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) 
  
  N1.sizebycontbyemo.BF <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) 
  
  # BFs
  compare.N1.BF[, k] <- c(
    exp(N1.sizeplusemo.BF@bayesFactor$bf[1]),
    exp(N1.sizebyemo.BF@bayesFactor$bf[1]),
    exp(N1.contplusemo.BF@bayesFactor$bf[1]),
    exp(N1.contbyemo.BF@bayesFactor$bf[1]),
    exp(N1.sizepluscontplusemo.BF@bayesFactor$bf[1]),
    exp(N1.sizebycontbyemo.BF@bayesFactor$bf[1])
  )
  # percentage of error
  compare.N1.perc.err[, k] <- c(
    N1.sizeplusemo.BF@bayesFactor$error[1] * 100,
    N1.sizebyemo.BF@bayesFactor$error[1] * 100,
    N1.contplusemo.BF@bayesFactor$error[1] * 100,
    N1.contbyemo.BF@bayesFactor$error[1] * 100,
    N1.sizepluscontplusemo.BF@bayesFactor$error[1] * 100,
    N1.sizebycontbyemo.BF@bayesFactor$error[1] * 100
  )
}

# summary confirmatory analysis
compare.N1 <- data.frame(
  "model" = c("size + emo", "size x emo", "contr + emo", "cont x emo", "size + cont + emo", "size x cont x emo"),
  "nar" = compare.N1.BF[, 1], "nar.p.err" = compare.N1.perc.err[, 1],
  "med" = compare.N1.BF[, 2], "med.p.err" = compare.N1.perc.err[, 2],
  "wid" = compare.N1.BF[, 3], "wid.p.err" = compare.N1.perc.err[, 3]
)

# sort according to medium scaling factor (in descending order)
compare.N1 <- compare.N1[order(compare.N1$med, decreasing = TRUE), ]

# nicer table
kable(format(compare.N1, scientific = TRUE))
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.N1[1, 4] < 1, "null", as.character(compare.N1[1, 1]))` ought to be preferred.   
The best model (`r as.character(compare.N1[1, 1])`) explains the observed data `r format(ifelse(compare.N1[1, 4] > 1, compare.N1[1, 4]/compare.N1[2, 4], 1/compare.N1[1, 4]), scientific = TRUE)` times better than the second best model (`r as.character(compare.N1[2, 1])`).   

### Paired comparisons

```{r N1_posthoc}
# interactions of interest (i.e., always negative vs. neutral)
N1.posthocBF <- data.EEG.trial %>%
  select(participant, cond, N1) %>%
  summarySEwithin(data = ., measurevar = "N1", withinvars = c("participant", "cond")) %>%
  split(.$cond) # split according to condition

# preallocate matrix with all BF10
compare.N1.posthocBF <- matrix(NA, 4, length(scaling.factor))
# preallocate matrix with all % errors
compare.N1.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor)) 

# ### uncomment to recompute models ###
# for (k in 1:length(scaling.factor)) { # loop through scaling factors
# 
#   ### large, dark, negative vs. neutral
#   N1.posthocBF.large.dark.negVSneut <- ttestBF(
#     N1.posthocBF$`negative large dark`$N1, # first condition
#     N1.posthocBF$`neutral large dark`$N1, # second condition
#     mu = 0, # null hypothesis (mean difference = 0)
#     paired = TRUE, # paired sample test
#     iterations = niter, # number of MCMC iterations
#     rscale = scaling.factor[k] # scaling factor
#   )
# 
#   saveRDS(N1.posthocBF.large.dark.negVSneut, # save model
#           file = paste0(getwd(), "/EEG/main/models/N1_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds"))
# 
#   ### small, dark, negative vs. neutral
#   N1.posthocBF.small.dark.negVSneut <- ttestBF(
#     N1.posthocBF$`negative small dark`$N1,
#     N1.posthocBF$`neutral small dark`$N1,
#     mu = 0,
#     paired = TRUE,
#     iterations = niter,
#     rscale = scaling.factor[k]
#   )
# 
#   saveRDS(N1.posthocBF.small.dark.negVSneut,
#           file = paste0(getwd(), "/EEG/main/models/N1_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds"))
# 
#   ### large, bright, negative vs. neutral
#   N1.posthocBF.large.bright.negVSneut <- ttestBF(
#     N1.posthocBF$`negative large bright`$N1,
#     N1.posthocBF$`neutral large bright`$N1,
#     mu = 0,
#     paired = TRUE,
#     iterations = niter,
#     rscale = scaling.factor[k]
#   )
# 
#   saveRDS(N1.posthocBF.large.bright.negVSneut,
#           file = paste0(getwd(), "/EEG/main/models/N1_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds"))
# 
#   ### small, bright, negative vs. neutral
#   N1.posthocBF.small.bright.negVSneut <- ttestBF(
#     N1.posthocBF$`negative small bright`$N1,
#     N1.posthocBF$`neutral small bright`$N1,
#     mu = 0,
#     iterations = niter,
#     paired = TRUE,
#     rscale = scaling.factor[k]
#   )
# 
#   saveRDS(N1.posthocBF.small.bright.negVSneut,
#           file = paste0(getwd(), "/EEG/main/models/N1_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds"))
# 
# }

### model comparison across scaling factors
for (k in 1:length(scaling.factor)) {
  
  ### load models
  N1.posthocBF.large.dark.negVSneut <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds"))
  
  N1.posthocBF.small.dark.negVSneut <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds"))
  
  N1.posthocBF.large.bright.negVSneut <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds"))
  
  N1.posthocBF.small.bright.negVSneut <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds"))
  
  ### model comparison
  compare.N1.posthocBF[, k] <- c(
    exp(N1.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
    exp(N1.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
    exp(N1.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
    exp(N1.posthocBF.small.bright.negVSneut@bayesFactor$bf[1])
  )

  # percentage of error
  compare.N1.posthocBF.perc.err[, k] <- c(
    N1.posthocBF.large.dark.negVSneut@bayesFactor$error[1] * 100,
    N1.posthocBF.small.dark.negVSneut@bayesFactor$error[1] * 100,
    N1.posthocBF.large.bright.negVSneut@bayesFactor$error[1] * 100,
    N1.posthocBF.small.bright.negVSneut@bayesFactor$error[1] * 100
  )
}

# summary
compare.N1.posthocBF <- data.frame(
  "comparison" = c("large.dark.negVSneut", "small.dark.negVSneut", "large.bright.negVSneut", "small.bright.negVSneut"),
  "nar" = compare.N1.posthocBF[, 1], "nar.p.err" = compare.N1.posthocBF.perc.err[, 1],
  "med" = compare.N1.posthocBF[, 2], "med.p.err" = compare.N1.posthocBF.perc.err[, 2],
  "wid" = compare.N1.posthocBF[, 3], "wid.p.err" = compare.N1.posthocBF.perc.err[, 3]
)

# nicer table
kable(format(compare.N1.posthocBF, scientific = TRUE), digits = 2)
```

Follow-up contrasts reveal that the effect of *emotion* does not explain changes in N1 amplitude.

### Exploratory model selection

```{r N1_expl_modelselect}
# preallocate matrix with all BF10
compare.N1.anovaBF.temp <- matrix(NA, 7, length(scaling.factor))
# preallocate matrix with all % errors
compare.N1.anovaBF.perc.err.temp <- matrix(NA, 7, length(scaling.factor))

# ### uncomment to recompute models ###
# ### How important is each effect/interaction if we remove it from the full model?
# for (k in 1:length(scaling.factor)) { # loop through scaling factors
# 
#   N1.anovaBF <- anovaBF(
#     N1 ~ size * cont * emo, # formula
#     data.EEG.trial, # data
#     whichModels = "top", # test all models created by removing a main effect or interaction from the full model
#     whichRandom = c("participant", "word"), # random effects
#     rscaleFixed = scaling.factor[k], # scaling factor of prior on effect size
#     rscaleRandom = "nuisance", # prior scale for standardized random effects
#     iterations = niter # number of MCMC iterations
#   )
#   
#   saveRDS(N1.anovaBF,
#           file = paste0(getwd(), "/EEG/main/models/N1_anovaBF_", scaling.factor[k], ".rds"))
# 
# }


### model comparison across scaling factors
for (k in 1:length(scaling.factor)) {
  
  ### load model
  N1.anovaBF <- readRDS(
    paste0(getwd(), "/EEG/main/models/N1_anovaBF_", scaling.factor[k], ".rds"))
  
  # BFs
  compare.N1.anovaBF.temp[, k] <- exp(N1.anovaBF@bayesFactor$bf)
  
  # percentage of error
  compare.N1.anovaBF.perc.err.temp[, k] <- N1.anovaBF@bayesFactor$error * 100
  
}

# summary exploratory analysis
compare.N1.anovaBF <- data.frame(
  "omit from full model" = c("cont:emo:size", "cont:emo", "emo:size", "cont:size", "emo", "cont", "size"),
  "nar" = compare.N1.anovaBF.temp[, 1], "nar.p.err" = compare.N1.anovaBF.perc.err.temp[, 1],
  "med" = compare.N1.anovaBF.temp[, 2], "med.p.err" = compare.N1.anovaBF.perc.err.temp[, 2],
  "wid" = compare.N1.anovaBF.temp[, 3], "wid.p.err" = compare.N1.anovaBF.perc.err.temp[, 3]
)

# sort according to medium scaling factor (in descending order)
compare.N1.anovaBF <- compare.N1.anovaBF[order(compare.N1.anovaBF$med, decreasing = TRUE), ]

# nicer table
kable(format(compare.N1.anovaBF, scientific = TRUE), digits = 2)
```

Exploratory analyses further suggest that omitting the *emotion x size* interaction from the full model improves fitting by `r compare.N1.anovaBF$med[1]` times. Removing *contrast x emotion*, *emotion*, and *size x contrast x emotion* also improves fitting by `r compare.N1.anovaBF$med[2]`, `r compare.N1.anovaBF$med[3]`, and `r compare.N1.anovaBF$med[4]` times, respectively.   
Conversely, omitting the factor *size* or the *contrast x size* interaction lowers the explanatory value of the resulting model by `r format(1/compare.N1.anovaBF$med[5], scientific = TRUE)` and `r format(1/compare.N1.anovaBF$med[6], scientific = TRUE)` times. Finally, omitting the factor *contrast* is maximally detrimental, as it would lower the explanatory value of the resulting model by `r format(1/compare.N1.anovaBF$med[7], scientific = TRUE)` times.

## EPN

```{r EPN_summary}
summarySEwithin(data.EEG.trial, 
                "EPN", 
                withinvars = c("size", "cont", "emo"), 
                idvar = "participant") %>%
  kable(., digits = 2)
```



























































## EPN

```{r EPN_summary}
# summarize data
summary.EPN <- summarySEwithin(data.EEG.trial, "EPN", withinvars = c("size", "cont", "emo"), idvar = "participant")
kable(summary.EPN, digits = 2)
```

```{r EPN_models}
# preallocate matrices with all BFs
compare.EPN.BF <- matrix(NA, 6, length(scaling.factor)) # BFs
compare.EPN.perc.err <- matrix(NA, 6, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  ### main effects of size and emotion
  # EPN.sizeplusemo.BF <- lmBF(EPN~size+emo, # formula
  #                           data.EEG.trial, # data
  #                           whichRandom=c("participant", "word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.sizeplusemo.BF, file=paste0(wd, "/models/EPN_sizeplusemo_BF_", scaling.factor[k], ".rds")) # save model
  EPN.sizeplusemo.BF <- readRDS(paste0(wd, "/models/EPN_sizeplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size and emotion
  # EPN.sizebyemo.BF <- lmBF(EPN~size*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant", "word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.sizebyemo.BF, file=paste0(wd, "/models/EPN_sizebyemo_BF_", scaling.factor[k], ".rds")) # save model
  EPN.sizebyemo.BF <- readRDS(paste0(wd, "/models/EPN_sizebyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of contrast and emotion
  # EPN.contplusemo.BF <- lmBF(EPN~cont+emo,
  #                           data.EEG.trial,
  #                           whichRandom=c("participant", "word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.contplusemo.BF, file=paste0(wd, "/models/EPN_contplusemo_BF_", scaling.factor[k], ".rds")) # save model
  EPN.contplusemo.BF <- readRDS(paste0(wd, "/models/EPN_contplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of contrast and emotion
  # EPN.contbyemo.BF <- lmBF(EPN~cont*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant", "word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.contbyemo.BF, file=paste0(wd, "/models/EPN_contbyemo_BF_", scaling.factor[k], ".rds")) # save model
  EPN.contbyemo.BF <- readRDS(paste0(wd, "/models/EPN_contbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of size, contrast, and emotion
  # EPN.sizepluscontplusemo.BF <- lmBF(EPN~size+cont+emo,
  #                                   data.EEG.trial,
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.sizepluscontplusemo.BF, file=paste0(wd, "/models/EPN_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # save model
  EPN.sizepluscontplusemo.BF <- readRDS(paste0(wd, "/models/EPN_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size, contrast, and emotion
  # EPN.sizebycontbyemo.BF <- lmBF(EPN~size*cont*emo,
  #                               data.EEG.trial,
  #                               whichRandom=c("participant", "word"), # random effects
  #                               rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                               rscaleRandom="nuisance", # prior scale for standardized random effects
  #                               rscaleCont="medium", # prior scale for standardized slopes
  #                               iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.sizebycontbyemo.BF, file=paste0(wd, "/models/EPN_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # save model
  EPN.sizebycontbyemo.BF <- readRDS(paste0(wd, "/models/EPN_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.EPN.BF[, k] <- c(
    exp(EPN.sizeplusemo.BF@bayesFactor$bf[1]),
    exp(EPN.sizebyemo.BF@bayesFactor$bf[1]),
    exp(EPN.contplusemo.BF@bayesFactor$bf[1]),
    exp(EPN.contbyemo.BF@bayesFactor$bf[1]),
    exp(EPN.sizepluscontplusemo.BF@bayesFactor$bf[1]),
    exp(EPN.sizebycontbyemo.BF@bayesFactor$bf[1])
  )
  # percentage of error
  compare.EPN.perc.err[, k] <- c(
    EPN.sizeplusemo.BF@bayesFactor$error[1] * 100,
    EPN.sizebyemo.BF@bayesFactor$error[1] * 100,
    EPN.contplusemo.BF@bayesFactor$error[1] * 100,
    EPN.contbyemo.BF@bayesFactor$error[1] * 100,
    EPN.sizepluscontplusemo.BF@bayesFactor$error[1] * 100,
    EPN.sizebycontbyemo.BF@bayesFactor$error[1] * 100
  )
}

# summary confirmatory analysis
compare.EPN <- data.frame(
  "model" = c("size + emo", "size x emo", "contr + emo", "cont x emo", "size + cont + emo", "size x cont x emo"),
  "nar" = compare.EPN.BF[, 1], "nar.p.err" = compare.EPN.perc.err[, 1],
  "med" = compare.EPN.BF[, 2], "med.p.err" = compare.EPN.perc.err[, 2],
  "wid" = compare.EPN.BF[, 3], "wid.p.err" = compare.EPN.perc.err[, 3]
)
compare.EPN <- compare.EPN[order(compare.EPN$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.EPN, scientific = TRUE))
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EPN[1, 4]<1, "null", as.character(compare.EPN[1, 1]))` ought to be preferred.   
The best model (`r as.character(compare.EPN[1, 1])`) explains the observed data `r format(ifelse(compare.EPN[1, 4]>1, compare.EPN[1, 4]/compare.EPN[2, 4], 1/compare.EPN[1, 4]), scientific=TRUE)` times better than the second best model (`r as.character(compare.EPN[2, 1])`).   

### Paired comparisons

```{r EPN_posthoc}
# interactions of interest (i.e., always negative vs. neutral)
EPN.posthocBF <- data.EEG.trial %>% # data frame
  select(participant, cond, EPN) %>% # select only variables of interest
  summarySEwithin(data = ., measurevar = "EPN", withinvars = c("participant", "cond")) %>% # summary
  split(.$cond) # split according to condition

compare.EPN.posthocBF <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all BF10
compare.EPN.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # large, dark, negative vs. neutral
  # EPN.posthocBF.large.dark.negVSneut <- ttestBF(EPN.posthocBF$`negative large dark`$EPN, # first condition
  #                                              EPN.posthocBF$`neutral large dark`$EPN, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.large.dark.negVSneut, file=paste0(wd, "/models/EPN_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  EPN.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd, "/models/EPN_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, dark, negative vs. neutral
  # EPN.posthocBF.small.dark.negVSneut <- ttestBF(EPN.posthocBF$`negative small dark`$EPN, # first condition
  #                                              EPN.posthocBF$`neutral small dark`$EPN, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.small.dark.negVSneut, file=paste0(wd, "/models/EPN_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  EPN.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd, "/models/EPN_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # large, bright, negative vs. neutral
  # EPN.posthocBF.large.bright.negVSneut <- ttestBF(EPN.posthocBF$`negative large bright`$EPN, # first condition
  #                                                EPN.posthocBF$`neutral large bright`$EPN, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.large.bright.negVSneut, file=paste0(wd, "/models/EPN_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  EPN.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd, "/models/EPN_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, bright, negative vs. neutral
  # EPN.posthocBF.small.bright.negVSneut <- ttestBF(EPN.posthocBF$`negative small bright`$EPN, # first condition
  #                                                EPN.posthocBF$`neutral small bright`$EPN, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.small.bright.negVSneut, file=paste0(wd, "/models/EPN_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  EPN.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd, "/models/EPN_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  ### model comparison
  compare.EPN.posthocBF[, k] <- c(
    exp(EPN.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
    exp(EPN.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
    exp(EPN.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
    exp(EPN.posthocBF.small.bright.negVSneut@bayesFactor$bf[1])
  )

  # percentage of error
  compare.EPN.posthocBF.perc.err[, k] <- c(
    EPN.posthocBF.large.dark.negVSneut@bayesFactor$error[1] * 100,
    EPN.posthocBF.small.dark.negVSneut@bayesFactor$error[1] * 100,
    EPN.posthocBF.large.bright.negVSneut@bayesFactor$error[1] * 100,
    EPN.posthocBF.small.bright.negVSneut@bayesFactor$error[1] * 100
  )
}

# summary
compare.EPN.posthocBF <- data.frame(
  "comparison" = c("large.dark.negVSneut", "small.dark.negVSneut", "large.bright.negVSneut", "small.bright.negVSneut"),
  "nar" = compare.EPN.posthocBF[, 1], "nar.p.err" = compare.EPN.posthocBF.perc.err[, 1],
  "med" = compare.EPN.posthocBF[, 2], "med.p.err" = compare.EPN.posthocBF.perc.err[, 2],
  "wid" = compare.EPN.posthocBF[, 3], "wid.p.err" = compare.EPN.posthocBF.perc.err[, 3]
)
kable(format(compare.EPN.posthocBF, scientific = TRUE), digits = 2)
```

Follow-up contrasts reveal that *emotion* may explain changes in EPN amplitude when words are presented in *small* font and *high* contrast (`r compare.EPN.posthocBF$med[2]`), as well as *large* font and *low* contrast (`r compare.EPN.posthocBF$med[3]`).

### Exploratory model selection

```{r EPN_expl_modelselect}
# preallocate matrices with all BFs
compare.EPN.anovaBF.temp <- matrix(NA, 7, length(scaling.factor)) # BFs
compare.EPN.anovaBF.perc.err.temp <- matrix(NA, 7, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # How important is each effect/interaction if we remove it from the full model?
  # EPN.anovaBF <- anovaBF(EPN~size*cont*emo, # formula
  #                       data.EEG.trial, # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant", "word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.anovaBF, file=paste0(wd, "/models/EPN_anovaBF_", scaling.factor[k], ".rds")) # save model
  EPN.anovaBF <- readRDS(paste0(wd, "/models/EPN_anovaBF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.EPN.anovaBF.temp[, k] <- exp(EPN.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.EPN.anovaBF.perc.err.temp[, k] <- EPN.anovaBF@bayesFactor$error * 100
}

# summary exploratory analysis
compare.EPN.anovaBF <- data.frame(
  "omit from full model" = c("cont:emo:size", "cont:emo", "emo:size", "cont:size", "emo", "cont", "size"),
  "nar" = compare.EPN.anovaBF.temp[, 1], "nar.p.err" = compare.EPN.anovaBF.perc.err.temp[, 1],
  "med" = compare.EPN.anovaBF.temp[, 2], "med.p.err" = compare.EPN.anovaBF.perc.err.temp[, 2],
  "wid" = compare.EPN.anovaBF.temp[, 3], "wid.p.err" = compare.EPN.anovaBF.perc.err.temp[, 3]
)
compare.EPN.anovaBF <- compare.EPN.anovaBF[order(compare.EPN.anovaBF$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.EPN.anovaBF, scientific = TRUE), digits = 2)
```

Exploratory analyses further suggest that omitting the factor *contrast* from the full model improves fitting by `r compare.EPN.anovaBF$med[1]` times. Removing *contrast x size*, *contrast x emotion*, *emotion x size*, and *size x contrast x emotion* also improves fitting by `r compare.EPN.anovaBF$med[2]`, `r compare.EPN.anovaBF$med[3]`, `r compare.EPN.anovaBF$med[4]`, and `r compare.EPN.anovaBF$med[5]` times, respectively.   
Conversely, omitting the factor *emotion* lowers the explanatory value of the resulting model by `r 1/compare.EPN.anovaBF$med[6]` times. Finally, omitting the factor *size* is maximally detrimental, as it would lower the explanatory value of the resulting model by `r format(1/compare.EPN.anovaBF$med[7], scientific=TRUE)` times.

## LPP

```{r LPP_summary}
# summarize data
summary.LPP <- summarySEwithin(data.EEG.trial, "LPP", withinvars = c("size", "cont", "emo"), idvar = "participant")
kable(summary.LPP, digits = 2)
```

```{r LPP_models}
# preallocate matrices with all BFs
compare.LPP.BF <- matrix(NA, 6, length(scaling.factor)) # BFs
compare.LPP.perc.err <- matrix(NA, 6, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  ### main effects of size and emotion
  # LPP.sizeplusemo.BF <- lmBF(LPP~size+emo, # formula
  #                           data.EEG.trial, # data
  #                           whichRandom=c("participant", "word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.sizeplusemo.BF, file=paste0(wd, "/models/LPP_sizeplusemo_BF_", scaling.factor[k], ".rds")) # save model
  LPP.sizeplusemo.BF <- readRDS(paste0(wd, "/models/LPP_sizeplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size and emotion
  # LPP.sizebyemo.BF <- lmBF(LPP~size*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant", "word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.sizebyemo.BF, file=paste0(wd, "/models/LPP_sizebyemo_BF_", scaling.factor[k], ".rds")) # save model
  LPP.sizebyemo.BF <- readRDS(paste0(wd, "/models/LPP_sizebyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of contrast and emotion
  # LPP.contplusemo.BF <- lmBF(LPP~cont+emo,
  #                           data.EEG.trial,
  #                           whichRandom=c("participant", "word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.contplusemo.BF, file=paste0(wd, "/models/LPP_contplusemo_BF_", scaling.factor[k], ".rds")) # save model
  LPP.contplusemo.BF <- readRDS(paste0(wd, "/models/LPP_contplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of contrast and emotion
  # LPP.contbyemo.BF <- lmBF(LPP~cont*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant", "word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.contbyemo.BF, file=paste0(wd, "/models/LPP_contbyemo_BF_", scaling.factor[k], ".rds")) # save model
  LPP.contbyemo.BF <- readRDS(paste0(wd, "/models/LPP_contbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of size, contrast, and emotion
  # LPP.sizepluscontplusemo.BF <- lmBF(LPP~size+cont+emo,
  #                                   data.EEG.trial,
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.sizepluscontplusemo.BF, file=paste0(wd, "/models/LPP_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # save model
  LPP.sizepluscontplusemo.BF <- readRDS(paste0(wd, "/models/LPP_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size, contrast, and emotion
  # LPP.sizebycontbyemo.BF <- lmBF(LPP~size*cont*emo,
  #                               data.EEG.trial,
  #                               whichRandom=c("participant", "word"), # random effects
  #                               rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                               rscaleRandom="nuisance", # prior scale for standardized random effects
  #                               rscaleCont="medium", # prior scale for standardized slopes
  #                               iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.sizebycontbyemo.BF, file=paste0(wd, "/models/LPP_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # save model
  LPP.sizebycontbyemo.BF <- readRDS(paste0(wd, "/models/LPP_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.LPP.BF[, k] <- c(
    exp(LPP.sizeplusemo.BF@bayesFactor$bf[1]),
    exp(LPP.sizebyemo.BF@bayesFactor$bf[1]),
    exp(LPP.contplusemo.BF@bayesFactor$bf[1]),
    exp(LPP.contbyemo.BF@bayesFactor$bf[1]),
    exp(LPP.sizepluscontplusemo.BF@bayesFactor$bf[1]),
    exp(LPP.sizebycontbyemo.BF@bayesFactor$bf[1])
  )
  # percentage of error
  compare.LPP.perc.err[, k] <- c(
    LPP.sizeplusemo.BF@bayesFactor$error[1] * 100,
    LPP.sizebyemo.BF@bayesFactor$error[1] * 100,
    LPP.contplusemo.BF@bayesFactor$error[1] * 100,
    LPP.contbyemo.BF@bayesFactor$error[1] * 100,
    LPP.sizepluscontplusemo.BF@bayesFactor$error[1] * 100,
    LPP.sizebycontbyemo.BF@bayesFactor$error[1] * 100
  )
}

# summary confirmatory analysis
compare.LPP <- data.frame(
  "model" = c("size + emo", "size x emo", "contr + emo", "cont x emo", "size + cont + emo", "size x cont x emo"),
  "nar" = compare.LPP.BF[, 1], "nar.p.err" = compare.LPP.perc.err[, 1],
  "med" = compare.LPP.BF[, 2], "med.p.err" = compare.LPP.perc.err[, 2],
  "wid" = compare.LPP.BF[, 3], "wid.p.err" = compare.LPP.perc.err[, 3]
)
compare.LPP <- compare.LPP[order(compare.LPP$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.LPP, scientific = TRUE))
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.LPP[1, 4]<1, "null", as.character(compare.LPP[1, 1]))` ought to be preferred.   
The best model (`r as.character(compare.LPP[1, 1])`) explains the observed data `r format(ifelse(compare.LPP[1, 4]>1, compare.LPP[1, 4]/compare.LPP[2, 4], 1/compare.LPP[1, 4]), scientific=TRUE)` times better than the second best model (`r as.character(compare.LPP[2, 1])`).   

### Paired comparisons

```{r LPP_posthoc}
# interactions of interest (i.e., always negative vs. neutral)
LPP.posthocBF <- data.EEG.trial %>% # data frame
  select(participant, cond, LPP) %>% # select only variables of interest
  summarySEwithin(data = ., measurevar = "LPP", withinvars = c("participant", "cond")) %>% # summary
  split(.$cond) # split according to condition

compare.LPP.posthocBF <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all BF10
compare.LPP.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # large, dark, negative vs. neutral
  # LPP.posthocBF.large.dark.negVSneut <- ttestBF(LPP.posthocBF$`negative large dark`$LPP, # first condition
  #                                              LPP.posthocBF$`neutral large dark`$LPP, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.large.dark.negVSneut, file=paste0(wd, "/models/LPP_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  LPP.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd, "/models/LPP_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, dark, negative vs. neutral
  # LPP.posthocBF.small.dark.negVSneut <- ttestBF(LPP.posthocBF$`negative small dark`$LPP, # first condition
  #                                              LPP.posthocBF$`neutral small dark`$LPP, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.small.dark.negVSneut, file=paste0(wd, "/models/LPP_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  LPP.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd, "/models/LPP_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # large, bright, negative vs. neutral
  # LPP.posthocBF.large.bright.negVSneut <- ttestBF(LPP.posthocBF$`negative large bright`$LPP, # first condition
  #                                                LPP.posthocBF$`neutral large bright`$LPP, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.large.bright.negVSneut, file=paste0(wd, "/models/LPP_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  LPP.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd, "/models/LPP_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, bright, negative vs. neutral
  # LPP.posthocBF.small.bright.negVSneut <- ttestBF(LPP.posthocBF$`negative small bright`$LPP, # first condition
  #                                                LPP.posthocBF$`neutral small bright`$LPP, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.small.bright.negVSneut, file=paste0(wd, "/models/LPP_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  LPP.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd, "/models/LPP_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  ### model comparison
  compare.LPP.posthocBF[, k] <- c(
    exp(LPP.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
    exp(LPP.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
    exp(LPP.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
    exp(LPP.posthocBF.small.bright.negVSneut@bayesFactor$bf[1])
  )

  # percentage of error
  compare.LPP.posthocBF.perc.err[, k] <- c(
    LPP.posthocBF.large.dark.negVSneut@bayesFactor$error[1] * 100,
    LPP.posthocBF.small.dark.negVSneut@bayesFactor$error[1] * 100,
    LPP.posthocBF.large.bright.negVSneut@bayesFactor$error[1] * 100,
    LPP.posthocBF.small.bright.negVSneut@bayesFactor$error[1] * 100
  )
}

# summary
compare.LPP.posthocBF <- data.frame(
  "comparison" = c("large.dark.negVSneut", "small.dark.negVSneut", "large.bright.negVSneut", "small.bright.negVSneut"),
  "nar" = compare.LPP.posthocBF[, 1], "nar.p.err" = compare.LPP.posthocBF.perc.err[, 1],
  "med" = compare.LPP.posthocBF[, 2], "med.p.err" = compare.LPP.posthocBF.perc.err[, 2],
  "wid" = compare.LPP.posthocBF[, 3], "wid.p.err" = compare.LPP.posthocBF.perc.err[, 3]
)
kable(format(compare.LPP.posthocBF, scientific = TRUE), digits = 2)
```

Follow-up contrasts reveal that *emotion* does not explain changes in LPP amplitude.

### Exploratory model selection

```{r LPP_expl_modelselect}
# preallocate matrices with all BFs
compare.LPP.anovaBF.temp <- matrix(NA, 7, length(scaling.factor)) # BFs
compare.LPP.anovaBF.perc.err.temp <- matrix(NA, 7, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # How important is each effect/interaction if we remove it from the full model?
  # LPP.anovaBF <- anovaBF(LPP~size*cont*emo, # formula
  #                       data.EEG.trial, # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant", "word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.anovaBF, file=paste0(wd, "/models/LPP_anovaBF_", scaling.factor[k], ".rds")) # save model
  LPP.anovaBF <- readRDS(paste0(wd, "/models/LPP_anovaBF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.LPP.anovaBF.temp[, k] <- exp(LPP.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.LPP.anovaBF.perc.err.temp[, k] <- LPP.anovaBF@bayesFactor$error * 100
}

# summary exploratory analysis
compare.LPP.anovaBF <- data.frame(
  "omit from full model" = c("cont:emo:size", "cont:emo", "emo:size", "cont:size", "emo", "cont", "size"),
  "nar" = compare.LPP.anovaBF.temp[, 1], "nar.p.err" = compare.LPP.anovaBF.perc.err.temp[, 1],
  "med" = compare.LPP.anovaBF.temp[, 2], "med.p.err" = compare.LPP.anovaBF.perc.err.temp[, 2],
  "wid" = compare.LPP.anovaBF.temp[, 3], "wid.p.err" = compare.LPP.anovaBF.perc.err.temp[, 3]
)
compare.LPP.anovaBF <- compare.LPP.anovaBF[order(compare.LPP.anovaBF$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.LPP.anovaBF, scientific = TRUE), digits = 2)
```

Exploratory analyses further suggest that omitting the factor *emotion* from the full model improves fitting by `r compare.LPP.anovaBF$med[1]` times. Removing *contrast x emotion*, *size x emotion*, and *size x contrast x emotion* also improves fitting by `r compare.LPP.anovaBF$med[2]`, `r compare.LPP.anovaBF$med[3]`, `r compare.LPP.anovaBF$med[4]` times, respectively.   
Conversely, omitting the *contrast x size* interaction or the factor *contrast* lowers the explanatory value of the resulting model by `r 1/compare.LPP.anovaBF$med[5]` and `r format(1/compare.LPP.anovaBF$med[6], scientific=TRUE)` times, respectively. Finally, omitting the factor *size* is maximally detrimental, as it would lower the explanatory value of the resulting model by `r format(1/compare.LPP.anovaBF$med[7], scientific=TRUE)` times.

***
***

# SUPPLEMENTARY ANALYSIS

Visual inspection of the waveforms revealed unexpected latency shifts at the level of P1 and N1 components. This could be a potential source of noise when analyzing mean amplitude values. Therefore, we ran the same analyses as above but using, as dependent variables, peak amplitude and latency values of P1 and N1.

```{r data_peaks}
data.P1.peakamp <- read.table("P1_locpeakamp.txt", header = TRUE) # load data
data.P1.peaklat <- read.table("P1_locpeaklat.txt", header = TRUE) # load data
data.N1.peakamp <- read.table("N1_locpeakamp.txt", header = TRUE) # load data
data.N1.peaklat <- read.table("N1_locpeaklat.txt", header = TRUE) # load data

data.peaks <- rbind(data.P1.peakamp, data.P1.peaklat, data.N1.peakamp, data.N1.peaklat) %>%
  mutate(
    var = rep(c("peak.amp", "peak.lat", "peak.amp", "peak.lat"), each = 320), # peak amplitude or latency?
    bini = factor(bini), # convert condition numbers as factors
    size = revalue(bini, c("1" = "large", "2" = "small", "3" = "large", "4" = "small", "5" = "large", "6" = "small", "7" = "large", "8" = "small")), # main effect of size
    size = relevel(size, ref = "large"), # re-reference size to large
    cont = revalue(bini, c("1" = "dark", "2" = "dark", "3" = "bright", "4" = "bright", "5" = "dark", "6" = "dark", "7" = "bright", "8" = "bright")), # main effect of contrast
    cont = relevel(cont, ref = "dark"), # re-reference contrast to dark
    emo = revalue(bini, c("1" = "negative", "2" = "negative", "3" = "negative", "4" = "negative", "5" = "neutral", "6" = "neutral", "7" = "neutral", "8" = "neutral")), # main effect of emotion
    emo = relevel(emo, ref = "neutral")
  ) %>% # re-reference emotion to neutral
  select(participant = ERPset, component = chlabel, var, condition = binlabel, size, cont, emo, value) # select, reorder, and rename variables
rm(data.P1.peakamp, data.P1.peaklat, data.N1.peakamp, data.N1.peaklat) # remove unnecessary data frames
```

## P1

### Peak amplitude

Peak amplitude: positive value larger than the 3 points (~10 ms at 256 Hz sampling rate) on either side of the peak.   
Time window: 66-148 ms post-stimulus onset.   
Electrode cluster: P7 P9 PO7 O1 O2 PO8 P8 P10.

```{r P1_peakamp_pirateplot}
# summarize data
summary.P1.peakamp <- summarySEwithin(subset(data.peaks, component == "P1" & var == "peak.amp"), "value", withinvars = c("size", "cont", "emo"), idvar = "participant")
kable(summary.P1.peakamp, digits = 2)

# pirateplot
pirateplot(
  formula = value ~ emo + size + cont, # dependent~independent variables
  data = subset(data.peaks, component == "P1" & var == "peak.amp"), # data frame
  main = "P1 peak amplitude", # main title
  xlim = NULL, # x-axis: limits
  xlab = "", # x-axis: label
  ylim = c(-1, 11), # y-axis: limits
  ylab = expression(paste("amplitude (", mu, "V)")), # y-axis: label
  inf.method = "hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
  inf.within = "participant", # ID variable in within-subject designs
  hdi.iter = 5000, # number of iterations for 95% HDI
  cap.beans = TRUE, # max and min values of bean densities are capped at the limits found in the data
  pal = pirateplot.palette
) # color palette
```

```{r P1_peakamp_models}
# preallocate matrices with all BFs
compare.P1.peakamp.BF <- matrix(NA, 6, length(scaling.factor)) # BFs
compare.P1.peakamp.perc.err <- matrix(NA, 6, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  ### main effects of size and emotion
  # P1.peakamp.sizeplusemo.BF <- lmBF(value~size+emo, # formula
  #                                   subset(data.peaks, component=="P1" & var=="peak.amp"), # data
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.sizeplusemo.BF, file=paste0(wd, "/models/P1_peakamp_sizeplusemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.sizeplusemo.BF <- readRDS(paste0(wd, "/models/P1_peakamp_sizeplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size and emotion
  # P1.peakamp.sizebyemo.BF <- lmBF(value~size*emo, # formula
  #                                 subset(data.peaks, component=="P1" & var=="peak.amp"), # data
  #                                 whichRandom=c("participant", "word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.sizebyemo.BF, file=paste0(wd, "/models/P1_peakamp_sizebyemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.sizebyemo.BF <- readRDS(paste0(wd, "/models/P1_peakamp_sizebyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of contrast and emotion
  # P1.peakamp.contplusemo.BF <- lmBF(value~cont+emo, # formula
  #                                   subset(data.peaks, component=="P1" & var=="peak.amp"), # data
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.contplusemo.BF, file=paste0(wd, "/models/P1_peakamp_contplusemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.contplusemo.BF <- readRDS(paste0(wd, "/models/P1_peakamp_contplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of contrast and emotion
  # P1.peakamp.contbyemo.BF <- lmBF(value~cont*emo, # formula
  #                                 subset(data.peaks, component=="P1" & var=="peak.amp"), # data
  #                                 whichRandom=c("participant", "word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.contbyemo.BF, file=paste0(wd, "/models/P1_peakamp_contbyemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.contbyemo.BF <- readRDS(paste0(wd, "/models/P1_peakamp_contbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of size, contrast, and emotion
  # P1.peakamp.sizepluscontplusemo.BF <- lmBF(value~size+cont+emo, # formula
  #                                           subset(data.peaks, component=="P1" & var=="peak.amp"), # data
  #                                           whichRandom=c("participant", "word"), # random effects
  #                                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                           rscaleCont="medium", # prior scale for standardized slopes
  #                                           iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.sizepluscontplusemo.BF, file=paste0(wd, "/models/P1_peakamp_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.sizepluscontplusemo.BF <- readRDS(paste0(wd, "/models/P1_peakamp_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size, contrast, and emotion
  # P1.peakamp.sizebycontbyemo.BF <- lmBF(value~size*cont*emo, # formula
  #                                       subset(data.peaks, component=="P1" & var=="peak.amp"), # data
  #                                       whichRandom=c("participant", "word"), # random effects
  #                                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                       rscaleCont="medium", # prior scale for standardized slopes
  #                                       iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.sizebycontbyemo.BF, file=paste0(wd, "/models/P1_peakamp_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.sizebycontbyemo.BF <- readRDS(paste0(wd, "/models/P1_peakamp_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.P1.peakamp.BF[, k] <- c(
    exp(P1.peakamp.sizeplusemo.BF@bayesFactor$bf[1]),
    exp(P1.peakamp.sizebyemo.BF@bayesFactor$bf[1]),
    exp(P1.peakamp.contplusemo.BF@bayesFactor$bf[1]),
    exp(P1.peakamp.contbyemo.BF@bayesFactor$bf[1]),
    exp(P1.peakamp.sizepluscontplusemo.BF@bayesFactor$bf[1]),
    exp(P1.peakamp.sizebycontbyemo.BF@bayesFactor$bf[1])
  )
  # percentage of error
  compare.P1.peakamp.perc.err[, k] <- c(
    P1.peakamp.sizeplusemo.BF@bayesFactor$error[1] * 100,
    P1.peakamp.sizebyemo.BF@bayesFactor$error[1] * 100,
    P1.peakamp.contplusemo.BF@bayesFactor$error[1] * 100,
    P1.peakamp.contbyemo.BF@bayesFactor$error[1] * 100,
    P1.peakamp.sizepluscontplusemo.BF@bayesFactor$error[1] * 100,
    P1.peakamp.sizebycontbyemo.BF@bayesFactor$error[1] * 100
  )
}

# summary confirmatory analysis
compare.P1.peakamp <- data.frame(
  "model" = c("size + emo", "size x emo", "contr + emo", "cont x emo", "size + cont + emo", "size x cont x emo"),
  "nar" = compare.P1.peakamp.BF[, 1], "nar.p.err" = compare.P1.peakamp.perc.err[, 1],
  "med" = compare.P1.peakamp.BF[, 2], "med.p.err" = compare.P1.peakamp.perc.err[, 2],
  "wid" = compare.P1.peakamp.BF[, 3], "wid.p.err" = compare.P1.peakamp.perc.err[, 3]
)
compare.P1.peakamp <- compare.P1.peakamp[order(compare.P1.peakamp$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.P1.peakamp, scientific = TRUE), digits = 2)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.P1.peakamp[1, 4]<1, "null", as.character(compare.P1.peakamp[1, 1]))` ought to be preferred.   
The best model (`r as.character(compare.P1.peakamp[1, 1])`) explains the observed data `r ifelse(compare.P1.peakamp[1, 4]>1, compare.P1.peakamp[1, 4]/compare.P1.peakamp[2, 4], 1/compare.P1.peakamp[1, 4])` times better than the second best model (`r as.character(compare.P1.peakamp[2, 1])`).   

### Paired comparisons

```{r P1_peakamp_posthoc}
# interactions of interest (i.e., always negative vs. neutral)
P1.peakamp.posthocBF <- subset(data.peaks, component == "P1" & var == "peak.amp") %>% # data frame
  select(participant, condition, value) %>% # select only variables of interest
  split(.$condition) # split according to condition

compare.P1.peakamp.posthocBF <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.peakamp.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # large, dark, negative vs. neutral
  # P1.peakamp.posthocBF.large.dark.negVSneut <- ttestBF(P1.peakamp.posthocBF$negativeLargeDark$value, # first condition
  #                                                      P1.peakamp.posthocBF$neutralLargeDark$value, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.large.dark.negVSneut, file=paste0(wd, "/models/P1_peakamp_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd, "/models/P1_peakamp_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, dark, negative vs. neutral
  # P1.peakamp.posthocBF.small.dark.negVSneut <- ttestBF(P1.peakamp.posthocBF$negativeSmallDark$value, # first condition
  #                                                      P1.peakamp.posthocBF$neutralSmallDark$value, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.small.dark.negVSneut, file=paste0(wd, "/models/P1_peakamp_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd, "/models/P1_peakamp_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # large, bright, negative vs. neutral
  # P1.peakamp.posthocBF.large.bright.negVSneut <- ttestBF(P1.peakamp.posthocBF$negativeLargeBright$value, # first condition
  #                                                P1.peakamp.posthocBF$neutralLargeBright$value, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.large.bright.negVSneut, file=paste0(wd, "/models/P1_peakamp_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd, "/models/P1_peakamp_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, bright, negative vs. neutral
  # P1.peakamp.posthocBF.small.bright.negVSneut <- ttestBF(P1.peakamp.posthocBF$negativeSmallBright$value, # first condition
  #                                                P1.peakamp.posthocBF$neutralSmallBright$value, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.small.bright.negVSneut, file=paste0(wd, "/models/P1_peakamp_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd, "/models/P1_peakamp_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  ### model comparison
  compare.P1.peakamp.posthocBF[, k] <- c(
    exp(P1.peakamp.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
    exp(P1.peakamp.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
    exp(P1.peakamp.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
    exp(P1.peakamp.posthocBF.small.bright.negVSneut@bayesFactor$bf[1])
  )

  # percentage of error
  compare.P1.peakamp.posthocBF.perc.err[, k] <- c(
    P1.peakamp.posthocBF.large.dark.negVSneut@bayesFactor$error[1] * 100,
    P1.peakamp.posthocBF.small.dark.negVSneut@bayesFactor$error[1] * 100,
    P1.peakamp.posthocBF.large.bright.negVSneut@bayesFactor$error[1] * 100,
    P1.peakamp.posthocBF.small.bright.negVSneut@bayesFactor$error[1] * 100
  )
}

# summary
compare.P1.peakamp.posthocBF <- data.frame(
  "comparison" = c("large.dark.negVSneut", "small.dark.negVSneut", "large.bright.negVSneut", "small.bright.negVSneut"),
  "nar" = compare.P1.peakamp.posthocBF[, 1], "nar.p.err" = compare.P1.peakamp.posthocBF.perc.err[, 1],
  "med" = compare.P1.peakamp.posthocBF[, 2], "med.p.err" = compare.P1.peakamp.posthocBF.perc.err[, 2],
  "wid" = compare.P1.peakamp.posthocBF[, 3], "wid.p.err" = compare.P1.peakamp.posthocBF.perc.err[, 3]
)
kable(format(compare.P1.peakamp.posthocBF, scientific = TRUE), digits = 2)
```

Follow-up contrasts reveal that the effect of *emotion* does not explain changes in P1 peak amplitude.

### Exploratory model selection

```{r P1_peakamp_expl_modelselect}
# preallocate matrices with all BFs
compare.P1.peakamp.anovaBF.temp <- matrix(NA, 7, length(scaling.factor)) # BFs
compare.P1.peakamp.anovaBF.perc.err.temp <- matrix(NA, 7, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # How important is each effect/interaction if we remove it from the full model?
  # P1.peakamp.anovaBF <- anovaBF(value~size*cont*emo, # formula
  #                       subset(data.peaks, component=="P1" & var=="peak.amp"), # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant", "word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.anovaBF, file=paste0(wd, "/models/P1_peakamp_anovaBF_", scaling.factor[k], ".rds")) # save model
  P1.peakamp.anovaBF <- readRDS(paste0(wd, "/models/P1_peakamp_anovaBF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.P1.peakamp.anovaBF.temp[, k] <- exp(P1.peakamp.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.P1.peakamp.anovaBF.perc.err.temp[, k] <- P1.peakamp.anovaBF@bayesFactor$error * 100
}

# summary exploratory analysis
compare.P1.peakamp.anovaBF <- data.frame(
  "omit from full model" = c("cont:emo:size", "cont:emo", "emo:size", "cont:size", "emo", "cont", "size"),
  "nar" = compare.P1.peakamp.anovaBF.temp[, 1], "nar.p.err" = compare.P1.peakamp.anovaBF.perc.err.temp[, 1],
  "med" = compare.P1.peakamp.anovaBF.temp[, 2], "med.p.err" = compare.P1.peakamp.anovaBF.perc.err.temp[, 2],
  "wid" = compare.P1.peakamp.anovaBF.temp[, 3], "wid.p.err" = compare.P1.peakamp.anovaBF.perc.err.temp[, 3]
)
compare.P1.peakamp.anovaBF <- compare.P1.peakamp.anovaBF[order(compare.P1.peakamp.anovaBF$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.P1.peakamp.anovaBF, scientific = TRUE), digits = 2)
```

Exploratory analyses suggest that omitting the *contrast x emotion* interaction from the full model improves fitting by `r compare.P1.peakamp.anovaBF$med[1]` times. Removing *emotion*, *size x emotion*, and *size x contrast x emotion* also improves fitting by `r compare.P1.peakamp.anovaBF$med[2]`, `r compare.P1.peakamp.anovaBF$med[3]`, and `r compare.P1.peakamp.anovaBF$med[4]` times, respectively.   
Conversely, omitting  *contrast x size* or *contrast* lowers the explanatory value of the resulting model by `r 1/compare.P1.peakamp.anovaBF$med[5]` and `r 1/compare.P1.peakamp.anovaBF$med[6]` times, respectively. Finally, omitting the factor *size* is maximally detrimental, as it would lower the explanatory value of the resulting model by `r 1/compare.P1.peakamp.anovaBF$med[7]` times.

### Peak latency

Peak latency: time (in ms) of the positive value larger than the 3 points (~10 ms at 256 Hz sampling rate) on either side of the peak.   
Time window: 66-148 ms post-stimulus onset.   
Electrode cluster: P7 P9 PO7 O1 O2 PO8 P8 P10.

```{r P1_peaklat_pirateplot}
# summarize data
summary.P1.peaklat <- summarySEwithin(subset(data.peaks, component == "P1" & var == "peak.lat"), "value", withinvars = c("size", "cont", "emo"), idvar = "participant")
kable(summary.P1.peaklat, digits = 2)

# pirateplot
pirateplot(
  formula = value ~ emo + size + cont, # dependent~independent variables
  data = subset(data.peaks, component == "P1" & var == "peak.lat"), # data frame
  main = "P1 peak latency", # main title
  xlim = NULL, # x-axis: limits
  xlab = "", # x-axis: label
  ylim = c(60, 150), # y-axis: limits
  ylab = "time (ms)", # y-axis: label
  inf.method = "hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
  inf.within = "participant", # ID variable in within-subject designs
  hdi.iter = 5000, # number of iterations for 95% HDI
  cap.beans = TRUE, # max and min values of bean densities are capped at the limits found in the data
  pal = pirateplot.palette
) # color palette
```

```{r P1_peaklat_models}
# preallocate matrices with all BFs
compare.P1.peaklat.BF <- matrix(NA, 6, length(scaling.factor)) # BFs
compare.P1.peaklat.perc.err <- matrix(NA, 6, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  ### main effects of size and emotion
  # P1.peaklat.sizeplusemo.BF <- lmBF(value~size+emo, # formula
  #                                   subset(data.peaks, component=="P1" & var=="peak.lat"), # data
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peaklat.sizeplusemo.BF, file=paste0(wd, "/models/P1_peaklat_sizeplusemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.sizeplusemo.BF <- readRDS(paste0(wd, "/models/P1_peaklat_sizeplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size and emotion
  # P1.peaklat.sizebyemo.BF <- lmBF(value~size*emo, # formula
  #                                 subset(data.peaks, component=="P1" & var=="peak.lat"), # data
  #                                 whichRandom=c("participant", "word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peaklat.sizebyemo.BF, file=paste0(wd, "/models/P1_peaklat_sizebyemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.sizebyemo.BF <- readRDS(paste0(wd, "/models/P1_peaklat_sizebyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of contrast and emotion
  # P1.peaklat.contplusemo.BF <- lmBF(value~cont+emo, # formula
  #                                   subset(data.peaks, component=="P1" & var=="peak.lat"), # data
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peaklat.contplusemo.BF, file=paste0(wd, "/models/P1_peaklat_contplusemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.contplusemo.BF <- readRDS(paste0(wd, "/models/P1_peaklat_contplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of contrast and emotion
  # P1.peaklat.contbyemo.BF <- lmBF(value~cont*emo, # formula
  #                                 subset(data.peaks, component=="P1" & var=="peak.lat"), # data
  #                                 whichRandom=c("participant", "word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peaklat.contbyemo.BF, file=paste0(wd, "/models/P1_peaklat_contbyemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.contbyemo.BF <- readRDS(paste0(wd, "/models/P1_peaklat_contbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of size, contrast, and emotion
  # P1.peaklat.sizepluscontplusemo.BF <- lmBF(value~size+cont+emo, # formula
  #                                           subset(data.peaks, component=="P1" & var=="peak.lat"), # data
  #                                           whichRandom=c("participant", "word"), # random effects
  #                                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                           rscaleCont="medium", # prior scale for standardized slopes
  #                                           iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peaklat.sizepluscontplusemo.BF, file=paste0(wd, "/models/P1_peaklat_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.sizepluscontplusemo.BF <- readRDS(paste0(wd, "/models/P1_peaklat_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size, contrast, and emotion
  # P1.peaklat.sizebycontbyemo.BF <- lmBF(value~size*cont*emo, # formula
  #                                       subset(data.peaks, component=="P1" & var=="peak.lat"), # data
  #                                       whichRandom=c("participant", "word"), # random effects
  #                                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                       rscaleCont="medium", # prior scale for standardized slopes
  #                                       iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peaklat.sizebycontbyemo.BF, file=paste0(wd, "/models/P1_peaklat_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.sizebycontbyemo.BF <- readRDS(paste0(wd, "/models/P1_peaklat_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.P1.peaklat.BF[, k] <- c(
    exp(P1.peaklat.sizeplusemo.BF@bayesFactor$bf[1]),
    exp(P1.peaklat.sizebyemo.BF@bayesFactor$bf[1]),
    exp(P1.peaklat.contplusemo.BF@bayesFactor$bf[1]),
    exp(P1.peaklat.contbyemo.BF@bayesFactor$bf[1]),
    exp(P1.peaklat.sizepluscontplusemo.BF@bayesFactor$bf[1]),
    exp(P1.peaklat.sizebycontbyemo.BF@bayesFactor$bf[1])
  )
  # percentage of error
  compare.P1.peaklat.perc.err[, k] <- c(
    P1.peaklat.sizeplusemo.BF@bayesFactor$error[1] * 100,
    P1.peaklat.sizebyemo.BF@bayesFactor$error[1] * 100,
    P1.peaklat.contplusemo.BF@bayesFactor$error[1] * 100,
    P1.peaklat.contbyemo.BF@bayesFactor$error[1] * 100,
    P1.peaklat.sizepluscontplusemo.BF@bayesFactor$error[1] * 100,
    P1.peaklat.sizebycontbyemo.BF@bayesFactor$error[1] * 100
  )
}

# summary confirmatory analysis
compare.P1.peaklat <- data.frame(
  "model" = c("size + emo", "size x emo", "contr + emo", "cont x emo", "size + cont + emo", "size x cont x emo"),
  "nar" = compare.P1.peaklat.BF[, 1], "nar.p.err" = compare.P1.peaklat.perc.err[, 1],
  "med" = compare.P1.peaklat.BF[, 2], "med.p.err" = compare.P1.peaklat.perc.err[, 2],
  "wid" = compare.P1.peaklat.BF[, 3], "wid.p.err" = compare.P1.peaklat.perc.err[, 3]
)
compare.P1.peaklat <- compare.P1.peaklat[order(compare.P1.peaklat$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.P1.peaklat, scientific = TRUE), digits = 2)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.P1.peaklat[1, 4]<1, "null", as.character(compare.P1.peaklat[1, 1]))` ought to be preferred.   
The best model (`r as.character(compare.P1.peaklat[1, 1])`) explains the observed data `r ifelse(compare.P1.peaklat[1, 4]>1, compare.P1.peaklat[1, 4]/compare.P1.peaklat[2, 4], 1/compare.P1.peaklat[1, 4])` times better than the second best model (`r as.character(compare.P1.peaklat[2, 1])`).   

### Paired comparisons

```{r P1_peaklat_posthoc}
# interactions of interest (i.e., always negative vs. neutral)
P1.peaklat.posthocBF <- subset(data.peaks, component == "P1" & var == "peak.lat") %>% # data frame
  select(participant, condition, value) %>% # select only variables of interest
  split(.$condition) # split according to condition

compare.P1.peaklat.posthocBF <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.peaklat.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # large, dark, negative vs. neutral
  # P1.peaklat.posthocBF.large.dark.negVSneut <- ttestBF(P1.peaklat.posthocBF$negativeLargeDark$value, # first condition
  #                                                      P1.peaklat.posthocBF$neutralLargeDark$value, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peaklat.posthocBF.large.dark.negVSneut, file=paste0(wd, "/models/P1_peaklat_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd, "/models/P1_peaklat_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, dark, negative vs. neutral
  # P1.peaklat.posthocBF.small.dark.negVSneut <- ttestBF(P1.peaklat.posthocBF$negativeSmallDark$value, # first condition
  #                                                      P1.peaklat.posthocBF$neutralSmallDark$value, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peaklat.posthocBF.small.dark.negVSneut, file=paste0(wd, "/models/P1_peaklat_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd, "/models/P1_peaklat_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # large, bright, negative vs. neutral
  # P1.peaklat.posthocBF.large.bright.negVSneut <- ttestBF(P1.peaklat.posthocBF$negativeLargeBright$value, # first condition
  #                                                P1.peaklat.posthocBF$neutralLargeBright$value, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peaklat.posthocBF.large.bright.negVSneut, file=paste0(wd, "/models/P1_peaklat_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd, "/models/P1_peaklat_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, bright, negative vs. neutral
  # P1.peaklat.posthocBF.small.bright.negVSneut <- ttestBF(P1.peaklat.posthocBF$negativeSmallBright$value, # first condition
  #                                                P1.peaklat.posthocBF$neutralSmallBright$value, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peaklat.posthocBF.small.bright.negVSneut, file=paste0(wd, "/models/P1_peaklat_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd, "/models/P1_peaklat_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  ### model comparison
  compare.P1.peaklat.posthocBF[, k] <- c(
    exp(P1.peaklat.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
    exp(P1.peaklat.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
    exp(P1.peaklat.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
    exp(P1.peaklat.posthocBF.small.bright.negVSneut@bayesFactor$bf[1])
  )

  # percentage of error
  compare.P1.peaklat.posthocBF.perc.err[, k] <- c(
    P1.peaklat.posthocBF.large.dark.negVSneut@bayesFactor$error[1] * 100,
    P1.peaklat.posthocBF.small.dark.negVSneut@bayesFactor$error[1] * 100,
    P1.peaklat.posthocBF.large.bright.negVSneut@bayesFactor$error[1] * 100,
    P1.peaklat.posthocBF.small.bright.negVSneut@bayesFactor$error[1] * 100
  )
}

# summary
compare.P1.peaklat.posthocBF <- data.frame(
  "comparison" = c("large.dark.negVSneut", "small.dark.negVSneut", "large.bright.negVSneut", "small.bright.negVSneut"),
  "nar" = compare.P1.peaklat.posthocBF[, 1], "nar.p.err" = compare.P1.peaklat.posthocBF.perc.err[, 1],
  "med" = compare.P1.peaklat.posthocBF[, 2], "med.p.err" = compare.P1.peaklat.posthocBF.perc.err[, 2],
  "wid" = compare.P1.peaklat.posthocBF[, 3], "wid.p.err" = compare.P1.peaklat.posthocBF.perc.err[, 3]
)
kable(format(compare.P1.peaklat.posthocBF, scientific = TRUE), digits = 2)
```

Follow-up contrasts reveal that the effect of *emotion* does not explain changes in P1 peak latency.

### Exploratory model selection

```{r P1_peaklat_expl_modelselect}
# preallocate matrices with all BFs
compare.P1.peaklat.anovaBF.temp <- matrix(NA, 7, length(scaling.factor)) # BFs
compare.P1.peaklat.anovaBF.perc.err.temp <- matrix(NA, 7, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # How important is each effect/interaction if we remove it from the full model?
  # P1.peaklat.anovaBF <- anovaBF(value~size*cont*emo, # formula
  #                       subset(data.peaks, component=="P1" & var=="peak.lat"), # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant", "word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peaklat.anovaBF, file=paste0(wd, "/models/P1_peaklat_anovaBF_", scaling.factor[k], ".rds")) # save model
  P1.peaklat.anovaBF <- readRDS(paste0(wd, "/models/P1_peaklat_anovaBF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.P1.peaklat.anovaBF.temp[, k] <- exp(P1.peaklat.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.P1.peaklat.anovaBF.perc.err.temp[, k] <- P1.peaklat.anovaBF@bayesFactor$error * 100
}

# summary exploratory analysis
compare.P1.peaklat.anovaBF <- data.frame(
  "omit from full model" = c("cont:emo:size", "cont:emo", "emo:size", "cont:size", "emo", "cont", "size"),
  "nar" = compare.P1.peaklat.anovaBF.temp[, 1], "nar.p.err" = compare.P1.peaklat.anovaBF.perc.err.temp[, 1],
  "med" = compare.P1.peaklat.anovaBF.temp[, 2], "med.p.err" = compare.P1.peaklat.anovaBF.perc.err.temp[, 2],
  "wid" = compare.P1.peaklat.anovaBF.temp[, 3], "wid.p.err" = compare.P1.peaklat.anovaBF.perc.err.temp[, 3]
)
compare.P1.peaklat.anovaBF <- compare.P1.peaklat.anovaBF[order(compare.P1.peaklat.anovaBF$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.P1.peaklat.anovaBF, scientific = TRUE), digits = 2)
```

Exploratory analyses suggest that omitting *emotion* from the full model improves fitting by `r compare.P1.peaklat.anovaBF$med[1]` times. Removing *size*, *size x contrast x emotion*, *size x emotion*, and *contrast x emotion* also improves fitting by `r compare.P1.peaklat.anovaBF$med[2]`, `r compare.P1.peaklat.anovaBF$med[3]`, `r compare.P1.peaklat.anovaBF$med[4]`, and `r compare.P1.peaklat.anovaBF$med[5]` times, respectively.   
Conversely, omitting  *contrast x size* lowers the explanatory value of the resulting model by `r 1/compare.P1.peaklat.anovaBF$med[6]` times. Finally, omitting the factor *contrast* is maximally detrimental, as it would lower the explanatory value of the resulting model by `r 1/compare.P1.peaklat.anovaBF$med[7]` times.

## N1

### Peak amplitude

Peak amplitude: negative value larger than the 3 points (~10 ms at 256 Hz sampling rate) on either side of the peak.   
Time window: 150-260 ms post-stimulus onset.   
Electrode cluster: TP7 P7 P9 TP8 P8 P10.

```{r N1_peakamp_pirateplot}
# summarize data
summary.N1.peakamp <- summarySEwithin(subset(data.peaks, component == "N1" & var == "peak.amp"), "value", withinvars = c("size", "cont", "emo"), idvar = "participant")
kable(summary.N1.peakamp, digits = 2)

# pirateplot
pirateplot(
  formula = value ~ emo + size + cont, # dependent~independent variables
  data = subset(data.peaks, component == "N1" & var == "peak.amp"), # data frame
  main = "N1 peak amplitude", # main title
  xlim = NULL, # x-axis: limits
  xlab = "", # x-axis: label
  ylim = c(-10, 3), # y-axis: limits
  ylab = expression(paste("amplitude (", mu, "V)")), # y-axis: label
  inf.method = "hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
  inf.within = "participant", # ID variable in within-subject designs
  hdi.iter = 5000, # number of iterations for 95% HDI
  cap.beans = TRUE, # max and min values of bean densities are capped at the limits found in the data
  pal = pirateplot.palette
) # color palette
```

```{r N1_peakamp_models}
# preallocate matrices with all BFs
compare.N1.peakamp.BF <- matrix(NA, 6, length(scaling.factor)) # BFs
compare.N1.peakamp.perc.err <- matrix(NA, 6, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  ### main effects of size and emotion
  # N1.peakamp.sizeplusemo.BF <- lmBF(value~size+emo, # formula
  #                                   subset(data.peaks, component=="N1" & var=="peak.amp"), # data
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peakamp.sizeplusemo.BF, file=paste0(wd, "/models/N1_peakamp_sizeplusemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.sizeplusemo.BF <- readRDS(paste0(wd, "/models/N1_peakamp_sizeplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size and emotion
  # N1.peakamp.sizebyemo.BF <- lmBF(value~size*emo, # formula
  #                                 subset(data.peaks, component=="N1" & var=="peak.amp"), # data
  #                                 whichRandom=c("participant", "word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peakamp.sizebyemo.BF, file=paste0(wd, "/models/N1_peakamp_sizebyemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.sizebyemo.BF <- readRDS(paste0(wd, "/models/N1_peakamp_sizebyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of contrast and emotion
  # N1.peakamp.contplusemo.BF <- lmBF(value~cont+emo, # formula
  #                                   subset(data.peaks, component=="N1" & var=="peak.amp"), # data
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peakamp.contplusemo.BF, file=paste0(wd, "/models/N1_peakamp_contplusemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.contplusemo.BF <- readRDS(paste0(wd, "/models/N1_peakamp_contplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of contrast and emotion
  # N1.peakamp.contbyemo.BF <- lmBF(value~cont*emo, # formula
  #                                 subset(data.peaks, component=="N1" & var=="peak.amp"), # data
  #                                 whichRandom=c("participant", "word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peakamp.contbyemo.BF, file=paste0(wd, "/models/N1_peakamp_contbyemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.contbyemo.BF <- readRDS(paste0(wd, "/models/N1_peakamp_contbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of size, contrast, and emotion
  # N1.peakamp.sizepluscontplusemo.BF <- lmBF(value~size+cont+emo, # formula
  #                                           subset(data.peaks, component=="N1" & var=="peak.amp"), # data
  #                                           whichRandom=c("participant", "word"), # random effects
  #                                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                           rscaleCont="medium", # prior scale for standardized slopes
  #                                           iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peakamp.sizepluscontplusemo.BF, file=paste0(wd, "/models/N1_peakamp_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.sizepluscontplusemo.BF <- readRDS(paste0(wd, "/models/N1_peakamp_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size, contrast, and emotion
  # N1.peakamp.sizebycontbyemo.BF <- lmBF(value~size*cont*emo, # formula
  #                                       subset(data.peaks, component=="N1" & var=="peak.amp"), # data
  #                                       whichRandom=c("participant", "word"), # random effects
  #                                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                       rscaleCont="medium", # prior scale for standardized slopes
  #                                       iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peakamp.sizebycontbyemo.BF, file=paste0(wd, "/models/N1_peakamp_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.sizebycontbyemo.BF <- readRDS(paste0(wd, "/models/N1_peakamp_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.N1.peakamp.BF[, k] <- c(
    exp(N1.peakamp.sizeplusemo.BF@bayesFactor$bf[1]),
    exp(N1.peakamp.sizebyemo.BF@bayesFactor$bf[1]),
    exp(N1.peakamp.contplusemo.BF@bayesFactor$bf[1]),
    exp(N1.peakamp.contbyemo.BF@bayesFactor$bf[1]),
    exp(N1.peakamp.sizepluscontplusemo.BF@bayesFactor$bf[1]),
    exp(N1.peakamp.sizebycontbyemo.BF@bayesFactor$bf[1])
  )
  # percentage of error
  compare.N1.peakamp.perc.err[, k] <- c(
    N1.peakamp.sizeplusemo.BF@bayesFactor$error[1] * 100,
    N1.peakamp.sizebyemo.BF@bayesFactor$error[1] * 100,
    N1.peakamp.contplusemo.BF@bayesFactor$error[1] * 100,
    N1.peakamp.contbyemo.BF@bayesFactor$error[1] * 100,
    N1.peakamp.sizepluscontplusemo.BF@bayesFactor$error[1] * 100,
    N1.peakamp.sizebycontbyemo.BF@bayesFactor$error[1] * 100
  )
}

# summary confirmatory analysis
compare.N1.peakamp <- data.frame(
  "model" = c("size + emo", "size x emo", "contr + emo", "cont x emo", "size + cont + emo", "size x cont x emo"),
  "nar" = compare.N1.peakamp.BF[, 1], "nar.p.err" = compare.N1.peakamp.perc.err[, 1],
  "med" = compare.N1.peakamp.BF[, 2], "med.p.err" = compare.N1.peakamp.perc.err[, 2],
  "wid" = compare.N1.peakamp.BF[, 3], "wid.p.err" = compare.N1.peakamp.perc.err[, 3]
)
compare.N1.peakamp <- compare.N1.peakamp[order(compare.N1.peakamp$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.N1.peakamp, scientific = TRUE), digits = 2)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.N1.peakamp[1, 4]<1, "null", as.character(compare.N1.peakamp[1, 1]))` ought to be preferred.   
The best model (`r as.character(compare.N1.peakamp[1, 1])`) explains the observed data `r ifelse(compare.N1.peakamp[1, 4]>1, compare.N1.peakamp[1, 4]/compare.N1.peakamp[2, 4], 1/compare.N1.peakamp[1, 4])` times better than the second best model (`r as.character(compare.N1.peakamp[2, 1])`).   

### Paired comparisons

```{r N1_peakamp_posthoc}
# interactions of interest (i.e., always negative vs. neutral)
N1.peakamp.posthocBF <- subset(data.peaks, component == "N1" & var == "peak.amp") %>% # data frame
  select(participant, condition, value) %>% # select only variables of interest
  split(.$condition) # split according to condition

compare.N1.peakamp.posthocBF <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.peakamp.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # large, dark, negative vs. neutral
  # N1.peakamp.posthocBF.large.dark.negVSneut <- ttestBF(N1.peakamp.posthocBF$negativeLargeDark$value, # first condition
  #                                                      N1.peakamp.posthocBF$neutralLargeDark$value, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.peakamp.posthocBF.large.dark.negVSneut, file=paste0(wd, "/models/N1_peakamp_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd, "/models/N1_peakamp_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, dark, negative vs. neutral
  # N1.peakamp.posthocBF.small.dark.negVSneut <- ttestBF(N1.peakamp.posthocBF$negativeSmallDark$value, # first condition
  #                                                      N1.peakamp.posthocBF$neutralSmallDark$value, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.peakamp.posthocBF.small.dark.negVSneut, file=paste0(wd, "/models/N1_peakamp_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd, "/models/N1_peakamp_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # large, bright, negative vs. neutral
  # N1.peakamp.posthocBF.large.bright.negVSneut <- ttestBF(N1.peakamp.posthocBF$negativeLargeBright$value, # first condition
  #                                                N1.peakamp.posthocBF$neutralLargeBright$value, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.peakamp.posthocBF.large.bright.negVSneut, file=paste0(wd, "/models/N1_peakamp_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd, "/models/N1_peakamp_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, bright, negative vs. neutral
  # N1.peakamp.posthocBF.small.bright.negVSneut <- ttestBF(N1.peakamp.posthocBF$negativeSmallBright$value, # first condition
  #                                                N1.peakamp.posthocBF$neutralSmallBright$value, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.peakamp.posthocBF.small.bright.negVSneut, file=paste0(wd, "/models/N1_peakamp_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd, "/models/N1_peakamp_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  ### model comparison
  compare.N1.peakamp.posthocBF[, k] <- c(
    exp(N1.peakamp.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
    exp(N1.peakamp.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
    exp(N1.peakamp.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
    exp(N1.peakamp.posthocBF.small.bright.negVSneut@bayesFactor$bf[1])
  )

  # percentage of error
  compare.N1.peakamp.posthocBF.perc.err[, k] <- c(
    N1.peakamp.posthocBF.large.dark.negVSneut@bayesFactor$error[1] * 100,
    N1.peakamp.posthocBF.small.dark.negVSneut@bayesFactor$error[1] * 100,
    N1.peakamp.posthocBF.large.bright.negVSneut@bayesFactor$error[1] * 100,
    N1.peakamp.posthocBF.small.bright.negVSneut@bayesFactor$error[1] * 100
  )
}

# summary
compare.N1.peakamp.posthocBF <- data.frame(
  "comparison" = c("large.dark.negVSneut", "small.dark.negVSneut", "large.bright.negVSneut", "small.bright.negVSneut"),
  "nar" = compare.N1.peakamp.posthocBF[, 1], "nar.p.err" = compare.N1.peakamp.posthocBF.perc.err[, 1],
  "med" = compare.N1.peakamp.posthocBF[, 2], "med.p.err" = compare.N1.peakamp.posthocBF.perc.err[, 2],
  "wid" = compare.N1.peakamp.posthocBF[, 3], "wid.p.err" = compare.N1.peakamp.posthocBF.perc.err[, 3]
)
kable(format(compare.N1.peakamp.posthocBF, scientific = TRUE), digits = 2)
```

Follow-up contrasts reveal that the effect of *emotion* does not explain changes in N1 peak amplitude.

### Exploratory model selection

```{r N1_peakamp_expl_modelselect}
# preallocate matrices with all BFs
compare.N1.peakamp.anovaBF.temp <- matrix(NA, 7, length(scaling.factor)) # BFs
compare.N1.peakamp.anovaBF.perc.err.temp <- matrix(NA, 7, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # How important is each effect/interaction if we remove it from the full model?
  # N1.peakamp.anovaBF <- anovaBF(value~size*cont*emo, # formula
  #                       subset(data.peaks, component=="N1" & var=="peak.amp"), # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant", "word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peakamp.anovaBF, file=paste0(wd, "/models/N1_peakamp_anovaBF_", scaling.factor[k], ".rds")) # save model
  N1.peakamp.anovaBF <- readRDS(paste0(wd, "/models/N1_peakamp_anovaBF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.N1.peakamp.anovaBF.temp[, k] <- exp(N1.peakamp.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.N1.peakamp.anovaBF.perc.err.temp[, k] <- N1.peakamp.anovaBF@bayesFactor$error * 100
}

# summary exploratory analysis
compare.N1.peakamp.anovaBF <- data.frame(
  "omit from full model" = c("cont:emo:size", "cont:emo", "emo:size", "cont:size", "emo", "cont", "size"),
  "nar" = compare.N1.peakamp.anovaBF.temp[, 1], "nar.p.err" = compare.N1.peakamp.anovaBF.perc.err.temp[, 1],
  "med" = compare.N1.peakamp.anovaBF.temp[, 2], "med.p.err" = compare.N1.peakamp.anovaBF.perc.err.temp[, 2],
  "wid" = compare.N1.peakamp.anovaBF.temp[, 3], "wid.p.err" = compare.N1.peakamp.anovaBF.perc.err.temp[, 3]
)
compare.N1.peakamp.anovaBF <- compare.N1.peakamp.anovaBF[order(compare.N1.peakamp.anovaBF$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.N1.peakamp.anovaBF, scientific = TRUE), digits = 2)
```

Exploratory analyses suggest that omitting *emotion* from the full model improves fitting by `r compare.N1.peakamp.anovaBF$med[1]` times. Removing *contrast x emotion*, *size x emotion*, and *size x contrast x emotion* also improves fitting by `r compare.N1.peakamp.anovaBF$med[2]`, `r compare.N1.peakamp.anovaBF$med[3]`, and `r compare.N1.peakamp.anovaBF$med[4]` times, respectively.   
Conversely, omitting  *contrast x size* or *size* lowers the explanatory value of the resulting model by `r 1/compare.N1.peakamp.anovaBF$med[5]` and `r 1/compare.N1.peakamp.anovaBF$med[6]` times, respectively. Finally, omitting the factor *contrast* is maximally detrimental, as it would lower the explanatory value of the resulting model by `r 1/compare.N1.peakamp.anovaBF$med[7]` times.

### Peak latency

Peak latency: time (in ms) of the positive value larger than the 3 points (~10 ms at 256 Hz sampling rate) on either side of the peak.   
Time window: 150-260 ms post-stimulus onset.   
Electrode cluster: TP7 P7 P9 TP8 P8 P10.

```{r N1_peaklat_pirateplot}
# summarize data
summary.N1.peaklat <- summarySEwithin(subset(data.peaks, component == "N1" & var == "peak.lat"), "value", withinvars = c("size", "cont", "emo"), idvar = "participant")
kable(summary.N1.peaklat, digits = 2)

# pirateplot
pirateplot(
  formula = value ~ emo + size + cont, # dependent~independent variables
  data = subset(data.peaks, component == "N1" & var == "peak.lat"), # data frame
  main = "N1 peak latency", # main title
  xlim = NULL, # x-axis: limits
  xlab = "", # x-axis: label
  ylim = c(150, 260), # y-axis: limits
  ylab = "time (ms)", # y-axis: label
  inf.method = "hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
  inf.within = "participant", # ID variable in within-subject designs
  hdi.iter = 5000, # number of iterations for 95% HDI
  cap.beans = TRUE, # max and min values of bean densities are capped at the limits found in the data
  pal = pirateplot.palette
) # color palette
```

```{r N1_peaklat_models}
# preallocate matrices with all BFs
compare.N1.peaklat.BF <- matrix(NA, 6, length(scaling.factor)) # BFs
compare.N1.peaklat.perc.err <- matrix(NA, 6, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  ### main effects of size and emotion
  # N1.peaklat.sizeplusemo.BF <- lmBF(value~size+emo, # formula
  #                                   subset(data.peaks, component=="N1" & var=="peak.lat"), # data
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peaklat.sizeplusemo.BF, file=paste0(wd, "/models/N1_peaklat_sizeplusemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.sizeplusemo.BF <- readRDS(paste0(wd, "/models/N1_peaklat_sizeplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size and emotion
  # N1.peaklat.sizebyemo.BF <- lmBF(value~size*emo, # formula
  #                                 subset(data.peaks, component=="N1" & var=="peak.lat"), # data
  #                                 whichRandom=c("participant", "word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peaklat.sizebyemo.BF, file=paste0(wd, "/models/N1_peaklat_sizebyemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.sizebyemo.BF <- readRDS(paste0(wd, "/models/N1_peaklat_sizebyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of contrast and emotion
  # N1.peaklat.contplusemo.BF <- lmBF(value~cont+emo, # formula
  #                                   subset(data.peaks, component=="N1" & var=="peak.lat"), # data
  #                                   whichRandom=c("participant", "word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peaklat.contplusemo.BF, file=paste0(wd, "/models/N1_peaklat_contplusemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.contplusemo.BF <- readRDS(paste0(wd, "/models/N1_peaklat_contplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of contrast and emotion
  # N1.peaklat.contbyemo.BF <- lmBF(value~cont*emo, # formula
  #                                 subset(data.peaks, component=="N1" & var=="peak.lat"), # data
  #                                 whichRandom=c("participant", "word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peaklat.contbyemo.BF, file=paste0(wd, "/models/N1_peaklat_contbyemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.contbyemo.BF <- readRDS(paste0(wd, "/models/N1_peaklat_contbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### main effects of size, contrast, and emotion
  # N1.peaklat.sizepluscontplusemo.BF <- lmBF(value~size+cont+emo, # formula
  #                                           subset(data.peaks, component=="N1" & var=="peak.lat"), # data
  #                                           whichRandom=c("participant", "word"), # random effects
  #                                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                           rscaleCont="medium", # prior scale for standardized slopes
  #                                           iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peaklat.sizepluscontplusemo.BF, file=paste0(wd, "/models/N1_peaklat_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.sizepluscontplusemo.BF <- readRDS(paste0(wd, "/models/N1_peaklat_sizepluscontplusemo_BF_", scaling.factor[k], ".rds")) # load model

  ### interactive effects of size, contrast, and emotion
  # N1.peaklat.sizebycontbyemo.BF <- lmBF(value~size*cont*emo, # formula
  #                                       subset(data.peaks, component=="N1" & var=="peak.lat"), # data
  #                                       whichRandom=c("participant", "word"), # random effects
  #                                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                       rscaleCont="medium", # prior scale for standardized slopes
  #                                       iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peaklat.sizebycontbyemo.BF, file=paste0(wd, "/models/N1_peaklat_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.sizebycontbyemo.BF <- readRDS(paste0(wd, "/models/N1_peaklat_sizebycontbyemo_BF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.N1.peaklat.BF[, k] <- c(
    exp(N1.peaklat.sizeplusemo.BF@bayesFactor$bf[1]),
    exp(N1.peaklat.sizebyemo.BF@bayesFactor$bf[1]),
    exp(N1.peaklat.contplusemo.BF@bayesFactor$bf[1]),
    exp(N1.peaklat.contbyemo.BF@bayesFactor$bf[1]),
    exp(N1.peaklat.sizepluscontplusemo.BF@bayesFactor$bf[1]),
    exp(N1.peaklat.sizebycontbyemo.BF@bayesFactor$bf[1])
  )
  # percentage of error
  compare.N1.peaklat.perc.err[, k] <- c(
    N1.peaklat.sizeplusemo.BF@bayesFactor$error[1] * 100,
    N1.peaklat.sizebyemo.BF@bayesFactor$error[1] * 100,
    N1.peaklat.contplusemo.BF@bayesFactor$error[1] * 100,
    N1.peaklat.contbyemo.BF@bayesFactor$error[1] * 100,
    N1.peaklat.sizepluscontplusemo.BF@bayesFactor$error[1] * 100,
    N1.peaklat.sizebycontbyemo.BF@bayesFactor$error[1] * 100
  )
}

# summary confirmatory analysis
compare.N1.peaklat <- data.frame(
  "model" = c("size + emo", "size x emo", "contr + emo", "cont x emo", "size + cont + emo", "size x cont x emo"),
  "nar" = compare.N1.peaklat.BF[, 1], "nar.p.err" = compare.N1.peaklat.perc.err[, 1],
  "med" = compare.N1.peaklat.BF[, 2], "med.p.err" = compare.N1.peaklat.perc.err[, 2],
  "wid" = compare.N1.peaklat.BF[, 3], "wid.p.err" = compare.N1.peaklat.perc.err[, 3]
)
compare.N1.peaklat <- compare.N1.peaklat[order(compare.N1.peaklat$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.N1.peaklat, scientific = TRUE), digits = 2)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.N1.peaklat[1, 4]<1, "null", as.character(compare.N1.peaklat[1, 1]))` ought to be preferred.   
The best model (`r as.character(compare.N1.peaklat[1, 1])`) explains the observed data `r ifelse(compare.N1.peaklat[1, 4]>1, compare.N1.peaklat[1, 4]/compare.N1.peaklat[2, 4], 1/compare.N1.peaklat[1, 4])` times better than the second best model (`r as.character(compare.N1.peaklat[2, 1])`).   

### Paired comparisons

```{r N1_peaklat_posthoc}
# interactions of interest (i.e., always negative vs. neutral)
N1.peaklat.posthocBF <- subset(data.peaks, component == "N1" & var == "peak.lat") %>% # data frame
  select(participant, condition, value) %>% # select only variables of interest
  split(.$condition) # split according to condition

compare.N1.peaklat.posthocBF <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.peaklat.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor)) # preallocate matrix with all % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # large, dark, negative vs. neutral
  # N1.peaklat.posthocBF.large.dark.negVSneut <- ttestBF(N1.peaklat.posthocBF$negativeLargeDark$value, # first condition
  #                                                      N1.peaklat.posthocBF$neutralLargeDark$value, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.peaklat.posthocBF.large.dark.negVSneut, file=paste0(wd, "/models/N1_peaklat_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd, "/models/N1_peaklat_posthocBF_large_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, dark, negative vs. neutral
  # N1.peaklat.posthocBF.small.dark.negVSneut <- ttestBF(N1.peaklat.posthocBF$negativeSmallDark$value, # first condition
  #                                                      N1.peaklat.posthocBF$neutralSmallDark$value, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.peaklat.posthocBF.small.dark.negVSneut, file=paste0(wd, "/models/N1_peaklat_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd, "/models/N1_peaklat_posthocBF_small_dark_negVSneut_", scaling.factor[k], ".rds")) # load model

  # large, bright, negative vs. neutral
  # N1.peaklat.posthocBF.large.bright.negVSneut <- ttestBF(N1.peaklat.posthocBF$negativeLargeBright$value, # first condition
  #                                                N1.peaklat.posthocBF$neutralLargeBright$value, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.peaklat.posthocBF.large.bright.negVSneut, file=paste0(wd, "/models/N1_peaklat_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd, "/models/N1_peaklat_posthocBF_large_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  # small, bright, negative vs. neutral
  # N1.peaklat.posthocBF.small.bright.negVSneut <- ttestBF(N1.peaklat.posthocBF$negativeSmallBright$value, # first condition
  #                                                N1.peaklat.posthocBF$neutralSmallBright$value, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.peaklat.posthocBF.small.bright.negVSneut, file=paste0(wd, "/models/N1_peaklat_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd, "/models/N1_peaklat_posthocBF_small_bright_negVSneut_", scaling.factor[k], ".rds")) # load model

  ### model comparison
  compare.N1.peaklat.posthocBF[, k] <- c(
    exp(N1.peaklat.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
    exp(N1.peaklat.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
    exp(N1.peaklat.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
    exp(N1.peaklat.posthocBF.small.bright.negVSneut@bayesFactor$bf[1])
  )

  # percentage of error
  compare.N1.peaklat.posthocBF.perc.err[, k] <- c(
    N1.peaklat.posthocBF.large.dark.negVSneut@bayesFactor$error[1] * 100,
    N1.peaklat.posthocBF.small.dark.negVSneut@bayesFactor$error[1] * 100,
    N1.peaklat.posthocBF.large.bright.negVSneut@bayesFactor$error[1] * 100,
    N1.peaklat.posthocBF.small.bright.negVSneut@bayesFactor$error[1] * 100
  )
}

# summary
compare.N1.peaklat.posthocBF <- data.frame(
  "comparison" = c("large.dark.negVSneut", "small.dark.negVSneut", "large.bright.negVSneut", "small.bright.negVSneut"),
  "nar" = compare.N1.peaklat.posthocBF[, 1], "nar.p.err" = compare.N1.peaklat.posthocBF.perc.err[, 1],
  "med" = compare.N1.peaklat.posthocBF[, 2], "med.p.err" = compare.N1.peaklat.posthocBF.perc.err[, 2],
  "wid" = compare.N1.peaklat.posthocBF[, 3], "wid.p.err" = compare.N1.peaklat.posthocBF.perc.err[, 3]
)
kable(format(compare.N1.peaklat.posthocBF, scientific = TRUE), digits = 2)
```

Follow-up contrasts reveal that the effect of *emotion* does not explain changes in N1 peak latency.

### Exploratory model selection

```{r N1_peaklat_expl_modelselect}
# preallocate matrices with all BFs
compare.N1.peaklat.anovaBF.temp <- matrix(NA, 7, length(scaling.factor)) # BFs
compare.N1.peaklat.anovaBF.perc.err.temp <- matrix(NA, 7, length(scaling.factor)) # % errors

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  # How important is each effect/interaction if we remove it from the full model?
  # N1.peaklat.anovaBF <- anovaBF(value~size*cont*emo, # formula
  #                       subset(data.peaks, component=="N1" & var=="peak.lat"), # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant", "word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(N1.peaklat.anovaBF, file=paste0(wd, "/models/N1_peaklat_anovaBF_", scaling.factor[k], ".rds")) # save model
  N1.peaklat.anovaBF <- readRDS(paste0(wd, "/models/N1_peaklat_anovaBF_", scaling.factor[k], ".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.N1.peaklat.anovaBF.temp[, k] <- exp(N1.peaklat.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.N1.peaklat.anovaBF.perc.err.temp[, k] <- N1.peaklat.anovaBF@bayesFactor$error * 100
}

# summary exploratory analysis
compare.N1.peaklat.anovaBF <- data.frame(
  "omit from full model" = c("cont:emo:size", "cont:emo", "emo:size", "cont:size", "emo", "cont", "size"),
  "nar" = compare.N1.peaklat.anovaBF.temp[, 1], "nar.p.err" = compare.N1.peaklat.anovaBF.perc.err.temp[, 1],
  "med" = compare.N1.peaklat.anovaBF.temp[, 2], "med.p.err" = compare.N1.peaklat.anovaBF.perc.err.temp[, 2],
  "wid" = compare.N1.peaklat.anovaBF.temp[, 3], "wid.p.err" = compare.N1.peaklat.anovaBF.perc.err.temp[, 3]
)
compare.N1.peaklat.anovaBF <- compare.N1.peaklat.anovaBF[order(compare.N1.peaklat.anovaBF$med, decreasing = TRUE), ] # sort according to medium scaling factor (in descending order)
kable(format(compare.N1.peaklat.anovaBF, scientific = TRUE), digits = 2)
```

Exploratory analyses suggest that omitting *emotion* from the full model improves fitting by `r compare.N1.peaklat.anovaBF$med[1]` times. Removing *size x contrast*, *size x emotion*, *size x contrast x emotion*, and *size x emotion* also improves fitting by `r compare.N1.peaklat.anovaBF$med[2]`, `r compare.N1.peaklat.anovaBF$med[3]`, `r compare.N1.peaklat.anovaBF$med[4]`, and `r compare.N1.peaklat.anovaBF$med[5]` times, respectively.   
Conversely, omitting  *size* lowers the explanatory value of the resulting model by `r 1/compare.N1.peaklat.anovaBF$med[6]` times. Finally, omitting the factor *contrast* is maximally detrimental, as it would lower the explanatory value of the resulting model by `r 1/compare.N1.peaklat.anovaBF$med[7]` times.

***
***

