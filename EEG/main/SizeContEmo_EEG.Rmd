---
title: "<center> <h1>***SIZECONTEMO - EEG ANALYSIS***</h1> </center>"
author: '[Antonio Schettino](https://osf.io/zbv65/ "Antonio Schettino")'
date: '`r Sys.Date()`'
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

In this project we will investigate the electrophysiological correlates of the combined processing of basic visual properties (i.e., size and contrast) and the emotional content of simple words. 

```{r setup_environment,echo=FALSE,warning=FALSE,message=FALSE}
# setup work environment
# dev.off() # clear plots (if no plots are present, comment it out or it will throw an error)
cat("\014") # clear console
rm(list=ls()) # clear environment
set.seed(9001) # specify seed for RNG and ensure reproducible results (it's over 9000!)

expname <- "SizeContEmo" # experiment name
expphase <- "main" # experiment phase
wd <- paste0("E:/Experiments/",expname,"/analysis/EEG/",expphase,"/") # work directory
setwd(wd) # set work directory

# use pacman to install and load relevant packages
pacman::p_load("knitr", # dynamic report generation
               "reshape2", # to reshape the data               
               "tidyverse", # install the following packages: ggplot2, tibble, tidyr, readr, purrr, dplyr
               "ggthemes", # more themes for ggplot2
               "viridis", # more color maps
               "Rmisc", # for advanced summary functions
               "akima", # interpolation of irregularly and regularly spaced data
               "scales", # scale functions for visualization
               "mgcv", # general additive (mixed) models and other generalized ridge regression with multiple smoothing parameter estimation
               "grid", # for graphics
               "gridExtra", # extra functions for graphics
               "yarrr", # amazing graphs
               "BayesFactor") # calculate Bayes factors

# setup output
options(width=120,scipen=999,digits=3) # change output width (for better printing), disable scientific notation (default: scipen=0), constrain output to 4 decimals
opts_chunk$set(warning=FALSE,message=FALSE,fig.width=10,fig.height=6) # for each chunk, display the output but not the R code (echo=FALSE), no package warnings (message=FALSE), no package messages (message=FALSE), width and height of all figures

# custom color palettes for graphs
waveforms.palette <- c("#000000","#E69F00","#56B4E9","#009E73","#FFE259","#0072B2","#D55E00","#CC79A7","#999999")
pirateplot.palette <- c("#E69F00","#56B4E9","#009E73","#FFE259","#0072B2","#D55E00","#CC79A7","#999999")

niter <- 100000 # number of MCMC iterations for calculation of Bayes Factors
scaling.factor <- c(.5,.707,1) # scaling factors of JZS prior: narrow, medium, wide
```

# GRAPHS

```{r prepare_topos}
## plot electrode coordinates
electrodeLocs <- read_delim(paste0(wd,"leipzig64_Christopher.locs"), # load electrode locations
                            "\t", # delimiter (tab)
                            col_names=c("chanNo","theta","radius","electrode"), # column names
                            escape_double=FALSE,trim_ws=TRUE)

# convert theta values from degrees to radians
electrodeLocs$radianTheta <- pi/180*electrodeLocs$theta
# calculate Cartesian coordinates
electrodeLocs <- electrodeLocs %>% 
  mutate(x=.$radius*sin(.$radianTheta),
         y=.$radius*cos(.$radianTheta))
electrodeLocs <- electrodeLocs[order(electrodeLocs$electrode),] # sort electrodes in alphabetical orde

# create ggplot theme without axes and background grids
theme_topo <- function(base_size=12) {
  theme_bw(base_size=base_size) %+replace%
    theme(rect=element_blank(),
          line= element_blank(),
          axis.text=element_blank(),
          axis.title=element_blank()) }

# function to draw a circle (the head)
circleFun <- function(center=c(0,0),diameter=1,npoints=100) {
  r=diameter/2
  tt <- seq(0,2*pi,length.out=npoints)
  xx <- center[1]+r*cos(tt)
  yy <- center[2]+r*sin(tt)
  return(data.frame(x=xx,y=yy)) }

headShape <- circleFun(c(0,0),1,npoints=100)
nose <- data.frame(x=c(-0.075,0,.075),y=c(.495,.575,.495))

# # plot electrode coordinates on head
# ggplot(headShape,aes(x,y)) +
#   geom_path() +
#   geom_text(data=electrodeLocs,aes(x,y,label=electrode)) +
#   geom_line(data=nose,aes(x,y)) +
#   theme_topo() +
#   coord_equal()

# prepare topography
# jet.colors <- colorRampPalette(c("#00007F","blue","#007FFF","cyan","#7FFF7F","yellow","#FF7F00","red","#7F0000")) # jet color map
gridRes <- 268 # number of points for each grid dimension, corresponding to the resolution/smoothness of the interpolation
maskRing <- circleFun(diameter=1.42) # create a circle around the outside of the plotting area to mask the jagged edges of the interpolation

grand.avg.topos <- read.csv(paste0(expphase,"_topoEEG.csv"),header=TRUE,check.names=FALSE) # load data (check.names=FALSE eliminates the "X" at the beginning of each timepoint)

grand.avg.topos <- grand.avg.topos %>% # data frame
  # convert to long format
  gather(key=component, # name of new column
         value=amplitude, # value of new column
         -c(participant,bin,electrode)) # keep participants, conditions, and electrode cluster as columns
```

Butterfly plot.

```{r graph_grandavg}
grand.avg.localizer <- read.csv(paste0(expphase,"_grandEEG_localizer.csv"),header=TRUE,check.names=FALSE) # load data (check.names=FALSE eliminates the "X" at the beginning of each timepoint)

grand.avg.localizer <- grand.avg.localizer %>% # data frame
  select(-condition) %>% # drop condition column
  # convert to long format
  gather(key=timepoint, # name of new column
         value=amplitude, # value of new column
         convert=TRUE, # convert time points to numeric
         -c(participant,electrode)) # keep participants and electrodes as columns

# summarized data from each time point
# within-subject 95% CIs, although calculated, will not be used (to improve visualization)
grand.avg.localizer.pointsummary <- grand.avg.localizer %>% # data frame
  summarySEwithin(data=.,measurevar="amplitude",withinvars=c("electrode","timepoint"),idvar="participant") %>% # summary
  mutate(timepoint=as.numeric(levels(timepoint))[timepoint]) # re-convert time points to numeric

# plot
ggplot(grand.avg.localizer.pointsummary,aes(x=timepoint,y=amplitude,group=electrode)) + # basic plot
  geom_line(size=1.2,color="#494847",alpha=.8) + # one line per electrode
  labs(title="grand average collapsed localizer (all electrodes)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,100)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # horizontal reference line
  geom_vline(xintercept=seq(from=-200,to=1000,by=100),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  geom_hline(yintercept=seq(from=-3,to=3,by=1),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  theme_pander(base_size=20,pc="white",lp="none") # custom theme
```

```{r data_grandavg_comps}
grand.avg.comps <- read.csv(paste0(expphase,"_avgERP.csv"),header=TRUE,check.names=FALSE) # load data (check.names=FALSE eliminates the "X" at the beginning of each timepoint)

grand.avg.comps <- grand.avg.comps %>% # data frame
  # convert to long format
  gather(key=timepoint, # name of new column
         value=amplitude, # value of new column
         convert=TRUE, # convert time points to numeric
         -c(participant,elec_cluster,condition)) %>% # keep participants, electrode cluster, and conditions as columns
  # rename levels
  mutate(condition=revalue(condition,c("all "="localizer",
                                       "negative"="negative",
                                       "negative minus neutral"="negative minus neutral",
                                       "negativeLargeBright "="negative large bright",
                                       "negativeLargeDark "="negative large dark",
                                       "negativeSmallBright "="negative small bright",
                                       "negativeSmallDark "="negative small dark",
                                       "neutral"="neutral",
                                       "neutralLargeBright"="neutral large bright",
                                       "neutralLargeDark"="neutral large dark",
                                       "neutralSmallBright"="neutral small bright",
                                       "neutralSmallDark"="neutral small dark")),
         # variable with main effect of size
         size=revalue(condition,c("localizer"=NA,
                                  "negative"=NA,
                                  "negative minus neutral"=NA,
                                  "negative large bright"="large",
                                  "negative large dark"="large",
                                  "negative small bright"="small",
                                  "negative small dark"="small",
                                  "neutral"=NA,
                                  "neutral large bright"="large",
                                  "neutral large dark"="large",
                                  "neutral small bright"="small",
                                  "neutral small dark"="small")),
         # variable with main effect of contrast
         cont=revalue(condition,c("localizer"=NA,
                                  "negative"=NA,
                                  "negative minus neutral"=NA,
                                  "negative large bright"="bright",
                                  "negative large dark"="dark",
                                  "negative small bright"="bright",
                                  "negative small dark"="dark",
                                  "neutral"=NA,
                                  "neutral large bright"="bright",
                                  "neutral large dark"="dark",
                                  "neutral small bright"="bright",
                                  "neutral small dark"="dark")),
         # variable with main effect of emotion
         emo=revalue(condition,c("localizer"=NA,
                                 "negative"=NA,
                                 "negative minus neutral"=NA,
                                 "negative large bright"="negative",
                                 "negative large dark"="negative",
                                 "negative small bright"="negative",
                                 "negative small dark"="negative",
                                 "neutral"=NA,
                                 "neutral large bright"="neutral",
                                 "neutral large dark"="neutral",
                                 "neutral small bright"="neutral",
                                 "neutral small dark"="neutral")))
```

## P1

Amplitude extracted from the following electrode cluster: P7 P9 PO7 O1 O2 PO8 P8 P10.

```{r P1_waveforms}
# summarized data from each time point, including within-subject 95% CIs
P1.grand.avg.comps.pointsummary <- grand.avg.comps %>% # data frame
  filter(elec_cluster=="P1",condition!="negative",condition!="negative minus neutral",condition!="neutral") %>% # filter out useless conditions
  summarySEwithin(data=.,measurevar="amplitude",withinvars=c("condition","timepoint"),idvar="participant") %>% # summary
  mutate(timepoint=as.numeric(levels(timepoint))[timepoint]) # re-convert time points to numeric

# plot waveforms
ggplot(filter(P1.grand.avg.comps.pointsummary,condition!="localizer"),aes(x=timepoint,y=amplitude,group=condition,color=condition)) + # basic plot
  geom_line(aes(color=condition),size=2.5,alpha=.6) + # one line per condition
  # geom_ribbon(data=filter(P1.grand.avg.comps.pointsummary,condition!="localizer"),aes(ymin=amplitude-ci,ymax=amplitude+ci,fill=condition),linetype="dotted",size=.1,alpha=.1) + # 95% CI for all conditions (commented out to improve visualization)
  geom_line(data=filter(P1.grand.avg.comps.pointsummary,condition=="localizer"),size=5) + # add thick black line for localizer
  geom_ribbon(data=filter(P1.grand.avg.comps.pointsummary,condition=="localizer"),aes(ymin=amplitude-ci,ymax=amplitude+ci),linetype="dotted",size=.1,alpha=.3) + # localizer 95% CI
  scale_color_manual(values=waveforms.palette) + # line colors
  scale_fill_manual(values=waveforms.palette,guide=FALSE) + # ribbon colors
  labs(title="P1 (66-148 ms)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,50),limits=c(-100,250)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # horizontal reference line
  geom_vline(xintercept=seq(from=-200,to=1000,by=50),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  geom_hline(yintercept=seq(from=-3,to=3,by=1),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  annotate("rect",xmin=66,xmax=148,ymin=-.5,ymax=3,fill="#c3bfb5",alpha=.3) + # highlight time window used for analysis
  theme_pander(base_size=20,pc="white",lp=c(.25,.8)) # custom theme
```

```{r P1_topo}
P1.topo <- grand.avg.topos %>% # data frame
  filter(component=="P1",bin=="localizer") %>% # select only component and bin of interest 
  summarySEwithin(data=.,measurevar="amplitude",withinvars="electrode",idvar="participant") # summary
P1.topo <- cbind(electrodeLocs,P1.topo[,"amplitude"]) # electrode locations and amplitudes in the same data frame
names(P1.topo)[8] <- "amplitude" # change variable name

# plot topography
amplim <- c(-.7,.7) # min/max amplitude limit
contour.binwidth <- .1 # map contour
splineSmooth <- gam(amplitude~s(x,y,bs='ts'),data=P1.topo)
GAMtopo <- data.frame(expand.grid(x=seq(min(P1.topo$x)*2,
                                        max(P1.topo$x)*2,
                                        length=gridRes),
                                  y=seq(min(P1.topo$y)*2,
                                        max(P1.topo$y)*2,
                                        length=gridRes)))
GAMtopo$amplitude <-  predict(splineSmooth,GAMtopo,type="response")
GAMtopo$incircle <- (GAMtopo$x)^2+(GAMtopo$y)^2<.7^2
# plot topography
ggplot(GAMtopo[GAMtopo$incircle,],aes(x,y,fill=amplitude)) +
  geom_raster() +
  stat_contour(aes(z=amplitude),binwidth=contour.binwidth,size=.8,color="black") +
  theme_topo() +
  scale_fill_gradientn(colors=viridis(10),
                       limits=amplim,
                       guide="colorbar",
                       oob=squish) +
  geom_path(data=maskRing,aes(x,y,z=NULL,fill=NULL),color="white",size=6) +
  geom_point(data=P1.topo,
             aes(x,y,fill=NULL)) +
  geom_path(data=nose,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  geom_path(data=headShape,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  ggtitle("P1 (66-148 ms)") + 
  coord_quickmap()
```

## N1

Amplitude extracted from the following electrode cluster: TP7 P7 P9 TP8 P8 P10.

```{r N1_waveforms}
# summarized data from each time point, including within-subject 95% CIs
N1.grand.avg.comps.pointsummary <- grand.avg.comps %>% # data frame
  filter(elec_cluster=="N1",condition!="negative",condition!="negative minus neutral",condition!="neutral") %>% # filter out useless conditions
  summarySEwithin(data=.,measurevar="amplitude",withinvars=c("condition","timepoint"),idvar="participant") %>% # summary
  mutate(timepoint=as.numeric(levels(timepoint))[timepoint]) # re-convert time points to numeric

# plot waveforms
ggplot(filter(N1.grand.avg.comps.pointsummary,condition!="localizer"),aes(x=timepoint,y=amplitude,group=condition,color=condition)) + # basic plot
  geom_line(aes(color=condition),size=2.5,alpha=.6) + # one line per condition
  # geom_ribbon(data=filter(N1.grand.avg.comps.pointsummary,condition!="localizer"),aes(ymin=amplitude-ci,ymax=amplitude+ci,fill=condition),linetype="dotted",size=.1,alpha=.1) + # 95% CI for all conditions (commented out to improve visualization)
  geom_line(data=filter(N1.grand.avg.comps.pointsummary,condition=="localizer"),size=5) + # add thick black line for localizer
  geom_ribbon(data=filter(N1.grand.avg.comps.pointsummary,condition=="localizer"),aes(ymin=amplitude-ci,ymax=amplitude+ci),linetype="dotted",size=.1,alpha=.3) + # localizer 95% CI
  scale_color_manual(values=waveforms.palette) + # line colors
  scale_fill_manual(values=waveforms.palette,guide=FALSE) + # ribbon colors
  labs(title="N1 (150-260 ms)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,50),limits=c(-100,400)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # horizontal reference line
  geom_vline(xintercept=seq(from=-200,to=1000,by=50),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  geom_hline(yintercept=seq(from=-3,to=3,by=1),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  annotate("rect",xmin=150,xmax=260,ymin=-2.5,ymax=1,fill="#c3bfb5",alpha=.3) + # highlight time window used for analysis
  theme_pander(base_size=20,pc="white",lp=c(.25,.8)) # custom theme
```

```{r N1_topo}
N1.topo <- grand.avg.topos %>% # data frame
  filter(component=="N1",bin=="localizer") %>% # select only component and bin of interest 
  summarySEwithin(data=.,measurevar="amplitude",withinvars="electrode",idvar="participant") # summary
N1.topo <- cbind(electrodeLocs,N1.topo[,"amplitude"]) # electrode locations and amplitudes in the same data frame
names(N1.topo)[8] <- "amplitude" # change variable name

# plot topography
amplim <- c(-.4,.4) # min/max amplitude limit
contour.binwidth <- .1 # map contour
splineSmooth <- gam(amplitude~s(x,y,bs='ts'),data=N1.topo)
GAMtopo <- data.frame(expand.grid(x=seq(min(N1.topo$x)*2,
                                        max(N1.topo$x)*2,
                                        length=gridRes),
                                  y=seq(min(N1.topo$y)*2,
                                        max(N1.topo$y)*2,
                                        length=gridRes)))
GAMtopo$amplitude <-  predict(splineSmooth,GAMtopo,type="response")
GAMtopo$incircle <- (GAMtopo$x)^2+(GAMtopo$y)^2<.7^2
# plot topography
ggplot(GAMtopo[GAMtopo$incircle,],aes(x,y,fill=amplitude)) +
  geom_raster() +
  stat_contour(aes(z=amplitude),binwidth=contour.binwidth,size=.8,color="black") +
  theme_topo() +
  scale_fill_gradientn(colors=viridis(10),
                       limits=amplim,
                       guide="colorbar",
                       oob=squish) +
  geom_path(data=maskRing,aes(x,y,z=NULL,fill=NULL),color="white",size=6) +
  geom_point(data=N1.topo,
             aes(x,y,fill=NULL)) +
  geom_path(data=nose,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  geom_path(data=headShape,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  ggtitle("N1 (150-260 ms)") + 
  coord_quickmap()
```

# EPN

Amplitude extracted from the following electrode cluster: P7 P9 PO7 PO3 O1 Oz Iz O2 PO4 PO8 P8 P10.

```{r EPN_waveforms}
# summarized data from each time point, including within-subject 95% CIs
EPN.grand.avg.comps.pointsummary <- grand.avg.comps %>% # data frame
  filter(elec_cluster=="EPN",condition==c("negative","neutral","negative minus neutral")) %>% # filter out useless conditions
  summarySEwithin(data=.,measurevar="amplitude",withinvars=c("condition","timepoint"),idvar="participant") %>% # summary
  mutate(timepoint=as.numeric(levels(timepoint))[timepoint]) # re-convert time points to numeric

# plot waveforms
ggplot(filter(EPN.grand.avg.comps.pointsummary,condition!="negative minus neutral"),aes(x=timepoint,y=amplitude,group=condition,color=condition)) + # basic plot
  geom_line(aes(color=condition),size=2.5,alpha=.6) + # one line per condition
  geom_ribbon(data=filter(EPN.grand.avg.comps.pointsummary,condition!="negative minus neutral"),aes(ymin=amplitude-ci,ymax=amplitude+ci,fill=condition),linetype="dotted",size=.1,alpha=.1) + # 95% CI for all conditions
  geom_line(data=filter(EPN.grand.avg.comps.pointsummary,condition=="negative minus neutral"),size=5) + # add thick black line for localizer
  geom_ribbon(data=filter(EPN.grand.avg.comps.pointsummary,condition=="negative minus neutral"),aes(ymin=amplitude-ci,ymax=amplitude+ci),linetype="dotted",size=.1,alpha=.3) + # localizer 95% CI
  scale_color_manual(values=c("#E69F00","#000000","#56B4E9")) + # line colors
  scale_fill_manual(values=waveforms.palette,guide=FALSE) + # ribbon colors
  labs(title="EPN (300-500 ms)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,50),limits=c(-100,600)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # horizontal reference line
  geom_vline(xintercept=seq(from=-200,to=1000,by=50),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  geom_hline(yintercept=seq(from=-3,to=3,by=1),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  annotate("rect",xmin=300,xmax=500,ymin=-1,ymax=2,fill="#c3bfb5",alpha=.3) + # highlight time window used for analysis
  theme_pander(base_size=20,pc="white",lp=c(.25,.8)) # custom theme
```

```{r EPN_topo}
EPN.topo <- grand.avg.topos %>% # data frame
  filter(component=="EPN",bin=="NegMinNeut") %>% # select only component and bin of interest 
  summarySEwithin(data=.,measurevar="amplitude",withinvars="electrode",idvar="participant") # summary
EPN.topo <- cbind(electrodeLocs,EPN.topo[,"amplitude"]) # electrode locations and amplitudes in the same data frame
names(EPN.topo)[8] <- "amplitude" # change variable name

# plot topography
amplim <- c(-.2,.2) # min/max amplitude limit
contour.binwidth <- .1 # map contour
splineSmooth <- gam(amplitude~s(x,y,bs='ts'),data=EPN.topo)
GAMtopo <- data.frame(expand.grid(x=seq(min(EPN.topo$x)*2,
                                        max(EPN.topo$x)*2,
                                        length=gridRes),
                                  y=seq(min(EPN.topo$y)*2,
                                        max(EPN.topo$y)*2,
                                        length=gridRes)))
GAMtopo$amplitude <-  predict(splineSmooth,GAMtopo,type="response")
GAMtopo$incircle <- (GAMtopo$x)^2+(GAMtopo$y)^2<.7^2
# plot topography
ggplot(GAMtopo[GAMtopo$incircle,],aes(x,y,fill=amplitude)) +
  geom_raster() +
  stat_contour(aes(z=amplitude),binwidth=contour.binwidth,size=.8,color="black") +
  theme_topo() +
  scale_fill_gradientn(colors=viridis(10),
                       limits=amplim,
                       guide="colorbar",
                       oob=squish) +
  geom_path(data=maskRing,aes(x,y,z=NULL,fill=NULL),color="white",size=6) +
  geom_point(data=EPN.topo,
             aes(x,y,fill=NULL)) +
  geom_path(data=nose,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  geom_path(data=headShape,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  ggtitle("EPN (300-500 ms)") + 
  coord_quickmap()
```

# LPP

Amplitude extracted from the following electrode cluster: P1 Pz P2 P4 P6 P8 P10 POz PO4 PO8.

```{r LPP_waveforms}
# summarized data from each time point, including within-subject 95% CIs
LPP.grand.avg.comps.pointsummary <- grand.avg.comps %>% # data frame
  filter(elec_cluster=="LPP",condition!="negative",condition!="negative minus neutral",condition!="neutral") %>% # filter out useless conditions
  summarySEwithin(data=.,measurevar="amplitude",withinvars=c("condition","timepoint"),idvar="participant") %>% # summary
  mutate(timepoint=as.numeric(levels(timepoint))[timepoint]) # re-convert time points to numeric

# plot waveforms
ggplot(filter(LPP.grand.avg.comps.pointsummary,condition!="localizer"),aes(x=timepoint,y=amplitude,group=condition,color=condition)) + # basic plot
  geom_line(aes(color=condition),size=2.5,alpha=.6) + # one line per condition
  # geom_ribbon(data=filter(LPP.grand.avg.comps.pointsummary,condition!="localizer"),aes(ymin=amplitude-ci,ymax=amplitude+ci,fill=condition),linetype="dotted",size=.1,alpha=.1) + # 95% CI for all conditions (commented out to improve visualization)
  geom_line(data=filter(LPP.grand.avg.comps.pointsummary,condition=="localizer"),size=5) + # add thick black line for localizer
  geom_ribbon(data=filter(LPP.grand.avg.comps.pointsummary,condition=="localizer"),aes(ymin=amplitude-ci,ymax=amplitude+ci),linetype="dotted",size=.1,alpha=.3) + # localizer 95% CI
  scale_color_manual(values=waveforms.palette) + # line colors
  scale_fill_manual(values=waveforms.palette,guide=FALSE) + # ribbon colors
  labs(title="LPP (402-684 ms)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,50),limits=c(-100,800)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",color="black",size=1.2,alpha=.8) + # horizontal reference line
  geom_vline(xintercept=seq(from=-200,to=800,by=50),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  geom_hline(yintercept=seq(from=-3,to=3,by=1),linetype="dotted",color="#999999",size=.8,alpha=.5) + # reference lines
  annotate("rect",xmin=402,xmax=684,ymin=-.5,ymax=2.5,fill="#c3bfb5",alpha=.3) + # highlight time window used for analysis
  theme_pander(base_size=20,pc="white",lp=c(.25,.8)) # custom theme
```

```{r LPP_topo}
LPP.topo <- grand.avg.topos %>% # data frame
  filter(component=="LPP",bin=="localizer") %>% # select only component and bin of interest 
  summarySEwithin(data=.,measurevar="amplitude",withinvars="electrode",idvar="participant") # summary
LPP.topo <- cbind(electrodeLocs,LPP.topo[,"amplitude"]) # electrode locations and amplitudes in the same data frame
names(LPP.topo)[8] <- "amplitude" # change variable name

# plot topography
amplim <- c(-.6,.6) # min/max amplitude limit
contour.binwidth <- .1 # map contour
splineSmooth <- gam(amplitude~s(x,y,bs='ts'),data=LPP.topo)
GAMtopo <- data.frame(expand.grid(x=seq(min(LPP.topo$x)*2,
                                        max(LPP.topo$x)*2,
                                        length=gridRes),
                                  y=seq(min(LPP.topo$y)*2,
                                        max(LPP.topo$y)*2,
                                        length=gridRes)))
GAMtopo$amplitude <-  predict(splineSmooth,GAMtopo,type="response")
GAMtopo$incircle <- (GAMtopo$x)^2+(GAMtopo$y)^2<.7^2
# plot topography
ggplot(GAMtopo[GAMtopo$incircle,],aes(x,y,fill=amplitude)) +
  geom_raster() +
  stat_contour(aes(z=amplitude),binwidth=contour.binwidth,size=.8,color="black") +
  theme_topo() +
  scale_fill_gradientn(colors=viridis(10),
                       limits=amplim,
                       guide="colorbar",
                       oob=squish) +
  geom_path(data=maskRing,aes(x,y,z=NULL,fill=NULL),color="white",size=6) +
  geom_point(data=LPP.topo,
             aes(x,y,fill=NULL)) +
  geom_path(data=nose,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  geom_path(data=headShape,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  ggtitle("LPP (402-684 ms)") + 
  coord_quickmap()
```

***
***

# CONFIRMATORY ANALYSIS

```{r data}
data.EEG.trial <- read.csv(paste0(expphase,"_trialEEG.csv"),header=TRUE) # load data
data.EEG.trialWords <- read.csv(paste0(expphase,"_words.csv"),header=TRUE) # load data

data.EEG.trial <- data.EEG.trial %>% # data frame
  mutate(condition=factor(condition), # convert condition numbers as factors
         # variable with main effect of size
         size=revalue(condition,c("1"="large",
                                  "2"="small",
                                  "3"="large",
                                  "4"="small",
                                  "5"="large",
                                  "6"="small",
                                  "7"="large",
                                  "8"="small")),
         size=relevel(size,ref="large"), # re-reference size to large
         # variable with main effect of contrast
         cont=revalue(condition,c("1"="dark",
                                  "2"="dark",
                                  "3"="bright",
                                  "4"="bright",
                                  "5"="dark",
                                  "6"="dark",
                                  "7"="bright",
                                  "8"="bright")),
         cont=relevel(cont,ref="dark"), # re-reference contrast to dark
         # variable with main effect of emotion
         emo=revalue(condition,c("1"="negative",
                                 "2"="negative",
                                 "3"="negative",
                                 "4"="negative",
                                 "5"="neutral",
                                 "6"="neutral",
                                 "7"="neutral",
                                 "8"="neutral")), 
         emo=relevel(emo,ref="neutral"), # re-reference emotion to neutral
         cond=paste(emo,size,cont,sep=" "), # rename condition levels
         word=data.EEG.trialWords[,"word"]) %>% # include words in EEG data frame
  select (-condition) # eliminate unused variable (I tried to recode "condition", but did not work
rm(data.EEG.trialWords) # delete unused data
```

We will calculate and compare the Bayes Factor of different linear mixed-effects models. The random factors are participants and the individual word per trial. Their variance is set as nuisance.   

We will compare (against the null model) the following models:   

1. main effects of size and emotion   
2. interactive effects of size and emotion   
3. main effects of contrast and emotion   
4. interactive effects of contrast and emotion   
5. main effects of size, contrast, and emotion   
6. interactive effects of size, contrast, and emotion   

We will then compare the best competing models to understand which one should be preferred overall.

## P1

```{r P1_pirateplot}
# summarize data
summary.P1 <- summarySEwithin(data.EEG.trial,"P1",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.P1,digits=2)

# P1 graph
# better visualization with averages across trials
summary.P1.plot <- summarySEwithin(data.EEG.trial,"P1",withinvars=c("participant","size","cont","emo"),idvar="word")
pirateplot(formula=P1~emo+size+cont, # dependent~independent variables
           data=summary.P1.plot, # data frame
           main="P1 amplitude", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-4,6), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal=pirateplot.palette) # color palette
```

```{r P1_models}
# preallocate matrices with all BFs
compare.P1.BF <- matrix(NA,6,length(scaling.factor))
compare.P1.anovaBF.temp <- matrix(NA,7,length(scaling.factor))
# preallocate matrices with all % errors
compare.P1.perc.err <- matrix(NA,6,length(scaling.factor))
compare.P1.anovaBF.perc.err.temp <- matrix(NA,7,length(scaling.factor)) 

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### CONFIRMATORY ANALYSES ###
  ### main effects of size and emotion
  # P1.sizeplusemo.BF <- lmBF(P1~size+emo, # formula
  #                           data.EEG.trial, # data
  #                           whichRandom=c("participant","word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(P1.sizeplusemo.BF,file=paste0(wd,"/models/P1_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.sizeplusemo.BF <- readRDS(paste0(wd,"/models/P1_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # P1.sizebyemo.BF <- lmBF(P1~size*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant","word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(P1.sizebyemo.BF,file=paste0(wd,"/models/P1_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.sizebyemo.BF <- readRDS(paste0(wd,"/models/P1_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of contrast and emotion
  # P1.contplusemo.BF <- lmBF(P1~cont+emo,
  #                           data.EEG.trial,
  #                           whichRandom=c("participant","word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(P1.contplusemo.BF,file=paste0(wd,"/models/P1_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.contplusemo.BF <- readRDS(paste0(wd,"/models/P1_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # P1.contbyemo.BF <- lmBF(P1~cont*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant","word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(P1.contbyemo.BF,file=paste0(wd,"/models/P1_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.contbyemo.BF <- readRDS(paste0(wd,"/models/P1_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # P1.sizepluscontplusemo.BF <- lmBF(P1~size+cont+emo,
  #                                   data.EEG.trial,
  #                                   whichRandom=c("participant","word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(P1.sizepluscontplusemo.BF,file=paste0(wd,"/models/P1_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.sizepluscontplusemo.BF <- readRDS(paste0(wd,"/models/P1_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # P1.sizebycontbyemo.BF <- lmBF(P1~size*cont*emo,
  #                               data.EEG.trial,
  #                               whichRandom=c("participant","word"), # random effects
  #                               rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                               rscaleRandom="nuisance", # prior scale for standardized random effects
  #                               rscaleCont="medium", # prior scale for standardized slopes
  #                               iterations=niter) # number of MCMC iterations
  # saveRDS(P1.sizebycontbyemo.BF,file=paste0(wd,"/models/P1_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.sizebycontbyemo.BF <- readRDS(paste0(wd,"/models/P1_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison across scaling factors
  # BFs
  compare.P1.BF[,k] <- c(exp(P1.sizeplusemo.BF@bayesFactor$bf[1]),
                         exp(P1.sizebyemo.BF@bayesFactor$bf[1]),
                         exp(P1.contplusemo.BF@bayesFactor$bf[1]),
                         exp(P1.contbyemo.BF@bayesFactor$bf[1]),
                         exp(P1.sizepluscontplusemo.BF@bayesFactor$bf[1]),
                         exp(P1.sizebycontbyemo.BF@bayesFactor$bf[1]))
  # percentage of error
  compare.P1.perc.err[,k] <- c(P1.sizeplusemo.BF@bayesFactor$error[1]*100,
                               P1.sizebyemo.BF@bayesFactor$error[1]*100,
                               P1.contplusemo.BF@bayesFactor$error[1]*100,
                               P1.contbyemo.BF@bayesFactor$error[1]*100,
                               P1.sizepluscontplusemo.BF@bayesFactor$error[1]*100,
                               P1.sizebycontbyemo.BF@bayesFactor$error[1]*100)

  ### EXPLORATORY ANALYSES ###
  # How important is each effect/interaction if we remove it from the full model?

  # P1.anovaBF <- anovaBF(P1~size*cont*emo, # formula
  #                       data.EEG.trial, # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant","word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(P1.anovaBF,file=paste0(wd,"/models/P1_anovaBF_",scaling.factor[k],".rds")) # save model
  P1.anovaBF <- readRDS(paste0(wd,"/models/P1_anovaBF_",scaling.factor[k],".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.P1.anovaBF.temp[,k] <- exp(P1.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.P1.anovaBF.perc.err.temp[,k] <- P1.anovaBF@bayesFactor$error*100
}

# summary confirmatory analysis
compare.P1 <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
                         "nar"=compare.P1.BF[,1],"nar.p.err"=compare.P1.perc.err[,1],
                         "med"=compare.P1.BF[,2],"med.p.err"=compare.P1.perc.err[,2],
                         "wid"=compare.P1.BF[,3],"wid.p.err"=compare.P1.perc.err[,3])
compare.P1 <- compare.P1[order(compare.P1$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(format(compare.P1,scientific=TRUE),digits=2)

# summary exploratory analysis
compare.P1.anovaBF <- data.frame("omit from full model"=c("cont:emo:size","cont:emo","emo:size","cont:size","emo","cont","size"),
                                 "nar"=compare.P1.anovaBF.temp[,1],"nar.p.err"=compare.P1.anovaBF.perc.err.temp[,1],
                                 "med"=compare.P1.anovaBF.temp[,2],"med.p.err"=compare.P1.anovaBF.perc.err.temp[,2],
                                 "wid"=compare.P1.anovaBF.temp[,3],"wid.p.err"=compare.P1.anovaBF.perc.err.temp[,3])
compare.P1.anovaBF <- compare.P1.anovaBF[order(compare.P1.anovaBF$nar,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.P1[1,4]<1,"null",as.character(compare.P1[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.P1[1,1])`) explains the observed data `r format(ifelse(compare.P1[1,4]>1,compare.P1[1,4]/compare.P1[2,4],1/compare.P1[1,4]),scientific=TRUE)` times better than the second best model (`r as.character(compare.P1[2,1])`).   

### Paired comparisons

```{r P1_posthoc}
# main effects
# size
P1.posthocBF.size <- data.EEG.trial %>% # data frame
  select(participant,size,P1) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="P1",withinvars=c("participant","size")) %>% # summary
  split(.$size) # split according to condition
# contrast
P1.posthocBF.cont <- data.EEG.trial %>% # data frame
  select(participant,cont,P1) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="P1",withinvars=c("participant","cont")) %>% # summary
  split(.$cont) # split according to condition
# emotion
P1.posthocBF.emo <- data.EEG.trial %>% # data frame
  select(participant,emo,P1) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="P1",withinvars=c("participant","emo")) %>% # summary
  split(.$emo) # split according to condition

# interactions of interest (i.e., always negative vs. neutral)
P1.posthocBF <- data.EEG.trial %>% # data frame
  select(participant,condition,P1) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="P1",withinvars=c("participant","condition")) %>% # summary
  split(.$condition) # split according to condition

compare.P1.posthocBF <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.posthocBF.perc.err <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors

  # large vs. small
  # P1.posthocBF.largeVSsmall <- ttestBF(P1.posthocBF.size$large$P1, # first condition
  #                                      P1.posthocBF.size$small$P1, # second condition
  #                                      mu=0, # null hypothesis (mean difference=0)
  #                                      paired=TRUE, # paired sample test
  #                                      iterations=niter, # number of MCMC iterations
  #                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.posthocBF.largeVSsmall,file=paste0(wd,"/models/P1_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # save model
  P1.posthocBF.largeVSsmall <- readRDS(paste0(wd,"/models/P1_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # load model

  # dark vs. bright
  # P1.posthocBF.darkVSbright <- ttestBF(P1.posthocBF.cont$dark$P1, # first condition
  #                                      P1.posthocBF.cont$bright$P1, # second condition
  #                                      mu=0, # null hypothesis (mean difference=0)
  #                                      paired=TRUE, # paired sample test
  #                                      iterations=niter, # number of MCMC iterations
  #                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.posthocBF.darkVSbright,file=paste0(wd,"/models/P1_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # save model
  P1.posthocBF.darkVSbright <- readRDS(paste0(wd,"/models/P1_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # load model

  # negative vs. neutral
  # P1.posthocBF.negVSneut <- ttestBF(P1.posthocBF.emo$neutral$P1, # first condition
  #                                   P1.posthocBF.emo$negative$P1, # second condition
  #                                   mu=0, # null hypothesis (mean difference=0)
  #                                   paired=TRUE, # paired sample test
  #                                   iterations=niter, # number of MCMC iterations
  #                                   rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.posthocBF.negVSneut,file=paste0(wd,"/models/P1_posthocBF_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.posthocBF.negVSneut <- readRDS(paste0(wd,"/models/P1_posthocBF_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, dark, negative vs. neutral
  # P1.posthocBF.large.dark.negVSneut <- ttestBF(P1.posthocBF$negativeLargeDark$P1, # first condition
  #                                              P1.posthocBF$neutralLargeDark$P1, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.posthocBF.large.dark.negVSneut,file=paste0(wd,"/models/P1_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd,"/models/P1_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, dark, negative vs. neutral
  # P1.posthocBF.small.dark.negVSneut <- ttestBF(P1.posthocBF$negativeSmallDark$P1, # first condition
  #                                              P1.posthocBF$neutralSmallDark$P1, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.posthocBF.small.dark.negVSneut,file=paste0(wd,"/models/P1_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd,"/models/P1_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, bright, negative vs. neutral
  # P1.posthocBF.large.bright.negVSneut <- ttestBF(P1.posthocBF$negativeLargeBright$P1, # first condition
  #                                                P1.posthocBF$neutralLargeBright$P1, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.posthocBF.large.bright.negVSneut,file=paste0(wd,"/models/P1_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd,"/models/P1_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, bright, negative vs. neutral
  # P1.posthocBF.small.bright.negVSneut <- ttestBF(P1.posthocBF$negativeSmallBright$P1, # first condition
  #                                                P1.posthocBF$neutralSmallBright$P1, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.posthocBF.small.bright.negVSneut,file=paste0(wd,"/models/P1_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd,"/models/P1_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # load model

  ### model comparison
  compare.P1.posthocBF[,k] <- c(exp(P1.posthocBF.largeVSsmall@bayesFactor$bf[1]),
                                exp(P1.posthocBF.darkVSbright@bayesFactor$bf[1]),
                                exp(P1.posthocBF.negVSneut@bayesFactor$bf[1]),
                                exp(P1.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
                                exp(P1.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
                                exp(P1.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
                                exp(P1.posthocBF.small.bright.negVSneut@bayesFactor$bf[1]))
  
  # percentage of error
  compare.P1.posthocBF.perc.err[,k] <- c(P1.posthocBF.largeVSsmall@bayesFactor$error[1]*100,
                                         P1.posthocBF.darkVSbright@bayesFactor$error[1]*100,
                                         P1.posthocBF.negVSneut@bayesFactor$error[1]*100,
                                         P1.posthocBF.large.dark.negVSneut@bayesFactor$error[1]*100,
                                         P1.posthocBF.small.dark.negVSneut@bayesFactor$error[1]*100,
                                         P1.posthocBF.large.bright.negVSneut@bayesFactor$error[1]*100,
                                         P1.posthocBF.small.bright.negVSneut@bayesFactor$error[1]*100)
}
# summary
compare.P1.posthocBF <- data.frame("comparison"=c("largeVSsmall","darkVSbright","negVSneut","large.dark.negVSneut","small.dark.negVSneut","large.bright.negVSneut","small.bright.negVSneut"),
                         "nar"=compare.P1.posthocBF[,1],"nar.p.err"=compare.P1.posthocBF.perc.err[,1],
                         "med"=compare.P1.posthocBF[,2],"med.p.err"=compare.P1.posthocBF.perc.err[,2],
                         "wid"=compare.P1.posthocBF[,3],"wid.p.err"=compare.P1.posthocBF.perc.err[,3])
kable(format(compare.P1.posthocBF,scientific=TRUE),digits=2)
```

Follow-up contrasts reveal that the main effect of *size* best explains changes in P1 amplitude. Exploratory analyses further suggest that omitting the factor *emotion* from the full model improves fitting by at least `r compare.P1.anovaBF$nar[1]` times. Removing the interactions *size x contrast x emotion*, *contrast x emotion*, and *emotion x size* also improves fitting by at least `r compare.P1.anovaBF$nar[2]`, `r compare.P1.anovaBF$nar[3]`, and `r compare.P1.anovaBF$nar[4]` times, respectively.   
Conversely, omitting the factor *contrast* or the *contrast x size* interaction lowers the explanatory value of the resulting model by at least `r 1/compare.P1.anovaBF$nar[5]` and `r format(1/compare.P1.anovaBF$nar[6],scientific=TRUE)` times. Finally, omitting the factor *size* is maximally detrimental, as it would lower the explanatory value of the resulting model by at least `r format(1/compare.P1.anovaBF$nar[7],scientific=TRUE)` times.

## N1

```{r N1_pirateplot}
# summarize data
summary.N1 <- summarySEwithin(data.EEG.trial,"N1",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.N1,digits=2)

# N1 graph
# better visualization with averages across trials
summary.N1.plot <- summarySEwithin(data.EEG.trial,"N1",withinvars=c("participant","size","cont","emo"),idvar="word")
pirateplot(formula=N1~emo+size+cont, # dependent~independent variables
           data=summary.N1.plot, # data frame
           main="N1 amplitude", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-7,3), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal=pirateplot.palette) # color palette
```

```{r N1_models}
# preallocate matrices with all BFs
compare.N1.BF <- matrix(NA,6,length(scaling.factor))
compare.N1.anovaBF.temp <- matrix(NA,7,length(scaling.factor))
# preallocate matrices with all % errors
compare.N1.perc.err <- matrix(NA,6,length(scaling.factor))
compare.N1.anovaBF.perc.err.temp <- matrix(NA,7,length(scaling.factor)) 

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### CONFIRMATORY ANALYSES ###
  ### main effects of size and emotion
  # N1.sizeplusemo.BF <- lmBF(N1~size+emo, # formula
  #                           data.EEG.trial, # data
  #                           whichRandom=c("participant","word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(N1.sizeplusemo.BF,file=paste0(wd,"/models/N1_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.sizeplusemo.BF <- readRDS(paste0(wd,"/models/N1_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # N1.sizebyemo.BF <- lmBF(N1~size*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant","word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(N1.sizebyemo.BF,file=paste0(wd,"/models/N1_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.sizebyemo.BF <- readRDS(paste0(wd,"/models/N1_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of contrast and emotion
  # N1.contplusemo.BF <- lmBF(N1~cont+emo,
  #                           data.EEG.trial,
  #                           whichRandom=c("participant","word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(N1.contplusemo.BF,file=paste0(wd,"/models/N1_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.contplusemo.BF <- readRDS(paste0(wd,"/models/N1_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # N1.contbyemo.BF <- lmBF(N1~cont*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant","word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(N1.contbyemo.BF,file=paste0(wd,"/models/N1_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.contbyemo.BF <- readRDS(paste0(wd,"/models/N1_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # N1.sizepluscontplusemo.BF <- lmBF(N1~size+cont+emo,
  #                                   data.EEG.trial,
  #                                   whichRandom=c("participant","word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(N1.sizepluscontplusemo.BF,file=paste0(wd,"/models/N1_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.sizepluscontplusemo.BF <- readRDS(paste0(wd,"/models/N1_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # N1.sizebycontbyemo.BF <- lmBF(N1~size*cont*emo,
  #                               data.EEG.trial,
  #                               whichRandom=c("participant","word"), # random effects
  #                               rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                               rscaleRandom="nuisance", # prior scale for standardized random effects
  #                               rscaleCont="medium", # prior scale for standardized slopes
  #                               iterations=niter) # number of MCMC iterations
  # saveRDS(N1.sizebycontbyemo.BF,file=paste0(wd,"/models/N1_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.sizebycontbyemo.BF <- readRDS(paste0(wd,"/models/N1_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison across scaling factors
  # BFs
  compare.N1.BF[,k] <- c(exp(N1.sizeplusemo.BF@bayesFactor$bf[1]),
                         exp(N1.sizebyemo.BF@bayesFactor$bf[1]),
                         exp(N1.contplusemo.BF@bayesFactor$bf[1]),
                         exp(N1.contbyemo.BF@bayesFactor$bf[1]),
                         exp(N1.sizepluscontplusemo.BF@bayesFactor$bf[1]),
                         exp(N1.sizebycontbyemo.BF@bayesFactor$bf[1]))
  # percentage of error
  compare.N1.perc.err[,k] <- c(N1.sizeplusemo.BF@bayesFactor$error[1]*100,
                               N1.sizebyemo.BF@bayesFactor$error[1]*100,
                               N1.contplusemo.BF@bayesFactor$error[1]*100,
                               N1.contbyemo.BF@bayesFactor$error[1]*100,
                               N1.sizepluscontplusemo.BF@bayesFactor$error[1]*100,
                               N1.sizebycontbyemo.BF@bayesFactor$error[1]*100)

  ### EXPLORATORY ANALYSES ###
  # How important is each effect/interaction if we remove it from the full model?

  # N1.anovaBF <- anovaBF(N1~size*cont*emo, # formula
  #                       data.EEG.trial, # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant","word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(N1.anovaBF,file=paste0(wd,"/models/N1_anovaBF_",scaling.factor[k],".rds")) # save model
  N1.anovaBF <- readRDS(paste0(wd,"/models/N1_anovaBF_",scaling.factor[k],".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.N1.anovaBF.temp[,k] <- exp(N1.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.N1.anovaBF.perc.err.temp[,k] <- N1.anovaBF@bayesFactor$error*100
}

# summary confirmatory analysis
compare.N1 <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
                         "nar"=compare.N1.BF[,1],"nar.p.err"=compare.N1.perc.err[,1],
                         "med"=compare.N1.BF[,2],"med.p.err"=compare.N1.perc.err[,2],
                         "wid"=compare.N1.BF[,3],"wid.p.err"=compare.N1.perc.err[,3])
compare.N1 <- compare.N1[order(compare.N1$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(format(compare.N1,scientific=TRUE),digits=2)

# summary exploratory analysis
compare.N1.anovaBF <- data.frame("omit from full model"=c("cont:emo:size","cont:emo","emo:size","cont:size","emo","cont","size"),
                                 "nar"=compare.N1.anovaBF.temp[,1],"nar.p.err"=compare.N1.anovaBF.perc.err.temp[,1],
                                 "med"=compare.N1.anovaBF.temp[,2],"med.p.err"=compare.N1.anovaBF.perc.err.temp[,2],
                                 "wid"=compare.N1.anovaBF.temp[,3],"wid.p.err"=compare.N1.anovaBF.perc.err.temp[,3])
compare.N1.anovaBF <- compare.N1.anovaBF[order(compare.N1.anovaBF$nar,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.N1[1,4]<1,"null",as.character(compare.N1[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.N1[1,1])`) explains the observed data `r format(ifelse(compare.N1[1,4]>1,compare.N1[1,4]/compare.N1[2,4],1/compare.N1[1,4]),scientific=TRUE)` times better than the second best model (`r as.character(compare.N1[2,1])`).   

### Paired comparisons

```{r N1_posthoc}
# main effects
# size
N1.posthocBF.size <- data.EEG.trial %>% # data frame
  select(participant,size,N1) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="N1",withinvars=c("participant","size")) %>% # summary
  split(.$size) # split according to condition
# contrast
N1.posthocBF.cont <- data.EEG.trial %>% # data frame
  select(participant,cont,N1) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="N1",withinvars=c("participant","cont")) %>% # summary
  split(.$cont) # split according to condition
# emotion
N1.posthocBF.emo <- data.EEG.trial %>% # data frame
  select(participant,emo,N1) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="N1",withinvars=c("participant","emo")) %>% # summary
  split(.$emo) # split according to condition

# interactions of interest (i.e., always negative vs. neutral)
N1.posthocBF <- data.EEG.trial %>% # data frame
  select(participant,condition,N1) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="N1",withinvars=c("participant","condition")) %>% # summary
  split(.$condition) # split according to condition

compare.N1.posthocBF <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.posthocBF.perc.err <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors

  # large vs. small
  # N1.posthocBF.largeVSsmall <- ttestBF(N1.posthocBF.size$large$N1, # first condition
  #                                      N1.posthocBF.size$small$N1, # second condition
  #                                      mu=0, # null hypothesis (mean difference=0)
  #                                      paired=TRUE, # paired sample test
  #                                      iterations=niter, # number of MCMC iterations
  #                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.posthocBF.largeVSsmall,file=paste0(wd,"/models/N1_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # save model
  N1.posthocBF.largeVSsmall <- readRDS(paste0(wd,"/models/N1_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # load model

  # dark vs. bright
  # N1.posthocBF.darkVSbright <- ttestBF(N1.posthocBF.cont$dark$N1, # first condition
  #                                      N1.posthocBF.cont$bright$N1, # second condition
  #                                      mu=0, # null hypothesis (mean difference=0)
  #                                      paired=TRUE, # paired sample test
  #                                      iterations=niter, # number of MCMC iterations
  #                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.posthocBF.darkVSbright,file=paste0(wd,"/models/N1_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # save model
  N1.posthocBF.darkVSbright <- readRDS(paste0(wd,"/models/N1_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # load model

  # negative vs. neutral
  # N1.posthocBF.negVSneut <- ttestBF(N1.posthocBF.emo$neutral$N1, # first condition
  #                                   N1.posthocBF.emo$negative$N1, # second condition
  #                                   mu=0, # null hypothesis (mean difference=0)
  #                                   paired=TRUE, # paired sample test
  #                                   iterations=niter, # number of MCMC iterations
  #                                   rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.posthocBF.negVSneut,file=paste0(wd,"/models/N1_posthocBF_negVSneut_",scaling.factor[k],".rds")) # save model
  N1.posthocBF.negVSneut <- readRDS(paste0(wd,"/models/N1_posthocBF_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, dark, negative vs. neutral
  # N1.posthocBF.large.dark.negVSneut <- ttestBF(N1.posthocBF$negativeLargeDark$N1, # first condition
  #                                              N1.posthocBF$neutralLargeDark$N1, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.posthocBF.large.dark.negVSneut,file=paste0(wd,"/models/N1_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  N1.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd,"/models/N1_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, dark, negative vs. neutral
  # N1.posthocBF.small.dark.negVSneut <- ttestBF(N1.posthocBF$negativeSmallDark$N1, # first condition
  #                                              N1.posthocBF$neutralSmallDark$N1, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.posthocBF.small.dark.negVSneut,file=paste0(wd,"/models/N1_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  N1.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd,"/models/N1_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, bright, negative vs. neutral
  # N1.posthocBF.large.bright.negVSneut <- ttestBF(N1.posthocBF$negativeLargeBright$N1, # first condition
  #                                                N1.posthocBF$neutralLargeBright$N1, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.posthocBF.large.bright.negVSneut,file=paste0(wd,"/models/N1_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  N1.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd,"/models/N1_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, bright, negative vs. neutral
  # N1.posthocBF.small.bright.negVSneut <- ttestBF(N1.posthocBF$negativeSmallBright$N1, # first condition
  #                                                N1.posthocBF$neutralSmallBright$N1, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(N1.posthocBF.small.bright.negVSneut,file=paste0(wd,"/models/N1_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  N1.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd,"/models/N1_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # load model

  ### model comparison
  compare.N1.posthocBF[,k] <- c(exp(N1.posthocBF.largeVSsmall@bayesFactor$bf[1]),
                                exp(N1.posthocBF.darkVSbright@bayesFactor$bf[1]),
                                exp(N1.posthocBF.negVSneut@bayesFactor$bf[1]),
                                exp(N1.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
                                exp(N1.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
                                exp(N1.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
                                exp(N1.posthocBF.small.bright.negVSneut@bayesFactor$bf[1]))
  
  # percentage of error
  compare.N1.posthocBF.perc.err[,k] <- c(N1.posthocBF.largeVSsmall@bayesFactor$error[1]*100,
                                         N1.posthocBF.darkVSbright@bayesFactor$error[1]*100,
                                         N1.posthocBF.negVSneut@bayesFactor$error[1]*100,
                                         N1.posthocBF.large.dark.negVSneut@bayesFactor$error[1]*100,
                                         N1.posthocBF.small.dark.negVSneut@bayesFactor$error[1]*100,
                                         N1.posthocBF.large.bright.negVSneut@bayesFactor$error[1]*100,
                                         N1.posthocBF.small.bright.negVSneut@bayesFactor$error[1]*100)
}
# summary
compare.N1.posthocBF <- data.frame("comparison"=c("largeVSsmall","darkVSbright","negVSneut","large.dark.negVSneut","small.dark.negVSneut","large.bright.negVSneut","small.bright.negVSneut"),
                         "nar"=compare.N1.posthocBF[,1],"nar.p.err"=compare.N1.posthocBF.perc.err[,1],
                         "med"=compare.N1.posthocBF[,2],"med.p.err"=compare.N1.posthocBF.perc.err[,2],
                         "wid"=compare.N1.posthocBF[,3],"wid.p.err"=compare.N1.posthocBF.perc.err[,3])
kable(format(compare.N1.posthocBF,scientific=TRUE),digits=2)
```

Follow-up contrasts reveal that the main effect of *contrast* best explains changes in N1 amplitude. Exploratory analyses further suggest that omitting the *contrast x emotion* interaction from the full model improves fitting by at least `r compare.N1.anovaBF$nar[1]` times. Removing *emotion x size*, *emotion*, and *size x contrast x emotion* also improves fitting by at least `r compare.N1.anovaBF$nar[2]`, `r compare.N1.anovaBF$nar[3]`, and `r compare.N1.anovaBF$nar[4]` times, respectively.   
Conversely, omitting the factor *size* or the *contrast x size* interaction lowers the explanatory value of the resulting model by at least `r format(1/compare.N1.anovaBF$nar[5],scientific=TRUE)` and `r format(1/compare.N1.anovaBF$nar[6],scientific=TRUE)` times. Finally, omitting the factor *contrast* is maximally detrimental, as it would lower the explanatory value of the resulting model by at least `r format(1/compare.N1.anovaBF$nar[7],scientific=TRUE)` times.

## EPN

```{r EPN_pirateplot}
# summarize data
summary.EPN <- summarySEwithin(data.EEG.trial,"EPN",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.EPN,digits=2)

# EPN graph
# better visualization with averages across trials
summary.EPN.plot <- summarySEwithin(data.EEG.trial,"EPN",withinvars=c("participant","size","cont","emo"),idvar="word")
pirateplot(formula=EPN~emo+size+cont, # dependent~independent variables
           data=summary.EPN.plot, # data frame
           main="EPN amplitude", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-5,5), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal=pirateplot.palette) # color palette
```

```{r EPN_models}
# preallocate matrices with all BFs
compare.EPN.BF <- matrix(NA,6,length(scaling.factor))
compare.EPN.anovaBF.temp <- matrix(NA,7,length(scaling.factor))
# preallocate matrices with all % errors
compare.EPN.perc.err <- matrix(NA,6,length(scaling.factor))
compare.EPN.anovaBF.perc.err.temp <- matrix(NA,7,length(scaling.factor)) 

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### CONFIRMATORY ANALYSES ###
  ### main effects of size and emotion
  # EPN.sizeplusemo.BF <- lmBF(EPN~size+emo, # formula
  #                           data.EEG.trial, # data
  #                           whichRandom=c("participant","word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.sizeplusemo.BF,file=paste0(wd,"/models/EPN_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.sizeplusemo.BF <- readRDS(paste0(wd,"/models/EPN_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # EPN.sizebyemo.BF <- lmBF(EPN~size*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant","word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.sizebyemo.BF,file=paste0(wd,"/models/EPN_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.sizebyemo.BF <- readRDS(paste0(wd,"/models/EPN_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of contrast and emotion
  # EPN.contplusemo.BF <- lmBF(EPN~cont+emo,
  #                           data.EEG.trial,
  #                           whichRandom=c("participant","word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.contplusemo.BF,file=paste0(wd,"/models/EPN_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.contplusemo.BF <- readRDS(paste0(wd,"/models/EPN_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # EPN.contbyemo.BF <- lmBF(EPN~cont*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant","word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.contbyemo.BF,file=paste0(wd,"/models/EPN_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.contbyemo.BF <- readRDS(paste0(wd,"/models/EPN_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # EPN.sizepluscontplusemo.BF <- lmBF(EPN~size+cont+emo,
  #                                   data.EEG.trial,
  #                                   whichRandom=c("participant","word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.sizepluscontplusemo.BF,file=paste0(wd,"/models/EPN_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.sizepluscontplusemo.BF <- readRDS(paste0(wd,"/models/EPN_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # EPN.sizebycontbyemo.BF <- lmBF(EPN~size*cont*emo,
  #                               data.EEG.trial,
  #                               whichRandom=c("participant","word"), # random effects
  #                               rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                               rscaleRandom="nuisance", # prior scale for standardized random effects
  #                               rscaleCont="medium", # prior scale for standardized slopes
  #                               iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.sizebycontbyemo.BF,file=paste0(wd,"/models/EPN_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.sizebycontbyemo.BF <- readRDS(paste0(wd,"/models/EPN_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison across scaling factors
  # BFs
  compare.EPN.BF[,k] <- c(exp(EPN.sizeplusemo.BF@bayesFactor$bf[1]),
                         exp(EPN.sizebyemo.BF@bayesFactor$bf[1]),
                         exp(EPN.contplusemo.BF@bayesFactor$bf[1]),
                         exp(EPN.contbyemo.BF@bayesFactor$bf[1]),
                         exp(EPN.sizepluscontplusemo.BF@bayesFactor$bf[1]),
                         exp(EPN.sizebycontbyemo.BF@bayesFactor$bf[1]))
  # percentage of error
  compare.EPN.perc.err[,k] <- c(EPN.sizeplusemo.BF@bayesFactor$error[1]*100,
                               EPN.sizebyemo.BF@bayesFactor$error[1]*100,
                               EPN.contplusemo.BF@bayesFactor$error[1]*100,
                               EPN.contbyemo.BF@bayesFactor$error[1]*100,
                               EPN.sizepluscontplusemo.BF@bayesFactor$error[1]*100,
                               EPN.sizebycontbyemo.BF@bayesFactor$error[1]*100)

  ### EXPLORATORY ANALYSES ###
  # How important is each effect/interaction if we remove it from the full model?

  # EPN.anovaBF <- anovaBF(EPN~size*cont*emo, # formula
  #                       data.EEG.trial, # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant","word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(EPN.anovaBF,file=paste0(wd,"/models/EPN_anovaBF_",scaling.factor[k],".rds")) # save model
  EPN.anovaBF <- readRDS(paste0(wd,"/models/EPN_anovaBF_",scaling.factor[k],".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.EPN.anovaBF.temp[,k] <- exp(EPN.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.EPN.anovaBF.perc.err.temp[,k] <- EPN.anovaBF@bayesFactor$error*100
}

# summary confirmatory analysis
compare.EPN <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
                         "nar"=compare.EPN.BF[,1],"nar.p.err"=compare.EPN.perc.err[,1],
                         "med"=compare.EPN.BF[,2],"med.p.err"=compare.EPN.perc.err[,2],
                         "wid"=compare.EPN.BF[,3],"wid.p.err"=compare.EPN.perc.err[,3])
compare.EPN <- compare.EPN[order(compare.EPN$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(format(compare.EPN,scientific=TRUE),digits=2)

# summary exploratory analysis
compare.EPN.anovaBF <- data.frame("omit from full model"=c("cont:emo:size","cont:emo","emo:size","cont:size","emo","cont","size"),
                                 "nar"=compare.EPN.anovaBF.temp[,1],"nar.p.err"=compare.EPN.anovaBF.perc.err.temp[,1],
                                 "med"=compare.EPN.anovaBF.temp[,2],"med.p.err"=compare.EPN.anovaBF.perc.err.temp[,2],
                                 "wid"=compare.EPN.anovaBF.temp[,3],"wid.p.err"=compare.EPN.anovaBF.perc.err.temp[,3])
compare.EPN.anovaBF <- compare.EPN.anovaBF[order(compare.EPN.anovaBF$nar,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EPN[1,4]<1,"null",as.character(compare.EPN[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.EPN[1,1])`) explains the observed data `r ifelse(compare.EPN[1,4]>1,compare.EPN[1,4]/compare.EPN[2,4],1/compare.EPN[1,4])` times better than the second best model (`r as.character(compare.EPN[2,1])`).   

### Paired comparisons

```{r EPN_posthoc}
# main effects
# size
EPN.posthocBF.size <- data.EEG.trial %>% # data frame
  select(participant,size,EPN) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="EPN",withinvars=c("participant","size")) %>% # summary
  split(.$size) # split according to condition
# contrast
EPN.posthocBF.cont <- data.EEG.trial %>% # data frame
  select(participant,cont,EPN) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="EPN",withinvars=c("participant","cont")) %>% # summary
  split(.$cont) # split according to condition
# emotion
EPN.posthocBF.emo <- data.EEG.trial %>% # data frame
  select(participant,emo,EPN) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="EPN",withinvars=c("participant","emo")) %>% # summary
  split(.$emo) # split according to condition

# interactions of interest (i.e., always negative vs. neutral)
EPN.posthocBF <- data.EEG.trial %>% # data frame
  select(participant,condition,EPN) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="EPN",withinvars=c("participant","condition")) %>% # summary
  split(.$condition) # split according to condition

compare.EPN.posthocBF <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all BF10
compare.EPN.posthocBF.perc.err <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors

  # large vs. small
  # EPN.posthocBF.largeVSsmall <- ttestBF(EPN.posthocBF.size$large$EPN, # first condition
  #                                      EPN.posthocBF.size$small$EPN, # second condition
  #                                      mu=0, # null hypothesis (mean difference=0)
  #                                      paired=TRUE, # paired sample test
  #                                      iterations=niter, # number of MCMC iterations
  #                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.largeVSsmall,file=paste0(wd,"/models/EPN_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # save model
  EPN.posthocBF.largeVSsmall <- readRDS(paste0(wd,"/models/EPN_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # load model

  # dark vs. bright
  # EPN.posthocBF.darkVSbright <- ttestBF(EPN.posthocBF.cont$dark$EPN, # first condition
  #                                      EPN.posthocBF.cont$bright$EPN, # second condition
  #                                      mu=0, # null hypothesis (mean difference=0)
  #                                      paired=TRUE, # paired sample test
  #                                      iterations=niter, # number of MCMC iterations
  #                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.darkVSbright,file=paste0(wd,"/models/EPN_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # save model
  EPN.posthocBF.darkVSbright <- readRDS(paste0(wd,"/models/EPN_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # load model

  # negative vs. neutral
  # EPN.posthocBF.negVSneut <- ttestBF(EPN.posthocBF.emo$neutral$EPN, # first condition
  #                                   EPN.posthocBF.emo$negative$EPN, # second condition
  #                                   mu=0, # null hypothesis (mean difference=0)
  #                                   paired=TRUE, # paired sample test
  #                                   iterations=niter, # number of MCMC iterations
  #                                   rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.negVSneut,file=paste0(wd,"/models/EPN_posthocBF_negVSneut_",scaling.factor[k],".rds")) # save model
  EPN.posthocBF.negVSneut <- readRDS(paste0(wd,"/models/EPN_posthocBF_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, dark, negative vs. neutral
  # EPN.posthocBF.large.dark.negVSneut <- ttestBF(EPN.posthocBF$negativeLargeDark$EPN, # first condition
  #                                              EPN.posthocBF$neutralLargeDark$EPN, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.large.dark.negVSneut,file=paste0(wd,"/models/EPN_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  EPN.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd,"/models/EPN_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, dark, negative vs. neutral
  # EPN.posthocBF.small.dark.negVSneut <- ttestBF(EPN.posthocBF$negativeSmallDark$EPN, # first condition
  #                                              EPN.posthocBF$neutralSmallDark$EPN, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.small.dark.negVSneut,file=paste0(wd,"/models/EPN_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  EPN.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd,"/models/EPN_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, bright, negative vs. neutral
  # EPN.posthocBF.large.bright.negVSneut <- ttestBF(EPN.posthocBF$negativeLargeBright$EPN, # first condition
  #                                                EPN.posthocBF$neutralLargeBright$EPN, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.large.bright.negVSneut,file=paste0(wd,"/models/EPN_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  EPN.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd,"/models/EPN_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, bright, negative vs. neutral
  # EPN.posthocBF.small.bright.negVSneut <- ttestBF(EPN.posthocBF$negativeSmallBright$EPN, # first condition
  #                                                EPN.posthocBF$neutralSmallBright$EPN, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(EPN.posthocBF.small.bright.negVSneut,file=paste0(wd,"/models/EPN_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  EPN.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd,"/models/EPN_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # load model

  ### model comparison
  compare.EPN.posthocBF[,k] <- c(exp(EPN.posthocBF.largeVSsmall@bayesFactor$bf[1]),
                                exp(EPN.posthocBF.darkVSbright@bayesFactor$bf[1]),
                                exp(EPN.posthocBF.negVSneut@bayesFactor$bf[1]),
                                exp(EPN.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
                                exp(EPN.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
                                exp(EPN.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
                                exp(EPN.posthocBF.small.bright.negVSneut@bayesFactor$bf[1]))
  
  # percentage of error
  compare.EPN.posthocBF.perc.err[,k] <- c(EPN.posthocBF.largeVSsmall@bayesFactor$error[1]*100,
                                         EPN.posthocBF.darkVSbright@bayesFactor$error[1]*100,
                                         EPN.posthocBF.negVSneut@bayesFactor$error[1]*100,
                                         EPN.posthocBF.large.dark.negVSneut@bayesFactor$error[1]*100,
                                         EPN.posthocBF.small.dark.negVSneut@bayesFactor$error[1]*100,
                                         EPN.posthocBF.large.bright.negVSneut@bayesFactor$error[1]*100,
                                         EPN.posthocBF.small.bright.negVSneut@bayesFactor$error[1]*100)
}
# summary
compare.EPN.posthocBF <- data.frame("comparison"=c("largeVSsmall","darkVSbright","negVSneut","large.dark.negVSneut","small.dark.negVSneut","large.bright.negVSneut","small.bright.negVSneut"),
                         "nar"=compare.EPN.posthocBF[,1],"nar.p.err"=compare.EPN.posthocBF.perc.err[,1],
                         "med"=compare.EPN.posthocBF[,2],"med.p.err"=compare.EPN.posthocBF.perc.err[,2],
                         "wid"=compare.EPN.posthocBF[,3],"wid.p.err"=compare.EPN.posthocBF.perc.err[,3])
kable(format(compare.EPN.posthocBF,scientific=TRUE),digits=2)
```

Follow-up contrasts reveal that the main effect of *size* best explains changes in EPN amplitude. Exploratory analyses further suggest that omitting the factor *contrast* from the full model improves fitting by at least `r compare.EPN.anovaBF$nar[1]` times. Removing *contrast x size*, *emotion x size*, *contrast x emotion*, and *size x contrast x emotion* also improves fitting by at least `r compare.EPN.anovaBF$nar[2]`, `r compare.EPN.anovaBF$nar[3]`, `r compare.EPN.anovaBF$nar[4]`, and `r compare.EPN.anovaBF$nar[5]` times, respectively.   
Conversely, omitting the factor *emotion* lowers the explanatory value of the resulting model by at least `r 1/compare.EPN.anovaBF$nar[6]` times. Finally, omitting the factor *size* is maximally detrimental, as it would lower the explanatory value of the resulting model by at least `r format(1/compare.EPN.anovaBF$nar[7],scientific=TRUE)` times.

## LPP

```{r LPP_pirateplot}
# summarize data
summary.LPP <- summarySEwithin(data.EEG.trial,"LPP",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.LPP,digits=2)

# LPP graph
# better visualization with averages across trials
summary.LPP.plot <- summarySEwithin(data.EEG.trial,"LPP",withinvars=c("participant","size","cont","emo"),idvar="word")
pirateplot(formula=LPP~emo+size+cont, # dependent~independent variables
           data=summary.LPP.plot, # data frame
           main="LPP amplitude", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-2,4), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal=pirateplot.palette) # color palette
```

```{r LPP_models}
# preallocate matrices with all BFs
compare.LPP.BF <- matrix(NA,6,length(scaling.factor))
compare.LPP.anovaBF.temp <- matrix(NA,7,length(scaling.factor))
# preallocate matrices with all % errors
compare.LPP.perc.err <- matrix(NA,6,length(scaling.factor))
compare.LPP.anovaBF.perc.err.temp <- matrix(NA,7,length(scaling.factor)) 

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### CONFIRMATORY ANALYSES ###
  ### main effects of size and emotion
  # LPP.sizeplusemo.BF <- lmBF(LPP~size+emo, # formula
  #                           data.EEG.trial, # data
  #                           whichRandom=c("participant","word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.sizeplusemo.BF,file=paste0(wd,"/models/LPP_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.sizeplusemo.BF <- readRDS(paste0(wd,"/models/LPP_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # LPP.sizebyemo.BF <- lmBF(LPP~size*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant","word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.sizebyemo.BF,file=paste0(wd,"/models/LPP_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.sizebyemo.BF <- readRDS(paste0(wd,"/models/LPP_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of contrast and emotion
  # LPP.contplusemo.BF <- lmBF(LPP~cont+emo,
  #                           data.EEG.trial,
  #                           whichRandom=c("participant","word"), # random effects
  #                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                           rscaleCont="medium", # prior scale for standardized slopes
  #                           iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.contplusemo.BF,file=paste0(wd,"/models/LPP_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.contplusemo.BF <- readRDS(paste0(wd,"/models/LPP_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # LPP.contbyemo.BF <- lmBF(LPP~cont*emo,
  #                         data.EEG.trial,
  #                         whichRandom=c("participant","word"), # random effects
  #                         rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                         rscaleRandom="nuisance", # prior scale for standardized random effects
  #                         rscaleCont="medium", # prior scale for standardized slopes
  #                         iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.contbyemo.BF,file=paste0(wd,"/models/LPP_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.contbyemo.BF <- readRDS(paste0(wd,"/models/LPP_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # LPP.sizepluscontplusemo.BF <- lmBF(LPP~size+cont+emo,
  #                                   data.EEG.trial,
  #                                   whichRandom=c("participant","word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.sizepluscontplusemo.BF,file=paste0(wd,"/models/LPP_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.sizepluscontplusemo.BF <- readRDS(paste0(wd,"/models/LPP_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # LPP.sizebycontbyemo.BF <- lmBF(LPP~size*cont*emo,
  #                               data.EEG.trial,
  #                               whichRandom=c("participant","word"), # random effects
  #                               rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                               rscaleRandom="nuisance", # prior scale for standardized random effects
  #                               rscaleCont="medium", # prior scale for standardized slopes
  #                               iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.sizebycontbyemo.BF,file=paste0(wd,"/models/LPP_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.sizebycontbyemo.BF <- readRDS(paste0(wd,"/models/LPP_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison across scaling factors
  # BFs
  compare.LPP.BF[,k] <- c(exp(LPP.sizeplusemo.BF@bayesFactor$bf[1]),
                         exp(LPP.sizebyemo.BF@bayesFactor$bf[1]),
                         exp(LPP.contplusemo.BF@bayesFactor$bf[1]),
                         exp(LPP.contbyemo.BF@bayesFactor$bf[1]),
                         exp(LPP.sizepluscontplusemo.BF@bayesFactor$bf[1]),
                         exp(LPP.sizebycontbyemo.BF@bayesFactor$bf[1]))
  # percentage of error
  compare.LPP.perc.err[,k] <- c(LPP.sizeplusemo.BF@bayesFactor$error[1]*100,
                               LPP.sizebyemo.BF@bayesFactor$error[1]*100,
                               LPP.contplusemo.BF@bayesFactor$error[1]*100,
                               LPP.contbyemo.BF@bayesFactor$error[1]*100,
                               LPP.sizepluscontplusemo.BF@bayesFactor$error[1]*100,
                               LPP.sizebycontbyemo.BF@bayesFactor$error[1]*100)

  ### EXPLORATORY ANALYSES ###
  # How important is each effect/interaction if we remove it from the full model?

  # LPP.anovaBF <- anovaBF(LPP~size*cont*emo, # formula
  #                       data.EEG.trial, # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant","word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(LPP.anovaBF,file=paste0(wd,"/models/LPP_anovaBF_",scaling.factor[k],".rds")) # save model
  LPP.anovaBF <- readRDS(paste0(wd,"/models/LPP_anovaBF_",scaling.factor[k],".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.LPP.anovaBF.temp[,k] <- exp(LPP.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.LPP.anovaBF.perc.err.temp[,k] <- LPP.anovaBF@bayesFactor$error*100
}

# summary confirmatory analysis
compare.LPP <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
                         "nar"=compare.LPP.BF[,1],"nar.p.err"=compare.LPP.perc.err[,1],
                         "med"=compare.LPP.BF[,2],"med.p.err"=compare.LPP.perc.err[,2],
                         "wid"=compare.LPP.BF[,3],"wid.p.err"=compare.LPP.perc.err[,3])
compare.LPP <- compare.LPP[order(compare.LPP$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(format(compare.LPP,scientific=TRUE),digits=2)

# summary exploratory analysis
compare.LPP.anovaBF <- data.frame("omit from full model"=c("cont:emo:size","cont:emo","emo:size","cont:size","emo","cont","size"),
                                 "nar"=compare.LPP.anovaBF.temp[,1],"nar.p.err"=compare.LPP.anovaBF.perc.err.temp[,1],
                                 "med"=compare.LPP.anovaBF.temp[,2],"med.p.err"=compare.LPP.anovaBF.perc.err.temp[,2],
                                 "wid"=compare.LPP.anovaBF.temp[,3],"wid.p.err"=compare.LPP.anovaBF.perc.err.temp[,3])
compare.LPP.anovaBF <- compare.LPP.anovaBF[order(compare.LPP.anovaBF$nar,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.LPP[1,4]<1,"null",as.character(compare.LPP[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.LPP[1,1])`) explains the observed data `r ifelse(compare.LPP[1,4]>1,compare.LPP[1,4]/compare.LPP[2,4],1/compare.LPP[1,4])` times better than the second best model (`r as.character(compare.LPP[2,1])`).   

### Paired comparisons

```{r LPP_posthoc}
# main effects
# size
LPP.posthocBF.size <- data.EEG.trial %>% # data frame
  select(participant,size,LPP) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="LPP",withinvars=c("participant","size")) %>% # summary
  split(.$size) # split according to condition
# contrast
LPP.posthocBF.cont <- data.EEG.trial %>% # data frame
  select(participant,cont,LPP) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="LPP",withinvars=c("participant","cont")) %>% # summary
  split(.$cont) # split according to condition
# emotion
LPP.posthocBF.emo <- data.EEG.trial %>% # data frame
  select(participant,emo,LPP) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="LPP",withinvars=c("participant","emo")) %>% # summary
  split(.$emo) # split according to condition

# interactions of interest (i.e., always negative vs. neutral)
LPP.posthocBF <- data.EEG.trial %>% # data frame
  select(participant,condition,LPP) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="LPP",withinvars=c("participant","condition")) %>% # summary
  split(.$condition) # split according to condition

compare.LPP.posthocBF <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all BF10
compare.LPP.posthocBF.perc.err <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors

  # large vs. small
  # LPP.posthocBF.largeVSsmall <- ttestBF(LPP.posthocBF.size$large$LPP, # first condition
  #                                      LPP.posthocBF.size$small$LPP, # second condition
  #                                      mu=0, # null hypothesis (mean difference=0)
  #                                      paired=TRUE, # paired sample test
  #                                      iterations=niter, # number of MCMC iterations
  #                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.largeVSsmall,file=paste0(wd,"/models/LPP_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # save model
  LPP.posthocBF.largeVSsmall <- readRDS(paste0(wd,"/models/LPP_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # load model

  # dark vs. bright
  # LPP.posthocBF.darkVSbright <- ttestBF(LPP.posthocBF.cont$dark$LPP, # first condition
  #                                      LPP.posthocBF.cont$bright$LPP, # second condition
  #                                      mu=0, # null hypothesis (mean difference=0)
  #                                      paired=TRUE, # paired sample test
  #                                      iterations=niter, # number of MCMC iterations
  #                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.darkVSbright,file=paste0(wd,"/models/LPP_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # save model
  LPP.posthocBF.darkVSbright <- readRDS(paste0(wd,"/models/LPP_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # load model

  # negative vs. neutral
  # LPP.posthocBF.negVSneut <- ttestBF(LPP.posthocBF.emo$neutral$LPP, # first condition
  #                                   LPP.posthocBF.emo$negative$LPP, # second condition
  #                                   mu=0, # null hypothesis (mean difference=0)
  #                                   paired=TRUE, # paired sample test
  #                                   iterations=niter, # number of MCMC iterations
  #                                   rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.negVSneut,file=paste0(wd,"/models/LPP_posthocBF_negVSneut_",scaling.factor[k],".rds")) # save model
  LPP.posthocBF.negVSneut <- readRDS(paste0(wd,"/models/LPP_posthocBF_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, dark, negative vs. neutral
  # LPP.posthocBF.large.dark.negVSneut <- ttestBF(LPP.posthocBF$negativeLargeDark$LPP, # first condition
  #                                              LPP.posthocBF$neutralLargeDark$LPP, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.large.dark.negVSneut,file=paste0(wd,"/models/LPP_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  LPP.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd,"/models/LPP_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, dark, negative vs. neutral
  # LPP.posthocBF.small.dark.negVSneut <- ttestBF(LPP.posthocBF$negativeSmallDark$LPP, # first condition
  #                                              LPP.posthocBF$neutralSmallDark$LPP, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.small.dark.negVSneut,file=paste0(wd,"/models/LPP_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  LPP.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd,"/models/LPP_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, bright, negative vs. neutral
  # LPP.posthocBF.large.bright.negVSneut <- ttestBF(LPP.posthocBF$negativeLargeBright$LPP, # first condition
  #                                                LPP.posthocBF$neutralLargeBright$LPP, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.large.bright.negVSneut,file=paste0(wd,"/models/LPP_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  LPP.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd,"/models/LPP_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, bright, negative vs. neutral
  # LPP.posthocBF.small.bright.negVSneut <- ttestBF(LPP.posthocBF$negativeSmallBright$LPP, # first condition
  #                                                LPP.posthocBF$neutralSmallBright$LPP, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(LPP.posthocBF.small.bright.negVSneut,file=paste0(wd,"/models/LPP_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  LPP.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd,"/models/LPP_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # load model

  ### model comparison
  compare.LPP.posthocBF[,k] <- c(exp(LPP.posthocBF.largeVSsmall@bayesFactor$bf[1]),
                                exp(LPP.posthocBF.darkVSbright@bayesFactor$bf[1]),
                                exp(LPP.posthocBF.negVSneut@bayesFactor$bf[1]),
                                exp(LPP.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
                                exp(LPP.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
                                exp(LPP.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
                                exp(LPP.posthocBF.small.bright.negVSneut@bayesFactor$bf[1]))
  
  # percentage of error
  compare.LPP.posthocBF.perc.err[,k] <- c(LPP.posthocBF.largeVSsmall@bayesFactor$error[1]*100,
                                         LPP.posthocBF.darkVSbright@bayesFactor$error[1]*100,
                                         LPP.posthocBF.negVSneut@bayesFactor$error[1]*100,
                                         LPP.posthocBF.large.dark.negVSneut@bayesFactor$error[1]*100,
                                         LPP.posthocBF.small.dark.negVSneut@bayesFactor$error[1]*100,
                                         LPP.posthocBF.large.bright.negVSneut@bayesFactor$error[1]*100,
                                         LPP.posthocBF.small.bright.negVSneut@bayesFactor$error[1]*100)
}
# summary
compare.LPP.posthocBF <- data.frame("comparison"=c("largeVSsmall","darkVSbright","negVSneut","large.dark.negVSneut","small.dark.negVSneut","large.bright.negVSneut","small.bright.negVSneut"),
                         "nar"=compare.LPP.posthocBF[,1],"nar.p.err"=compare.LPP.posthocBF.perc.err[,1],
                         "med"=compare.LPP.posthocBF[,2],"med.p.err"=compare.LPP.posthocBF.perc.err[,2],
                         "wid"=compare.LPP.posthocBF[,3],"wid.p.err"=compare.LPP.posthocBF.perc.err[,3])
kable(format(compare.LPP.posthocBF,scientific=TRUE),digits=2)
```

Follow-up contrasts reveal that the main effect of *contrast* best explains changes in LPP amplitude, closely followed by the main effect of *size*. Exploratory analyses further suggest that omitting the factor *emotion* from the full model improves fitting by at least `r compare.LPP.anovaBF$nar[1]` times. Removing *contrast x emotion*, *emotion x size*, and *size x contrast x emotion* also improves fitting by at least `r compare.LPP.anovaBF$nar[2]`, `r compare.LPP.anovaBF$nar[3]`, and `r compare.LPP.anovaBF$nar[4]` times, respectively.   
Conversely, omitting the *size x contrast* interaction or the main effect of *contrast* lowers the explanatory value of the resulting model by at least `r 1/compare.LPP.anovaBF$nar[5]` and `r format(1/compare.LPP.anovaBF$nar[6],scientific=TRUE)` times, respectively. Finally, omitting the factor *size* is maximally detrimental, as it would lower the explanatory value of the resulting model by at least `r format(1/compare.LPP.anovaBF$nar[7],scientific=TRUE)` times.

***
***

# SUPPLEMENTARY ANALYSIS

Visual inspection of the waveforms revealed unexpected latency shifts at the level of P1 and N1 components. This could be a potential source of noise when analyzing mean amplitude values. Therefore, as supplementary analyses, we ran the same analyses as above but using, as dependent variables, peak amplitude and latency values of P1 and N1.

```{r data_peaks}
data.P1.peakamp <- read.table("P1_locpeakamp.txt",header=TRUE) # load data
data.P1.peaklat <- read.table("P1_locpeaklat.txt",header=TRUE) # load data
data.N1.peakamp <- read.table("N1_locpeakamp.txt",header=TRUE) # load data
data.N1.peaklat <- read.table("N1_locpeaklat.txt",header=TRUE) # load data

data.peaks <- rbind(data.P1.peakamp,data.P1.peaklat,data.N1.peakamp,data.N1.peaklat) %>%
  mutate(var=rep(c("peak.amp","peak.lat","peak.amp","peak.lat"),each=320), # peak amplitude or latency?
         bini=factor(bini), # convert condition numbers as factors
         size=revalue(bini,c("1"="large","2"="small","3"="large","4"="small","5"="large","6"="small","7"="large","8"="small")), # main effect of size
         size=relevel(size,ref="large"), # re-reference size to large
         cont=revalue(bini,c("1"="dark","2"="dark","3"="bright","4"="bright","5"="dark","6"="dark","7"="bright","8"="bright")), # main effect of contrast
         cont=relevel(cont,ref="dark"), # re-reference contrast to dark
         emo=revalue(bini,c("1"="negative","2"="negative","3"="negative","4"="negative","5"="neutral","6"="neutral","7"="neutral","8"="neutral")), # main effect of emotion
         emo=relevel(emo,ref="neutral")) %>% # re-reference emotion to neutral
           select(participant=ERPset,component=chlabel,var,condition=binlabel,size,cont,emo,amplitude=value) # select, reorder, and rename variables
rm(data.P1.peakamp,data.P1.peaklat,data.N1.peakamp,data.N1.peaklat) # remove unnecessary data frames
```

## P1

### Peak amplitude

Peak amplitude was calculated as the highest positive value within 66-148 ms post-stimulus onset larger than the 3 points (~10 ms at 256 Hz sampling rate) on either side of the peak.

```{r P1_peakamp_pirateplot}
# summarize data
summary.P1.peakamp <- summarySEwithin(subset(data.peaks,component=="P1" & var=="peak.amp"),"amplitude",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.P1.peakamp,digits=2)

# P1 graph
pirateplot(formula=amplitude~emo+size+cont, # dependent~independent variables
           data=subset(data.peaks,component=="P1" & var=="peak.amp"), # data frame
           main="P1 peak amplitude", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-1,11), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal=pirateplot.palette) # color palette
```

```{r P1_peakamp_models}
# preallocate matrices with all BFs
compare.P1.peakamp.BF <- matrix(NA,6,length(scaling.factor))
compare.P1.peakamp.anovaBF.temp <- matrix(NA,7,length(scaling.factor))
# preallocate matrices with all % errors
compare.P1.peakamp.perc.err <- matrix(NA,6,length(scaling.factor))
compare.P1.peakamp.anovaBF.perc.err.temp <- matrix(NA,7,length(scaling.factor)) 

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### CONFIRMATORY ANALYSES ###
  ## main effects of size and emotion
  # P1.peakamp.sizeplusemo.BF <- lmBF(amplitude~size+emo, # formula
  #                                   subset(data.peaks,component=="P1" & var=="peak.amp"), # data
  #                                   whichRandom=c("participant","word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.sizeplusemo.BF,file=paste0(wd,"/models/P1_peakamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.peakamp.sizeplusemo.BF <- readRDS(paste0(wd,"/models/P1_peakamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # P1.peakamp.sizebyemo.BF <- lmBF(amplitude~size*emo, # formula
  #                                 subset(data.peaks,component=="P1" & var=="peak.amp"), # data
  #                                 whichRandom=c("participant","word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.sizebyemo.BF,file=paste0(wd,"/models/P1_peakamp_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.peakamp.sizebyemo.BF <- readRDS(paste0(wd,"/models/P1_peakamp_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of contrast and emotion
  # P1.peakamp.contplusemo.BF <- lmBF(amplitude~cont+emo, # formula
  #                                   subset(data.peaks,component=="P1" & var=="peak.amp"), # data
  #                                   whichRandom=c("participant","word"), # random effects
  #                                   rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                   rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                   rscaleCont="medium", # prior scale for standardized slopes
  #                                   iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.contplusemo.BF,file=paste0(wd,"/models/P1_peakamp_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.peakamp.contplusemo.BF <- readRDS(paste0(wd,"/models/P1_peakamp_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # P1.peakamp.contbyemo.BF <- lmBF(amplitude~cont*emo, # formula
  #                                 subset(data.peaks,component=="P1" & var=="peak.amp"), # data
  #                                 whichRandom=c("participant","word"), # random effects
  #                                 rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                 rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                 rscaleCont="medium", # prior scale for standardized slopes
  #                                 iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.contbyemo.BF,file=paste0(wd,"/models/P1_peakamp_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.peakamp.contbyemo.BF <- readRDS(paste0(wd,"/models/P1_peakamp_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # P1.peakamp.sizepluscontplusemo.BF <- lmBF(amplitude~size+cont+emo, # formula
  #                                           subset(data.peaks,component=="P1" & var=="peak.amp"), # data
  #                                           whichRandom=c("participant","word"), # random effects
  #                                           rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                           rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                           rscaleCont="medium", # prior scale for standardized slopes
  #                                           iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.sizepluscontplusemo.BF,file=paste0(wd,"/models/P1_peakamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.peakamp.sizepluscontplusemo.BF <- readRDS(paste0(wd,"/models/P1_peakamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # P1.peakamp.sizebycontbyemo.BF <- lmBF(amplitude~size*cont*emo, # formula
  #                                       subset(data.peaks,component=="P1" & var=="peak.amp"), # data
  #                                       whichRandom=c("participant","word"), # random effects
  #                                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                                       rscaleCont="medium", # prior scale for standardized slopes
  #                                       iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.sizebycontbyemo.BF,file=paste0(wd,"/models/P1_peakamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.peakamp.sizebycontbyemo.BF <- readRDS(paste0(wd,"/models/P1_peakamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison across scaling factors
  # BFs
  compare.P1.peakamp.BF[,k] <- c(exp(P1.peakamp.sizeplusemo.BF@bayesFactor$bf[1]),
                         exp(P1.peakamp.sizebyemo.BF@bayesFactor$bf[1]),
                         exp(P1.peakamp.contplusemo.BF@bayesFactor$bf[1]),
                         exp(P1.peakamp.contbyemo.BF@bayesFactor$bf[1]),
                         exp(P1.peakamp.sizepluscontplusemo.BF@bayesFactor$bf[1]),
                         exp(P1.peakamp.sizebycontbyemo.BF@bayesFactor$bf[1]))
  # percentage of error
  compare.P1.peakamp.perc.err[,k] <- c(P1.peakamp.sizeplusemo.BF@bayesFactor$error[1]*100,
                               P1.peakamp.sizebyemo.BF@bayesFactor$error[1]*100,
                               P1.peakamp.contplusemo.BF@bayesFactor$error[1]*100,
                               P1.peakamp.contbyemo.BF@bayesFactor$error[1]*100,
                               P1.peakamp.sizepluscontplusemo.BF@bayesFactor$error[1]*100,
                               P1.peakamp.sizebycontbyemo.BF@bayesFactor$error[1]*100)

  ### EXPLORATORY ANALYSES ###
  # How important is each effect/interaction if we remove it from the full model?

  # P1.peakamp.anovaBF <- anovaBF(amplitude~size*cont*emo, # formula
  #                       subset(data.peaks,component=="P1" & var=="peak.amp"), # data
  #                       whichModels="top", # test all models created by removing a main effect or interaction from the full model
  #                       whichRandom=c("participant","word"), # random effects
  #                       rscaleFixed=scaling.factor[k], # scaling factor of prior on effect size
  #                       rscaleRandom="nuisance", # prior scale for standardized random effects
  #                       iterations=niter) # number of MCMC iterations
  # saveRDS(P1.peakamp.anovaBF,file=paste0(wd,"/models/P1_peakamp_anovaBF_",scaling.factor[k],".rds")) # save model
  P1.peakamp.anovaBF <- readRDS(paste0(wd,"/models/P1_peakamp_anovaBF_",scaling.factor[k],".rds")) # load model

  ### model comparison across scaling factors
  # BFs
  compare.P1.peakamp.anovaBF.temp[,k] <- exp(P1.peakamp.anovaBF@bayesFactor$bf)
  # percentage of error
  compare.P1.peakamp.anovaBF.perc.err.temp[,k] <- P1.peakamp.anovaBF@bayesFactor$error*100
}

# summary confirmatory analysis
compare.P1.peakamp <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
                         "nar"=compare.P1.peakamp.BF[,1],"nar.p.err"=compare.P1.peakamp.perc.err[,1],
                         "med"=compare.P1.peakamp.BF[,2],"med.p.err"=compare.P1.peakamp.perc.err[,2],
                         "wid"=compare.P1.peakamp.BF[,3],"wid.p.err"=compare.P1.peakamp.perc.err[,3])
compare.P1.peakamp <- compare.P1.peakamp[order(compare.P1.peakamp$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(format(compare.P1.peakamp,scientific=TRUE),digits=2)

# summary exploratory analysis
compare.P1.peakamp.anovaBF <- data.frame("omit from full model"=c("cont:emo:size","cont:emo","emo:size","cont:size","emo","cont","size"),
                                 "nar"=compare.P1.peakamp.anovaBF.temp[,1],"nar.p.err"=compare.P1.peakamp.anovaBF.perc.err.temp[,1],
                                 "med"=compare.P1.peakamp.anovaBF.temp[,2],"med.p.err"=compare.P1.peakamp.anovaBF.perc.err.temp[,2],
                                 "wid"=compare.P1.peakamp.anovaBF.temp[,3],"wid.p.err"=compare.P1.peakamp.anovaBF.perc.err.temp[,3])
compare.P1.peakamp.anovaBF <- compare.P1.peakamp.anovaBF[order(compare.P1.peakamp.anovaBF$nar,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.P1.peakamp[1,4]<1,"null",as.character(compare.P1.peakamp[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.P1.peakamp[1,1])`) explains the observed data `r ifelse(compare.P1.peakamp[1,4]>1,compare.P1.peakamp[1,4]/compare.P1.peakamp[2,4],1/compare.P1.peakamp[1,4])` times better than the second best model (`r as.character(compare.P1.peakamp[2,1])`).   

### Paired comparisons

```{r P1_peakamp_posthoc}
# main effects
# size
P1.peakamp.posthocBF.size <- subset(data.peaks,component=="P1" & var=="peak.amp") %>% # data frame
  select(participant,component,size,amplitude) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="amplitude",withinvars=c("participant","size")) %>% # summary
  split(.$size) # split according to condition
# contrast
P1.peakamp.posthocBF.cont <- subset(data.peaks,component=="P1" & var=="peak.amp") %>% # data frame
  select(participant,component,cont,amplitude) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="amplitude",withinvars=c("participant","cont")) %>% # summary
  split(.$cont) # split according to condition
# emotion
P1.peakamp.posthocBF.emo <- subset(data.peaks,component=="P1" & var=="peak.amp") %>% # data frame
  select(participant,component,emo,amplitude) %>% # select only variables of interest
  summarySEwithin(data=.,measurevar="amplitude",withinvars=c("participant","emo")) %>% # summary
  split(.$emo) # split according to condition
# interactions of interest (i.e., always negative vs. neutral)
P1.peakamp.posthocBF <- subset(data.peaks,component=="P1" & var=="peak.amp") %>% # data frame
  select(participant,condition,amplitude) %>% # select only variables of interest
  split(.$condition) # split according to condition

compare.P1.peakamp.posthocBF <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.peakamp.posthocBF.perc.err <- matrix(NA,7,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors

  # large vs. small
  # P1.peakamp.posthocBF.largeVSsmall <- ttestBF(P1.peakamp.posthocBF.size$large$amplitude, # first condition
  #                                              P1.peakamp.posthocBF.size$small$amplitude, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.largeVSsmall,file=paste0(wd,"/models/P1_peakamp_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # save model
  P1.peakamp.posthocBF.largeVSsmall <- readRDS(paste0(wd,"/models/P1_peakamp_posthocBF_largeVSsmall_",scaling.factor[k],".rds")) # load model

  # dark vs. bright
  # P1.peakamp.posthocBF.darkVSbright <- ttestBF(P1.peakamp.posthocBF.cont$dark$amplitude, # first condition
  #                                              P1.peakamp.posthocBF.cont$bright$amplitude, # second condition
  #                                              mu=0, # null hypothesis (mean difference=0)
  #                                              paired=TRUE, # paired sample test
  #                                              iterations=niter, # number of MCMC iterations
  #                                              rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.darkVSbright,file=paste0(wd,"/models/P1_peakamp_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # save model
  P1.peakamp.posthocBF.darkVSbright <- readRDS(paste0(wd,"/models/P1_peakamp_posthocBF_darkVSbright_",scaling.factor[k],".rds")) # load model

  # negative vs. neutral
  # P1.peakamp.posthocBF.negVSneut <- ttestBF(P1.peakamp.posthocBF.emo$neutral$amplitude, # first condition
  #                                           P1.peakamp.posthocBF.emo$negative$amplitude, # second condition
  #                                           mu=0, # null hypothesis (mean difference=0)
  #                                           paired=TRUE, # paired sample test
  #                                           iterations=niter, # number of MCMC iterations
  #                                           rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.negVSneut,file=paste0(wd,"/models/P1_peakamp_posthocBF_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.peakamp.posthocBF.negVSneut <- readRDS(paste0(wd,"/models/P1_peakamp_posthocBF_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, dark, negative vs. neutral
  # P1.peakamp.posthocBF.large.dark.negVSneut <- ttestBF(P1.peakamp.posthocBF$negativeLargeDark$amplitude, # first condition
  #                                                      P1.peakamp.posthocBF$neutralLargeDark$amplitude, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.large.dark.negVSneut,file=paste0(wd,"/models/P1_peakamp_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.peakamp.posthocBF.large.dark.negVSneut <- readRDS(paste0(wd,"/models/P1_peakamp_posthocBF_large_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, dark, negative vs. neutral
  # P1.peakamp.posthocBF.small.dark.negVSneut <- ttestBF(P1.peakamp.posthocBF$negativeSmallDark$amplitude, # first condition
  #                                                      P1.peakamp.posthocBF$neutralSmallDark$amplitude, # second condition
  #                                                      mu=0, # null hypothesis (mean difference=0)
  #                                                      paired=TRUE, # paired sample test
  #                                                      iterations=niter, # number of MCMC iterations
  #                                                      rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.small.dark.negVSneut,file=paste0(wd,"/models/P1_peakamp_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.peakamp.posthocBF.small.dark.negVSneut <- readRDS(paste0(wd,"/models/P1_peakamp_posthocBF_small_dark_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # large, bright, negative vs. neutral
  # P1.peakamp.posthocBF.large.bright.negVSneut <- ttestBF(P1.peakamp.posthocBF$negativeLargeBright$amplitude, # first condition
  #                                                P1.peakamp.posthocBF$neutralLargeBright$amplitude, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                paired=TRUE, # paired sample test
  #                                                iterations=niter, # number of MCMC iterations
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.large.bright.negVSneut,file=paste0(wd,"/models/P1_peakamp_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.peakamp.posthocBF.large.bright.negVSneut <- readRDS(paste0(wd,"/models/P1_peakamp_posthocBF_large_bright_negVSneut_",scaling.factor[k],".rds")) # load model
  
  # small, bright, negative vs. neutral
  # P1.peakamp.posthocBF.small.bright.negVSneut <- ttestBF(P1.peakamp.posthocBF$negativeSmallBright$amplitude, # first condition
  #                                                P1.peakamp.posthocBF$neutralSmallBright$amplitude, # second condition
  #                                                mu=0, # null hypothesis (mean difference=0)
  #                                                iterations=niter, # number of MCMC iterations
  #                                                paired=TRUE, # paired sample test
  #                                                rscale=scaling.factor[k]) # scaling factor
  # saveRDS(P1.peakamp.posthocBF.small.bright.negVSneut,file=paste0(wd,"/models/P1_peakamp_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # save model
  P1.peakamp.posthocBF.small.bright.negVSneut <- readRDS(paste0(wd,"/models/P1_peakamp_posthocBF_small_bright_negVSneut_",scaling.factor[k],".rds")) # load model

  ### model comparison
  compare.P1.peakamp.posthocBF[,k] <- c(exp(P1.peakamp.posthocBF.largeVSsmall@bayesFactor$bf[1]),
                                exp(P1.peakamp.posthocBF.darkVSbright@bayesFactor$bf[1]),
                                exp(P1.peakamp.posthocBF.negVSneut@bayesFactor$bf[1]),
                                exp(P1.peakamp.posthocBF.large.dark.negVSneut@bayesFactor$bf[1]),
                                exp(P1.peakamp.posthocBF.small.dark.negVSneut@bayesFactor$bf[1]),
                                exp(P1.peakamp.posthocBF.large.bright.negVSneut@bayesFactor$bf[1]),
                                exp(P1.peakamp.posthocBF.small.bright.negVSneut@bayesFactor$bf[1]))
  
  # percentage of error
  compare.P1.peakamp.posthocBF.perc.err[,k] <- c(P1.peakamp.posthocBF.largeVSsmall@bayesFactor$error[1]*100,
                                         P1.peakamp.posthocBF.darkVSbright@bayesFactor$error[1]*100,
                                         P1.peakamp.posthocBF.negVSneut@bayesFactor$error[1]*100,
                                         P1.peakamp.posthocBF.large.dark.negVSneut@bayesFactor$error[1]*100,
                                         P1.peakamp.posthocBF.small.dark.negVSneut@bayesFactor$error[1]*100,
                                         P1.peakamp.posthocBF.large.bright.negVSneut@bayesFactor$error[1]*100,
                                         P1.peakamp.posthocBF.small.bright.negVSneut@bayesFactor$error[1]*100)
}
# summary
compare.P1.peakamp.posthocBF <- data.frame("comparison"=c("largeVSsmall","darkVSbright","negVSneut","large.dark.negVSneut","small.dark.negVSneut","large.bright.negVSneut","small.bright.negVSneut"),
                         "nar"=compare.P1.peakamp.posthocBF[,1],"nar.p.err"=compare.P1.peakamp.posthocBF.perc.err[,1],
                         "med"=compare.P1.peakamp.posthocBF[,2],"med.p.err"=compare.P1.peakamp.posthocBF.perc.err[,2],
                         "wid"=compare.P1.peakamp.posthocBF[,3],"wid.p.err"=compare.P1.peakamp.posthocBF.perc.err[,3])
kable(format(compare.P1.peakamp.posthocBF,scientific=TRUE),digits=2)
```

Follow-up contrasts reveal that the main effect of *size* best explains changes in P1 peak amplitude. Exploratory analyses further suggest that omitting the factor *emotion* from the full model improves fitting by at least `r compare.P1.peakamp.anovaBF$nar[1]` times. Removing the interactions *emotion x size*, *contrast x emotion*, and *size x  contrast x emotion* also improves fitting by at least `r compare.P1.peakamp.anovaBF$nar[2]`, `r compare.P1.peakamp.anovaBF$nar[3]`, and `r compare.P1.peakamp.anovaBF$nar[4]` times, respectively.   
Conversely, omitting the *contrast x size* interaction or the factor *contrast* lowers the explanatory value of the resulting model by at least `r 1/compare.P1.peakamp.anovaBF$nar[5]` and `r 1/compare.P1.peakamp.anovaBF$nar[6]` times. Finally, omitting the factor *size* is maximally detrimental, as it would lower the explanatory value of the resulting model by at least `r 1/compare.P1.peakamp.anovaBF$nar[7]` times.

### Peak latency









