---
title: "<center> <h1>***SIZECONTEMO***</h1> </center>"
author: '[Antonio Schettino](https://www.researchgate.net/profile/Antonio_Schettino2 "Antonio Schettino")'
date: '`r Sys.Date()`'
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
    toc: true
    toc_float: true
---

In this project we will investigate the electrophysiological correlates of the combined processing of basic visual properties (i.e., size and contrast) and the emotional content of simple words.   
   
This analysis is based on visual inspection of the waveforms by Sebastian.   
Local peak amplitude and latency values have been extracted with ERPLAB (see **SizeContEmo_CompIdent_visual.m** for details).

```{r setup_environment,echo=FALSE,warning=FALSE,message=FALSE}
# setup work environment
# dev.off() # clear plots (if no plots are present, comment it out or it will throw an error)
cat("\014") # clear console
rm(list=ls()) # clear environment
set.seed(9001) # specify seed for RNG and ensure reproducible results (it's over 9000!)

expname <- "SizeContEmo" # experiment name
expphase <- "main" # experiment phase
wd <- paste0("D:/OneDrive - UGent/",expname,"/analysis/EEG/",expphase,"/visual_inspection/") # work directory
setwd(wd) # set work directory

# load relevant libraries
library(knitr) # dynamic report generation
library(reshape2) # to reshape the data
library(tidyverse) # install the following packages: ggplot2, tibble, tidyr, readr, purrr, dplyr
library(viridis) # more color maps
library(ggthemes) # more themes for ggplot2
library(Rmisc) # for advanced summary functions
library(yarrr) # amazing graphs
library(BayesFactor) # calculate Bayes factors

# setup output
options(width=120,scipen=999,digits=3) # change output width (for better printing), disable scientific notation (default: scipen=0), constrain output to 4 decimals
opts_chunk$set(warning=FALSE,message=FALSE,fig.width=10,fig.height=6) # for each chunk, display the output but not the R code (echo=FALSE), no package warnings (message=FALSE), no package messages (message=FALSE), width and height of all figures
```

<center> <h1>*GRAND AVERAGE*</h1> </center>

```{r graph_grand_avg}
grand.avg.allbins <- read.csv(paste0(expphase,"_grand_avg_allbins.csv"),header=TRUE,check.names=FALSE) # load data (check.names=FALSE eliminates the "X" at the beginning of each timepoint)
grand.avg.allbins <- melt(grand.avg.allbins,id.vars="electrode",variable.name="timepoint",value.name="amplitude") # transform to long format
grand.avg.allbins$timepoint <- as.numeric(levels(grand.avg.allbins$timepoint))[grand.avg.allbins$timepoint] # convert time points to number

# plot
ggplot(grand.avg.allbins,aes(timepoint,amplitude)) + # basic plot
  geom_line(aes(color=electrode),size=1) + # one line per electrode
  scale_color_viridis(discrete=TRUE,option="magma",alpha=.4) + # color scale
  guides(color="none") + # no legend
  labs(title="grand average across bins (all electrodes)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,100)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # horizontal reference line
  theme_pander(base_size=20,pc="white",lp=c(.8,.8)) # custom theme
```

```{r prepare_topos}
## plot electrode coordinates
electrodeLocs <- read_delim(paste0(wd,"leipzig64_Christopher.locs"), # load electrode locations
                            "\t", # delimiter (tab)
                            col_names=c("chanNo","theta","radius","electrode"), # column names
                            escape_double=FALSE,trim_ws=TRUE)

# convert theta values from degrees to radians
electrodeLocs$radianTheta <- pi/180*electrodeLocs$theta
# calculate Cartesian coordinates
electrodeLocs <- electrodeLocs %>% 
  mutate(x=.$radius*sin(.$radianTheta),
         y=.$radius*cos(.$radianTheta))
electrodeLocs <- electrodeLocs[order(electrodeLocs$electrode),] # sort electrodes in alphabetical orde

# create ggplot theme without axes and background grids
theme_topo <- function(base_size=12) {
  theme_bw(base_size=base_size) %+replace%
    theme(rect=element_blank(),
          line= element_blank(),
          axis.text=element_blank(),
          axis.title=element_blank()) }

# function to draw a circle (the head)
circleFun <- function(center=c(0,0),diameter=1,npoints=100) {
  r=diameter/2
  tt <- seq(0,2*pi,length.out=npoints)
  xx <- center[1]+r*cos(tt)
  yy <- center[2]+r*sin(tt)
  return(data.frame(x=xx,y=yy)) }

headShape <- circleFun(c(0,0),1,npoints=100)
nose <- data.frame(x=c(-0.075,0,.075),y=c(.495,.575,.495))

# # plot electrode coordinates on head
# ggplot(headShape,aes(x,y)) +
#   geom_path() +
#   geom_text(data=electrodeLocs,aes(x,y,label=electrode)) +
#   geom_line(data=nose,aes(x,y)) +
#   theme_topo() +
#   coord_equal()

# prepare topography
jet.colors <- colorRampPalette(c("#00007F","blue","#007FFF","cyan","#7FFF7F","yellow","#FF7F00","red","#7F0000")) # jet color map
gridRes <- 268 # number of points for each grid dimension, corresponding to the resolution/smoothness of the interpolation
maskRing <- circleFun(diameter=1.42) # create a circle around the outside of the plotting area to mask the jagged edges of the interpolation
```

```{r load_data_grand_avg_vis_comps}
comps.grand.avg.allbins <- read.csv(paste0(expphase,"_vis_comp_timecourse.csv"),header=TRUE,check.names=FALSE) # load data (check.names=FALSE eliminates the "X" at the beginning of each timepoint)
comps.grand.avg.allbins <- melt(comps.grand.avg.allbins,id.vars=c("component","bin"),variable.name="timepoint",value.name="amplitude") # transform to long format
comps.grand.avg.allbins$timepoint <- as.numeric(levels(comps.grand.avg.allbins$timepoint))[comps.grand.avg.allbins$timepoint] # convert time points to number
levels(comps.grand.avg.allbins$bin) <- c("all","negativeLargeBright","negativeLargeDark","negativeSmallBright","negativeSmallDark","neutralLargeBright","neutralLargeDark","neutralSmallBright","neutralSmallDark") # eliminate annoying space in some level names
comps.grand.avg.allbins$size <- revalue(factor(comps.grand.avg.allbins$bin),c("all"="all","negativeLargeBright"="large","negativeLargeDark"="large","negativeSmallBright"="small","negativeSmallDark"="small","neutralLargeBright"="large","neutralLargeDark"="large","neutralSmallBright"="small","neutralSmallDark"="small")) # main effect of size
comps.grand.avg.allbins$cont <- revalue(factor(comps.grand.avg.allbins$bin),c("all"="all","negativeLargeBright"="bright","negativeLargeDark"="dark","negativeSmallBright"="bright","negativeSmallDark"="dark","neutralLargeBright"="bright","neutralLargeDark"="dark","neutralSmallBright"="bright","neutralSmallDark"="dark")) # main effect of contrast
comps.grand.avg.allbins$emo <- revalue(factor(comps.grand.avg.allbins$bin),c("all"="all","negativeLargeBright"="negative","negativeLargeDark"="negative","negativeSmallBright"="negative","negativeSmallDark"="negative","neutralLargeBright"="neutral","neutralLargeDark"="neutral","neutralSmallBright"="neutral","neutralSmallDark"="neutral")) # main effect of emotion
```

<center> <h1>*P1*</h1> </center>

Time window: 82 - 200 ms   
Electrode cluster: P9 P7 PO7 O1 O2 PO8 P8 P10   
   
```{r P1_topo}
# average across selected time points
P1.topos.grand.avg.allbins <- summarySEwithin(subset(grand.avg.allbins,timepoint >= 82 & timepoint <= 200),"amplitude",withinvars="electrode")
# electrode locations and amplitudes in the same data frame
P1.topos.grand.avg.allbins <- cbind(electrodeLocs,P1.topos.grand.avg.allbins[,"amplitude"])
names(P1.topos.grand.avg.allbins)[8] <- "amplitude" # change variable name

# plot topography
amplim <- c(-.5,.5) # min/max amplitude limit
contour.binwidth <- .1 # map contour

splineSmooth <- gam(amplitude~s(x,y,bs='ts'),data=P1.topos.grand.avg.allbins)
GAMtopo <- data.frame(expand.grid(x=seq(min(P1.topos.grand.avg.allbins$x)*2,
                                        max(P1.topos.grand.avg.allbins$x)*2,
                                        length=gridRes),
                                  y=seq(min(P1.topos.grand.avg.allbins$y)*2,
                                        max(P1.topos.grand.avg.allbins$y)*2,
                                        length=gridRes)))
GAMtopo$amplitude <-  predict(splineSmooth,GAMtopo,type="response")
GAMtopo$incircle <- (GAMtopo$x)^2+(GAMtopo$y)^2<.7^2
# plot topography
ggplot(GAMtopo[GAMtopo$incircle,],aes(x,y,fill=amplitude)) +
  geom_raster() +
  stat_contour(aes(z=amplitude),binwidth=contour.binwidth) +
  theme_topo() +
  scale_fill_gradientn(colours=jet.colors(10),
                       limits=amplim,
                       guide="colourbar",
                       oob=squish) +
  geom_path(data=maskRing,aes(x,y,z=NULL,fill=NULL),colour="white",size=6) +
  geom_point(data=P1.topos.grand.avg.allbins,
             aes(x,y,fill=NULL)) +
  geom_path(data=nose,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  geom_path(data=headShape,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  ggtitle("P1 (82 - 200 ms)") + 
  coord_quickmap()
```

```{r P1_waves}
ggplot(subset(comps.grand.avg.allbins,component=="P1" & bin!="all"),aes(timepoint,amplitude)) + # basic plot
  geom_line(aes(color=bin),size=1.5,alpha=.6) + # one line per bin
  scale_colour_brewer(palette="Dark2") + # color palette
  labs(title="P1 (82 - 200 ms)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,50),limits=c(-100,250)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # horizontal reference line
  annotate("rect",xmin=82,xmax=200,ymin=-1,ymax=2.5,alpha=.2) + # highlight time window used for analysis
  theme_pander(base_size=20,pc="white",lp=c(.5,.8)) # custom theme
```

# Analysis of local peak amplitude

```{r P1_locpeakamp}
P1.locpeakamp <- read.table("P1_locpeakamp.txt",header=TRUE) # load data
P1.locpeakamp <- P1.locpeakamp[,c("ERPset","binlabel","value")] # subset and reorder columns
names(P1.locpeakamp) <- c("participant","condition","amplitude") # rename columns
P1.locpeakamp$size <- revalue(P1.locpeakamp$condition,c("negativeLargeBright"="large","negativeLargeDark"="large","negativeSmallBright"="small","negativeSmallDark"="small","neutralLargeBright"="large","neutralLargeDark"="large","neutralSmallBright"="small","neutralSmallDark"="small")) # main effect of size
P1.locpeakamp$cont <- revalue(factor(P1.locpeakamp$condition),c("negativeLargeBright"="bright","negativeLargeDark"="dark","negativeSmallBright"="bright","negativeSmallDark"="dark","neutralLargeBright"="bright","neutralLargeDark"="dark","neutralSmallBright"="bright","neutralSmallDark"="dark")) # main effect of contrast
P1.locpeakamp$emo <- revalue(factor(P1.locpeakamp$condition),c("negativeLargeBright"="negative","negativeLargeDark"="negative","negativeSmallBright"="negative","negativeSmallDark"="negative","neutralLargeBright"="neutral","neutralLargeDark"="neutral","neutralSmallBright"="neutral","neutralSmallDark"="neutral")) # main effect of emotion

# summarize data
summary.P1.locpeakamp <- summarySEwithin(P1.locpeakamp,"amplitude",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.P1.locpeakamp)

# P1 graph
pirateplot(formula=amplitude~emo+cont+size, # dependent~independent variables
           data=P1.locpeakamp, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-1,8), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
par(mfrow=c(1,1)) # plotting environment back to one graph per graphic device
```

Calculate and compare the Bayes Factor of different linear mixed-effects models. The random factors are participants, and their variance is set as nuisance.   
   
We will compare (against the null model) the following models:   
   
1. main effects of size and emotion   
2. interactive effects of size and emotion   
3. main effects of contrast and emotion   
4. interactive effects of contrast and emotion   
5. main effects of size, contrast, and emotion   
6. interactive effects of size, contrast, and emotion   
   
We will then compare the best competing models to understand which one should be preferred overall.   

```{r P1_models_locpeakamp}
niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,.707,1) # scaling factors of JZS prior: narrow, medium, wide

compare.P1.locpeakamp.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.locpeakamp.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  # P1.locpeakamp.sizeplusemo.BF <- lmBF(amplitude~size+emo,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.sizeplusemo.BF,file=paste0("P1_locpeakamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.sizeplusemo.BF <- readRDS(paste0("P1_locpeakamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # P1.locpeakamp.sizebyemo.BF <- lmBF(amplitude~size:emo,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.sizebyemo.BF,file=paste0("P1_locpeakamp_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.sizebyemo.BF <- readRDS(paste0("P1_locpeakamp_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
      
  ### main effects of contrast and emotion
  # P1.locpeakamp.contplusemo.BF <- lmBF(amplitude~cont+emo,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.contplusemo.BF,file=paste0("P1_locpeakamp_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.contplusemo.BF <- readRDS(paste0("P1_locpeakamp_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # P1.locpeakamp.contbyemo.BF <- lmBF(amplitude~cont:emo,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.contbyemo.BF,file=paste0("P1_locpeakamp_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.contbyemo.BF <- readRDS(paste0("P1_locpeakamp_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # P1.locpeakamp.sizepluscontplusemo.BF <- lmBF(amplitude~size+cont+emo,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.sizepluscontplusemo.BF,file=paste0("P1_locpeakamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.sizepluscontplusemo.BF <- readRDS(paste0("P1_locpeakamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # P1.locpeakamp.sizebycontbyemo.BF <- lmBF(amplitude~size:cont:emo,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.sizebycontbyemo.BF,file=paste0("P1_locpeakamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.sizebycontbyemo.BF <- readRDS(paste0("P1_locpeakamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model

### model comparison
# BFs
compare.P1.locpeakamp.BF[,k] <- c(exp(1)^P1.locpeakamp.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeakamp.sizebyemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeakamp.contplusemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeakamp.contbyemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeakamp.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeakamp.sizebycontbyemo.BF@bayesFactor$bf[1])
# percentage of error
compare.P1.locpeakamp.perc.err[,k] <- c(P1.locpeakamp.sizeplusemo.BF@bayesFactor$error[1]*100,P1.locpeakamp.sizebyemo.BF@bayesFactor$error[1]*100,P1.locpeakamp.contplusemo.BF@bayesFactor$error[1]*100,P1.locpeakamp.contbyemo.BF@bayesFactor$error[1]*100,P1.locpeakamp.sizepluscontplusemo.BF@bayesFactor$error[1]*100,P1.locpeakamp.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}
# summary
compare.P1.locpeakamp <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=compare.P1.locpeakamp.BF[,1],"nar.p.err"=round(compare.P1.locpeakamp.perc.err[,1],digits=3),
"med"=compare.P1.locpeakamp.BF[,2],"med.p.err"=round(compare.P1.locpeakamp.perc.err[,2],digits=3),
"wid"=compare.P1.locpeakamp.BF[,3],"wid.p.err"=round(compare.P1.locpeakamp.perc.err[,3],digits=3))
compare.P1.locpeakamp <- compare.P1.locpeakamp[order(compare.P1.locpeakamp$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.P1.locpeakamp)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.P1.locpeakamp[1,4]<1,"null",as.character(compare.P1.locpeakamp[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.P1.locpeakamp[1,1])`) explains the observed data `r ifelse(compare.P1.locpeakamp[1,4]>1,compare.P1.locpeakamp[1,4]/compare.P1.locpeakamp[2,4],1/compare.P1.locpeakamp[1,4])` times better than the second best model (`r as.character(compare.P1.locpeakamp[2,1])`).   

# Paired comparisons

```{r P1_models_locpeakamp_posthoc_size}
# summarize data
summary.P1.locpeakamp.size <- summarySEwithin(P1.locpeakamp,"amplitude",withinvars="size",idvar="participant")
kable(summary.P1.locpeakamp.size)

# P1 graph
pirateplot(formula=amplitude~size, # dependent~independent variables
           data=P1.locpeakamp, # data frame
           main="size", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-1,8), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.P1.locpeakamp.size.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.locpeakamp.size.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  # ### main effect of size 
  # P1.locpeakamp.size.BF <- lmBF(amplitude~size,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.size.BF,file=paste0("P1_locpeakamp_size_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.size.BF <- readRDS(paste0("P1_locpeakamp_size_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.P1.locpeakamp.size.BF[,k] <- exp(1)^P1.locpeakamp.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.P1.locpeakamp.size.perc.err[,k] <- P1.locpeakamp.size.BF@bayesFactor$error[1]*100
}

# summary
compare.P1.locpeakamp.size <- data.frame("model"="size",
"nar"=compare.P1.locpeakamp.size.BF[,1],"nar.p.err"=round(compare.P1.locpeakamp.size.perc.err[,1],digits=3),
"med"=compare.P1.locpeakamp.size.BF[,2],"med.p.err"=round(compare.P1.locpeakamp.size.perc.err[,2],digits=3),
"wid"=compare.P1.locpeakamp.size.BF[,3],"wid.p.err"=round(compare.P1.locpeakamp.size.perc.err[,3],digits=3))
compare.P1.locpeakamp.size <- compare.P1.locpeakamp.size[order(compare.P1.locpeakamp.size$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.P1.locpeakamp.size)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the `r ifelse(compare.P1.locpeakamp.size[1,4]<1,"null",as.character(compare.P1.locpeakamp.size[1,1]))` model explains the observed data `r ifelse(compare.P1.locpeakamp.size[1,4]>1,compare.P1.locpeakamp.size[1,4],1/compare.P1.locpeakamp.size[1,4])` times better than the `r ifelse(compare.P1.locpeakamp.size[1,4]>1,"null",as.character(compare.P1.locpeakamp.size[1,1]))` model.

```{r P1_models_locpeakamp_posthoc_cont}
# summarize data
summary.P1.locpeakamp.cont <- summarySEwithin(P1.locpeakamp,"amplitude",withinvars="cont",idvar="participant")
kable(summary.P1.locpeakamp.cont)

# P1 graph
pirateplot(formula=amplitude~cont, # dependent~independent variables
           data=P1.locpeakamp, # data frame
           main="contrast", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-1,8), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.P1.locpeakamp.cont.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.locpeakamp.cont.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of cont 
  # P1.locpeakamp.cont.BF <- lmBF(amplitude~cont,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.cont.BF,file=paste0("P1_locpeakamp_cont_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.cont.BF <- readRDS(paste0("P1_locpeakamp_cont_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.P1.locpeakamp.cont.BF[,k] <- exp(1)^P1.locpeakamp.cont.BF@bayesFactor$bf[1]
  # percentage of error
  compare.P1.locpeakamp.cont.perc.err[,k] <- P1.locpeakamp.cont.BF@bayesFactor$error[1]*100
}

# summary
compare.P1.locpeakamp.cont <- data.frame("model"="cont",
"nar"=compare.P1.locpeakamp.cont.BF[,1],"nar.p.err"=round(compare.P1.locpeakamp.cont.perc.err[,1],digits=3),
"med"=compare.P1.locpeakamp.cont.BF[,2],"med.p.err"=round(compare.P1.locpeakamp.cont.perc.err[,2],digits=3),
"wid"=compare.P1.locpeakamp.cont.BF[,3],"wid.p.err"=round(compare.P1.locpeakamp.cont.perc.err[,3],digits=3))
compare.P1.locpeakamp.cont <- compare.P1.locpeakamp.cont[order(compare.P1.locpeakamp.cont$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.P1.locpeakamp.cont)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect conts, the `r ifelse(compare.P1.locpeakamp.cont[1,4]<1,"null",as.character(compare.P1.locpeakamp.cont[1,1]))` model explains the observed data `r ifelse(compare.P1.locpeakamp.cont[1,4]>1,compare.P1.locpeakamp.cont[1,4],1/compare.P1.locpeakamp.cont[1,4])` times better than the `r ifelse(compare.P1.locpeakamp.cont[1,4]>1,"null",as.character(compare.P1.locpeakamp.cont[1,1]))` model.

```{r P1_models_locpeakamp_posthoc_emo}
# summarize data
summary.P1.locpeakamp.emo <- summarySEwithin(P1.locpeakamp,"amplitude",withinvars="emo",idvar="participant")
kable(summary.P1.locpeakamp.emo)

# P1 graph
pirateplot(formula=amplitude~emo, # dependent~independent variables
           data=P1.locpeakamp, # data frame
           main="emotion", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-1,8), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.P1.locpeakamp.emo.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.locpeakamp.emo.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of emo 
  # P1.locpeakamp.emo.BF <- lmBF(amplitude~emo,P1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleemo="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeakamp.emo.BF,file=paste0("P1_locpeakamp_emo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeakamp.emo.BF <- readRDS(paste0("P1_locpeakamp_emo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.P1.locpeakamp.emo.BF[,k] <- exp(1)^P1.locpeakamp.emo.BF@bayesFactor$bf[1]
  # percentage of error
  compare.P1.locpeakamp.emo.perc.err[,k] <- P1.locpeakamp.emo.BF@bayesFactor$error[1]*100
}

# summary
compare.P1.locpeakamp.emo <- data.frame("model"="emo",
"nar"=compare.P1.locpeakamp.emo.BF[,1],"nar.p.err"=round(compare.P1.locpeakamp.emo.perc.err[,1],digits=3),
"med"=compare.P1.locpeakamp.emo.BF[,2],"med.p.err"=round(compare.P1.locpeakamp.emo.perc.err[,2],digits=3),
"wid"=compare.P1.locpeakamp.emo.BF[,3],"wid.p.err"=round(compare.P1.locpeakamp.emo.perc.err[,3],digits=3))
compare.P1.locpeakamp.emo <- compare.P1.locpeakamp.emo[order(compare.P1.locpeakamp.emo$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.P1.locpeakamp.emo)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect emos, the `r ifelse(compare.P1.locpeakamp.emo[1,4]<1,"null",as.character(compare.P1.locpeakamp.emo[1,1]))` model explains the observed data `r ifelse(compare.P1.locpeakamp.emo[1,4]>1,compare.P1.locpeakamp.emo[1,4],1/compare.P1.locpeakamp.emo[1,4])` times better than the `r ifelse(compare.P1.locpeakamp.emo[1,4]>1,"null",as.character(compare.P1.locpeakamp.emo[1,1]))` model.

# Analysis of local peak latency

```{r P1_locpeaklat}
P1.locpeaklat <- read.table("P1_locpeaklat.txt",header=TRUE) # load data
P1.locpeaklat <- P1.locpeaklat[,c("ERPset","binlabel","value")] # subset and reorder columns
names(P1.locpeaklat) <- c("participant","condition","latency") # rename columns
P1.locpeaklat$size <- revalue(P1.locpeaklat$condition,c("negativeLargeBright"="large","negativeLargeDark"="large","negativeSmallBright"="small","negativeSmallDark"="small","neutralLargeBright"="large","neutralLargeDark"="large","neutralSmallBright"="small","neutralSmallDark"="small")) # main effect of size
P1.locpeaklat$cont <- revalue(factor(P1.locpeaklat$condition),c("negativeLargeBright"="bright","negativeLargeDark"="dark","negativeSmallBright"="bright","negativeSmallDark"="dark","neutralLargeBright"="bright","neutralLargeDark"="dark","neutralSmallBright"="bright","neutralSmallDark"="dark")) # main effect of contrast
P1.locpeaklat$emo <- revalue(factor(P1.locpeaklat$condition),c("negativeLargeBright"="negative","negativeLargeDark"="negative","negativeSmallBright"="negative","negativeSmallDark"="negative","neutralLargeBright"="neutral","neutralLargeDark"="neutral","neutralSmallBright"="neutral","neutralSmallDark"="neutral")) # main effect of emotion

# summarize data
summary.P1.locpeaklat <- summarySEwithin(P1.locpeaklat,"latency",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.P1.locpeaklat)

# P1 graph
pirateplot(formula=latency~emo+cont+size, # dependent~independent variables
           data=P1.locpeaklat, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(0,150), # y-axis: limits
           ylab="latency (ms)", # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
par(mfrow=c(1,1)) # plotting environment back to one graph per graphic device
```

```{r P1_models_locpeaklat}
compare.P1.locpeaklat.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.locpeaklat.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  # P1.locpeaklat.sizeplusemo.BF <- lmBF(latency~size+emo,P1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeaklat.sizeplusemo.BF,file=paste0("P1_locpeaklat_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeaklat.sizeplusemo.BF <- readRDS(paste0("P1_locpeaklat_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # P1.locpeaklat.sizebyemo.BF <- lmBF(latency~size:emo,P1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeaklat.sizebyemo.BF,file=paste0("P1_locpeaklat_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeaklat.sizebyemo.BF <- readRDS(paste0("P1_locpeaklat_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
      
  ### main effects of contrast and emotion
  # P1.locpeaklat.contplusemo.BF <- lmBF(latency~cont+emo,P1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeaklat.contplusemo.BF,file=paste0("P1_locpeaklat_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeaklat.contplusemo.BF <- readRDS(paste0("P1_locpeaklat_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # P1.locpeaklat.contbyemo.BF <- lmBF(latency~cont:emo,P1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeaklat.contbyemo.BF,file=paste0("P1_locpeaklat_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeaklat.contbyemo.BF <- readRDS(paste0("P1_locpeaklat_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # P1.locpeaklat.sizepluscontplusemo.BF <- lmBF(latency~size+cont+emo,P1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeaklat.sizepluscontplusemo.BF,file=paste0("P1_locpeaklat_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeaklat.sizepluscontplusemo.BF <- readRDS(paste0("P1_locpeaklat_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # P1.locpeaklat.sizebycontbyemo.BF <- lmBF(latency~size:cont:emo,P1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeaklat.sizebycontbyemo.BF,file=paste0("P1_locpeaklat_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeaklat.sizebycontbyemo.BF <- readRDS(paste0("P1_locpeaklat_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model

### model comparison
# BFs
compare.P1.locpeaklat.BF[,k] <- c(exp(1)^P1.locpeaklat.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeaklat.sizebyemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeaklat.contplusemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeaklat.contbyemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeaklat.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^P1.locpeaklat.sizebycontbyemo.BF@bayesFactor$bf[1])
# percentage of error
compare.P1.locpeaklat.perc.err[,k] <- c(P1.locpeaklat.sizeplusemo.BF@bayesFactor$error[1]*100,P1.locpeaklat.sizebyemo.BF@bayesFactor$error[1]*100,P1.locpeaklat.contplusemo.BF@bayesFactor$error[1]*100,P1.locpeaklat.contbyemo.BF@bayesFactor$error[1]*100,P1.locpeaklat.sizepluscontplusemo.BF@bayesFactor$error[1]*100,P1.locpeaklat.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}
# summary
compare.P1.locpeaklat <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=compare.P1.locpeaklat.BF[,1],"nar.p.err"=round(compare.P1.locpeaklat.perc.err[,1],digits=3),
"med"=compare.P1.locpeaklat.BF[,2],"med.p.err"=round(compare.P1.locpeaklat.perc.err[,2],digits=3),
"wid"=compare.P1.locpeaklat.BF[,3],"wid.p.err"=round(compare.P1.locpeaklat.perc.err[,3],digits=3))
compare.P1.locpeaklat <- compare.P1.locpeaklat[order(compare.P1.locpeaklat$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.P1.locpeaklat)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.P1.locpeaklat[1,4]<1,"null",as.character(compare.P1.locpeaklat[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.P1.locpeaklat[1,1])`) explains the observed data `r ifelse(compare.P1.locpeaklat[1,4]>1,compare.P1.locpeaklat[1,4]/compare.P1.locpeaklat[2,4],1/compare.P1.locpeaklat[1,4])` times better than the second best model (`r as.character(compare.P1.locpeaklat[2,1])`).   

# Paired comparisons

```{r P1_models_locpeaklat_posthoc_cont}
# summarize data
summary.P1.locpeaklat.cont <- summarySEwithin(P1.locpeaklat,"latency",withinvars="cont",idvar="participant")
kable(summary.P1.locpeaklat.cont)

# P1 graph
pirateplot(formula=latency~cont, # dependent~independent variables
           data=P1.locpeaklat, # data frame
           main="contrast", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(0,150), # y-axis: limits
           ylab="latency (ms)", # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.P1.locpeaklat.cont.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.locpeaklat.cont.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of cont 
  # P1.locpeaklat.cont.BF <- lmBF(latency~cont,P1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeaklat.cont.BF,file=paste0("P1_locpeaklat_cont_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeaklat.cont.BF <- readRDS(paste0("P1_locpeaklat_cont_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.P1.locpeaklat.cont.BF[,k] <- exp(1)^P1.locpeaklat.cont.BF@bayesFactor$bf[1]
  # percentage of error
  compare.P1.locpeaklat.cont.perc.err[,k] <- P1.locpeaklat.cont.BF@bayesFactor$error[1]*100
}

# summary
compare.P1.locpeaklat.cont <- data.frame("model"="cont",
"nar"=compare.P1.locpeaklat.cont.BF[,1],"nar.p.err"=round(compare.P1.locpeaklat.cont.perc.err[,1],digits=3),
"med"=compare.P1.locpeaklat.cont.BF[,2],"med.p.err"=round(compare.P1.locpeaklat.cont.perc.err[,2],digits=3),
"wid"=compare.P1.locpeaklat.cont.BF[,3],"wid.p.err"=round(compare.P1.locpeaklat.cont.perc.err[,3],digits=3))
compare.P1.locpeaklat.cont <- compare.P1.locpeaklat.cont[order(compare.P1.locpeaklat.cont$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.P1.locpeaklat.cont)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect conts, the `r ifelse(compare.P1.locpeaklat.cont[1,4]<1,"null",as.character(compare.P1.locpeaklat.cont[1,1]))` model explains the observed data `r ifelse(compare.P1.locpeaklat.cont[1,4]>1,compare.P1.locpeaklat.cont[1,4],1/compare.P1.locpeaklat.cont[1,4])` times better than the `r ifelse(compare.P1.locpeaklat.cont[1,4]>1,"null",as.character(compare.P1.locpeaklat.cont[1,1]))` model.

```{r P1_models_locpeaklat_posthoc_emo}
# summarize data
summary.P1.locpeaklat.emo <- summarySEwithin(P1.locpeaklat,"latency",withinvars="emo",idvar="participant")
kable(summary.P1.locpeaklat.emo)

# P1 graph
pirateplot(formula=latency~emo, # dependent~independent variables
           data=P1.locpeaklat, # data frame
           main="emotion", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(0,150), # y-axis: limits
           ylab="latency (ms)", # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.P1.locpeaklat.emo.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.locpeaklat.emo.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of emo 
  # P1.locpeaklat.emo.BF <- lmBF(latency~emo,P1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleemo="medium",iterations=niter,posterior=FALSE)
  # saveRDS(P1.locpeaklat.emo.BF,file=paste0("P1_locpeaklat_emo_BF_",scaling.factor[k],".rds")) # save model
  P1.locpeaklat.emo.BF <- readRDS(paste0("P1_locpeaklat_emo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.P1.locpeaklat.emo.BF[,k] <- exp(1)^P1.locpeaklat.emo.BF@bayesFactor$bf[1]
  # percentage of error
  compare.P1.locpeaklat.emo.perc.err[,k] <- P1.locpeaklat.emo.BF@bayesFactor$error[1]*100
}

# summary
compare.P1.locpeaklat.emo <- data.frame("model"="emo",
"nar"=compare.P1.locpeaklat.emo.BF[,1],"nar.p.err"=round(compare.P1.locpeaklat.emo.perc.err[,1],digits=3),
"med"=compare.P1.locpeaklat.emo.BF[,2],"med.p.err"=round(compare.P1.locpeaklat.emo.perc.err[,2],digits=3),
"wid"=compare.P1.locpeaklat.emo.BF[,3],"wid.p.err"=round(compare.P1.locpeaklat.emo.perc.err[,3],digits=3))
compare.P1.locpeaklat.emo <- compare.P1.locpeaklat.emo[order(compare.P1.locpeaklat.emo$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.P1.locpeaklat.emo)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect emos, the `r ifelse(compare.P1.locpeaklat.emo[1,4]<1,"null",as.character(compare.P1.locpeaklat.emo[1,1]))` model explains the observed data `r ifelse(compare.P1.locpeaklat.emo[1,4]>1,compare.P1.locpeaklat.emo[1,4],1/compare.P1.locpeaklat.emo[1,4])` times better than the `r ifelse(compare.P1.locpeaklat.emo[1,4]>1,"null",as.character(compare.P1.locpeaklat.emo[1,1]))` model.

<center> <h1>*N1*</h1> </center>

Time window: 142 - 324 ms   
Electrode cluster: P9 P7 PO7 O1 O2 PO8 P8 P10   

```{r N1_topo}
# average across selected time points
N1.topos.grand.avg.allbins <- summarySEwithin(subset(grand.avg.allbins,timepoint >= 142 & timepoint <= 324),"amplitude",withinvars="electrode")
# electrode locations and amplitudes in the same data frame
N1.topos.grand.avg.allbins <- cbind(electrodeLocs,N1.topos.grand.avg.allbins[,"amplitude"])
names(N1.topos.grand.avg.allbins)[8] <- "amplitude" # change variable name

# plot topography
amplim <- c(-.5,.5) # min/max amplitude limit
contour.binwidth <- .1 # map contour

splineSmooth <- gam(amplitude~s(x,y,bs='ts'),data=N1.topos.grand.avg.allbins)
GAMtopo <- data.frame(expand.grid(x=seq(min(N1.topos.grand.avg.allbins$x)*2,
                                        max(N1.topos.grand.avg.allbins$x)*2,
                                        length=gridRes),
                                  y=seq(min(N1.topos.grand.avg.allbins$y)*2,
                                        max(N1.topos.grand.avg.allbins$y)*2,
                                        length=gridRes)))
GAMtopo$amplitude <-  predict(splineSmooth,GAMtopo,type="response")
GAMtopo$incircle <- (GAMtopo$x)^2+(GAMtopo$y)^2<.7^2
# plot topography
ggplot(GAMtopo[GAMtopo$incircle,],aes(x,y,fill=amplitude)) +
  geom_raster() +
  stat_contour(aes(z=amplitude),binwidth=contour.binwidth) +
  theme_topo() +
  scale_fill_gradientn(colours=jet.colors(10),
                       limits=amplim,
                       guide="colourbar",
                       oob=squish) +
  geom_path(data=maskRing,aes(x,y,z=NULL,fill=NULL),colour="white",size=6) +
  geom_point(data=N1.topos.grand.avg.allbins,
             aes(x,y,fill=NULL)) +
  geom_path(data=nose,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  geom_path(data=headShape,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  ggtitle("N1 (142 - 324 ms)") + 
  coord_quickmap()
```

```{r N1_waves}
ggplot(subset(comps.grand.avg.allbins,component=="N1" & bin!="all"),aes(timepoint,amplitude)) + # basic plot
  geom_line(aes(color=bin),size=1.5,alpha=.6) + # one line per bin
  scale_colour_brewer(palette="Dark2") + # color palette
  labs(title="N1 (142 - 324 ms)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,50),limits=c(-100,500)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # horizontal reference line
  annotate("rect",xmin=142,xmax=324,ymin=-2,ymax=1,alpha=.2) + # highlight time window used for analysis
  theme_pander(base_size=20,pc="white",lp=c(.8,.8)) # custom theme
```

# Analysis of local peak amplitude

```{r N1_locpeakamp}
N1.locpeakamp <- read.table("N1_locpeakamp.txt",header=TRUE) # load data
N1.locpeakamp <- N1.locpeakamp[,c("ERPset","binlabel","value")] # subset and reorder columns
names(N1.locpeakamp) <- c("participant","condition","amplitude") # rename columns
N1.locpeakamp$size <- revalue(N1.locpeakamp$condition,c("negativeLargeBright"="large","negativeLargeDark"="large","negativeSmallBright"="small","negativeSmallDark"="small","neutralLargeBright"="large","neutralLargeDark"="large","neutralSmallBright"="small","neutralSmallDark"="small")) # main effect of size
N1.locpeakamp$cont <- revalue(factor(N1.locpeakamp$condition),c("negativeLargeBright"="bright","negativeLargeDark"="dark","negativeSmallBright"="bright","negativeSmallDark"="dark","neutralLargeBright"="bright","neutralLargeDark"="dark","neutralSmallBright"="bright","neutralSmallDark"="dark")) # main effect of contrast
N1.locpeakamp$emo <- revalue(factor(N1.locpeakamp$condition),c("negativeLargeBright"="negative","negativeLargeDark"="negative","negativeSmallBright"="negative","negativeSmallDark"="negative","neutralLargeBright"="neutral","neutralLargeDark"="neutral","neutralSmallBright"="neutral","neutralSmallDark"="neutral")) # main effect of emotion

# summarize data
summary.N1.locpeakamp <- summarySEwithin(N1.locpeakamp,"amplitude",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.N1.locpeakamp)

# N1 graph
pirateplot(formula=amplitude~emo+cont+size, # dependent~independent variables
           data=N1.locpeakamp, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-7,1), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
par(mfrow=c(1,1)) # plotting environment back to one graph per graphic device
```

```{r N1_models_locpeakamp}
compare.N1.locpeakamp.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.locpeakamp.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  # N1.locpeakamp.sizeplusemo.BF <- lmBF(amplitude~size+emo,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.sizeplusemo.BF,file=paste0("N1_locpeakamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.sizeplusemo.BF <- readRDS(paste0("N1_locpeakamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # N1.locpeakamp.sizebyemo.BF <- lmBF(amplitude~size:emo,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.sizebyemo.BF,file=paste0("N1_locpeakamp_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.sizebyemo.BF <- readRDS(paste0("N1_locpeakamp_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
      
  ### main effects of contrast and emotion
  # N1.locpeakamp.contplusemo.BF <- lmBF(amplitude~cont+emo,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.contplusemo.BF,file=paste0("N1_locpeakamp_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.contplusemo.BF <- readRDS(paste0("N1_locpeakamp_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # N1.locpeakamp.contbyemo.BF <- lmBF(amplitude~cont:emo,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.contbyemo.BF,file=paste0("N1_locpeakamp_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.contbyemo.BF <- readRDS(paste0("N1_locpeakamp_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # N1.locpeakamp.sizepluscontplusemo.BF <- lmBF(amplitude~size+cont+emo,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.sizepluscontplusemo.BF,file=paste0("N1_locpeakamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.sizepluscontplusemo.BF <- readRDS(paste0("N1_locpeakamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # N1.locpeakamp.sizebycontbyemo.BF <- lmBF(amplitude~size:cont:emo,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.sizebycontbyemo.BF,file=paste0("N1_locpeakamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.sizebycontbyemo.BF <- readRDS(paste0("N1_locpeakamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model

### model comparison
# BFs
compare.N1.locpeakamp.BF[,k] <- c(exp(1)^N1.locpeakamp.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeakamp.sizebyemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeakamp.contplusemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeakamp.contbyemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeakamp.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeakamp.sizebycontbyemo.BF@bayesFactor$bf[1])
# percentage of error
compare.N1.locpeakamp.perc.err[,k] <- c(N1.locpeakamp.sizeplusemo.BF@bayesFactor$error[1]*100,N1.locpeakamp.sizebyemo.BF@bayesFactor$error[1]*100,N1.locpeakamp.contplusemo.BF@bayesFactor$error[1]*100,N1.locpeakamp.contbyemo.BF@bayesFactor$error[1]*100,N1.locpeakamp.sizepluscontplusemo.BF@bayesFactor$error[1]*100,N1.locpeakamp.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}
# summary
compare.N1.locpeakamp <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=compare.N1.locpeakamp.BF[,1],"nar.p.err"=round(compare.N1.locpeakamp.perc.err[,1],digits=3),
"med"=compare.N1.locpeakamp.BF[,2],"med.p.err"=round(compare.N1.locpeakamp.perc.err[,2],digits=3),
"wid"=compare.N1.locpeakamp.BF[,3],"wid.p.err"=round(compare.N1.locpeakamp.perc.err[,3],digits=3))
compare.N1.locpeakamp <- compare.N1.locpeakamp[order(compare.N1.locpeakamp$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1.locpeakamp)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.N1.locpeakamp[1,4]<1,"null",as.character(compare.N1.locpeakamp[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.N1.locpeakamp[1,1])`) explains the observed data `r ifelse(compare.N1.locpeakamp[1,4]>1,compare.N1.locpeakamp[1,4]/compare.N1.locpeakamp[2,4],1/compare.N1.locpeakamp[1,4])` times better than the second best model (`r as.character(compare.N1.locpeakamp[2,1])`).   

# Paired comparisons

```{r N1_models_locpeakamp_posthoc_size}
# summarize data
summary.N1.locpeakamp.size <- summarySEwithin(N1.locpeakamp,"amplitude",withinvars="size",idvar="participant")
kable(summary.N1.locpeakamp.size)

# N1 graph
pirateplot(formula=amplitude~size, # dependent~independent variables
           data=N1.locpeakamp, # data frame
           main="size", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-7,1), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.N1.locpeakamp.size.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.locpeakamp.size.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  # ### main effect of size 
  # N1.locpeakamp.size.BF <- lmBF(amplitude~size,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.size.BF,file=paste0("N1_locpeakamp_size_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.size.BF <- readRDS(paste0("N1_locpeakamp_size_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.N1.locpeakamp.size.BF[,k] <- exp(1)^N1.locpeakamp.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.N1.locpeakamp.size.perc.err[,k] <- N1.locpeakamp.size.BF@bayesFactor$error[1]*100
}

# summary
compare.N1.locpeakamp.size <- data.frame("model"="size",
"nar"=compare.N1.locpeakamp.size.BF[,1],"nar.p.err"=round(compare.N1.locpeakamp.size.perc.err[,1],digits=3),
"med"=compare.N1.locpeakamp.size.BF[,2],"med.p.err"=round(compare.N1.locpeakamp.size.perc.err[,2],digits=3),
"wid"=compare.N1.locpeakamp.size.BF[,3],"wid.p.err"=round(compare.N1.locpeakamp.size.perc.err[,3],digits=3))
compare.N1.locpeakamp.size <- compare.N1.locpeakamp.size[order(compare.N1.locpeakamp.size$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1.locpeakamp.size)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the `r ifelse(compare.N1.locpeakamp.size[1,4]<1,"null",as.character(compare.N1.locpeakamp.size[1,1]))` model explains the observed data `r ifelse(compare.N1.locpeakamp.size[1,4]>1,compare.N1.locpeakamp.size[1,4],1/compare.N1.locpeakamp.size[1,4])` times better than the `r ifelse(compare.N1.locpeakamp.size[1,4]>1,"null",as.character(compare.N1.locpeakamp.size[1,1]))` model.

```{r N1_models_locpeakamp_posthoc_cont}
# summarize data
summary.N1.locpeakamp.cont <- summarySEwithin(N1.locpeakamp,"amplitude",withinvars="cont",idvar="participant")
kable(summary.N1.locpeakamp.cont)

# N1 graph
pirateplot(formula=amplitude~cont, # dependent~independent variables
           data=N1.locpeakamp, # data frame
           main="contrast", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-7,1), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.N1.locpeakamp.cont.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.locpeakamp.cont.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of cont 
  # N1.locpeakamp.cont.BF <- lmBF(amplitude~cont,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.cont.BF,file=paste0("N1_locpeakamp_cont_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.cont.BF <- readRDS(paste0("N1_locpeakamp_cont_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.N1.locpeakamp.cont.BF[,k] <- exp(1)^N1.locpeakamp.cont.BF@bayesFactor$bf[1]
  # percentage of error
  compare.N1.locpeakamp.cont.perc.err[,k] <- N1.locpeakamp.cont.BF@bayesFactor$error[1]*100
}

# summary
compare.N1.locpeakamp.cont <- data.frame("model"="cont",
"nar"=compare.N1.locpeakamp.cont.BF[,1],"nar.p.err"=round(compare.N1.locpeakamp.cont.perc.err[,1],digits=3),
"med"=compare.N1.locpeakamp.cont.BF[,2],"med.p.err"=round(compare.N1.locpeakamp.cont.perc.err[,2],digits=3),
"wid"=compare.N1.locpeakamp.cont.BF[,3],"wid.p.err"=round(compare.N1.locpeakamp.cont.perc.err[,3],digits=3))
compare.N1.locpeakamp.cont <- compare.N1.locpeakamp.cont[order(compare.N1.locpeakamp.cont$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1.locpeakamp.cont)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect conts, the `r ifelse(compare.N1.locpeakamp.cont[1,4]<1,"null",as.character(compare.N1.locpeakamp.cont[1,1]))` model explains the observed data `r ifelse(compare.N1.locpeakamp.cont[1,4]>1,compare.N1.locpeakamp.cont[1,4],1/compare.N1.locpeakamp.cont[1,4])` times better than the `r ifelse(compare.N1.locpeakamp.cont[1,4]>1,"null",as.character(compare.N1.locpeakamp.cont[1,1]))` model.

```{r N1_models_locpeakamp_posthoc_emo}
# summarize data
summary.N1.locpeakamp.emo <- summarySEwithin(N1.locpeakamp,"amplitude",withinvars="emo",idvar="participant")
kable(summary.N1.locpeakamp.emo)

# N1 graph
pirateplot(formula=amplitude~emo, # dependent~independent variables
           data=N1.locpeakamp, # data frame
           main="emotion", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-7,1), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.N1.locpeakamp.emo.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.locpeakamp.emo.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of emo 
  # N1.locpeakamp.emo.BF <- lmBF(amplitude~emo,N1.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleemo="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeakamp.emo.BF,file=paste0("N1_locpeakamp_emo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeakamp.emo.BF <- readRDS(paste0("N1_locpeakamp_emo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.N1.locpeakamp.emo.BF[,k] <- exp(1)^N1.locpeakamp.emo.BF@bayesFactor$bf[1]
  # percentage of error
  compare.N1.locpeakamp.emo.perc.err[,k] <- N1.locpeakamp.emo.BF@bayesFactor$error[1]*100
}

# summary
compare.N1.locpeakamp.emo <- data.frame("model"="emo",
"nar"=compare.N1.locpeakamp.emo.BF[,1],"nar.p.err"=round(compare.N1.locpeakamp.emo.perc.err[,1],digits=3),
"med"=compare.N1.locpeakamp.emo.BF[,2],"med.p.err"=round(compare.N1.locpeakamp.emo.perc.err[,2],digits=3),
"wid"=compare.N1.locpeakamp.emo.BF[,3],"wid.p.err"=round(compare.N1.locpeakamp.emo.perc.err[,3],digits=3))
compare.N1.locpeakamp.emo <- compare.N1.locpeakamp.emo[order(compare.N1.locpeakamp.emo$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1.locpeakamp.emo)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect emos, the `r ifelse(compare.N1.locpeakamp.emo[1,4]<1,"null",as.character(compare.N1.locpeakamp.emo[1,1]))` model explains the observed data `r ifelse(compare.N1.locpeakamp.emo[1,4]>1,compare.N1.locpeakamp.emo[1,4],1/compare.N1.locpeakamp.emo[1,4])` times better than the `r ifelse(compare.N1.locpeakamp.emo[1,4]>1,"null",as.character(compare.N1.locpeakamp.emo[1,1]))` model.

# Analysis of local peak latency

```{r N1_locpeaklat}
N1.locpeaklat <- read.table("N1_locpeaklat.txt",header=TRUE) # load data
N1.locpeaklat <- N1.locpeaklat[,c("ERPset","binlabel","value")] # subset and reorder columns
names(N1.locpeaklat) <- c("participant","condition","latency") # rename columns
N1.locpeaklat$size <- revalue(N1.locpeaklat$condition,c("negativeLargeBright"="large","negativeLargeDark"="large","negativeSmallBright"="small","negativeSmallDark"="small","neutralLargeBright"="large","neutralLargeDark"="large","neutralSmallBright"="small","neutralSmallDark"="small")) # main effect of size
N1.locpeaklat$cont <- revalue(factor(N1.locpeaklat$condition),c("negativeLargeBright"="bright","negativeLargeDark"="dark","negativeSmallBright"="bright","negativeSmallDark"="dark","neutralLargeBright"="bright","neutralLargeDark"="dark","neutralSmallBright"="bright","neutralSmallDark"="dark")) # main effect of contrast
N1.locpeaklat$emo <- revalue(factor(N1.locpeaklat$condition),c("negativeLargeBright"="negative","negativeLargeDark"="negative","negativeSmallBright"="negative","negativeSmallDark"="negative","neutralLargeBright"="neutral","neutralLargeDark"="neutral","neutralSmallBright"="neutral","neutralSmallDark"="neutral")) # main effect of emotion

# summarize data
summary.N1.locpeaklat <- summarySEwithin(N1.locpeaklat,"latency",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.N1.locpeaklat)

# N1 graph
pirateplot(formula=latency~emo+cont+size, # dependent~independent variables
           data=N1.locpeaklat, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(150,260), # y-axis: limits
           ylab="latency (ms)", # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
par(mfrow=c(1,1)) # plotting environment back to one graph per graphic device
```

```{r N1_models_locpeaklat}
compare.N1.locpeaklat.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.locpeaklat.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  # N1.locpeaklat.sizeplusemo.BF <- lmBF(latency~size+emo,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.sizeplusemo.BF,file=paste0("N1_locpeaklat_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.sizeplusemo.BF <- readRDS(paste0("N1_locpeaklat_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # N1.locpeaklat.sizebyemo.BF <- lmBF(latency~size:emo,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.sizebyemo.BF,file=paste0("N1_locpeaklat_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.sizebyemo.BF <- readRDS(paste0("N1_locpeaklat_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
      
  ### main effects of contrast and emotion
  # N1.locpeaklat.contplusemo.BF <- lmBF(latency~cont+emo,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.contplusemo.BF,file=paste0("N1_locpeaklat_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.contplusemo.BF <- readRDS(paste0("N1_locpeaklat_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # N1.locpeaklat.contbyemo.BF <- lmBF(latency~cont:emo,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.contbyemo.BF,file=paste0("N1_locpeaklat_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.contbyemo.BF <- readRDS(paste0("N1_locpeaklat_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # N1.locpeaklat.sizepluscontplusemo.BF <- lmBF(latency~size+cont+emo,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.sizepluscontplusemo.BF,file=paste0("N1_locpeaklat_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.sizepluscontplusemo.BF <- readRDS(paste0("N1_locpeaklat_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # N1.locpeaklat.sizebycontbyemo.BF <- lmBF(latency~size:cont:emo,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.sizebycontbyemo.BF,file=paste0("N1_locpeaklat_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.sizebycontbyemo.BF <- readRDS(paste0("N1_locpeaklat_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model

### model comparison
# BFs
compare.N1.locpeaklat.BF[,k] <- c(exp(1)^N1.locpeaklat.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeaklat.sizebyemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeaklat.contplusemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeaklat.contbyemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeaklat.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^N1.locpeaklat.sizebycontbyemo.BF@bayesFactor$bf[1])
# percentage of error
compare.N1.locpeaklat.perc.err[,k] <- c(N1.locpeaklat.sizeplusemo.BF@bayesFactor$error[1]*100,N1.locpeaklat.sizebyemo.BF@bayesFactor$error[1]*100,N1.locpeaklat.contplusemo.BF@bayesFactor$error[1]*100,N1.locpeaklat.contbyemo.BF@bayesFactor$error[1]*100,N1.locpeaklat.sizepluscontplusemo.BF@bayesFactor$error[1]*100,N1.locpeaklat.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}
# summary
compare.N1.locpeaklat <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=compare.N1.locpeaklat.BF[,1],"nar.p.err"=round(compare.N1.locpeaklat.perc.err[,1],digits=3),
"med"=compare.N1.locpeaklat.BF[,2],"med.p.err"=round(compare.N1.locpeaklat.perc.err[,2],digits=3),
"wid"=compare.N1.locpeaklat.BF[,3],"wid.p.err"=round(compare.N1.locpeaklat.perc.err[,3],digits=3))
compare.N1.locpeaklat <- compare.N1.locpeaklat[order(compare.N1.locpeaklat$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1.locpeaklat)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.N1.locpeaklat[1,4]<1,"null",as.character(compare.N1.locpeaklat[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.N1.locpeaklat[1,1])`) explains the observed data `r ifelse(compare.N1.locpeaklat[1,4]>1,compare.N1.locpeaklat[1,4]/compare.N1.locpeaklat[2,4],1/compare.N1.locpeaklat[1,4])` times better than the second best model (`r as.character(compare.N1.locpeaklat[2,1])`).   

# Paired comparisons

```{r N1_models_locpeaklat_posthoc_size}
# summarize data
summary.N1.locpeaklat.size <- summarySEwithin(N1.locpeaklat,"latency",withinvars="size",idvar="participant")
kable(summary.N1.locpeaklat.size)

# N1 graph
pirateplot(formula=latency~size, # dependent~independent variables
           data=N1.locpeaklat, # data frame
           main="size", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(150,260), # y-axis: limits
           ylab="latency (ms)", # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.N1.locpeaklat.size.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.locpeaklat.size.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  # ### main effect of size 
  # N1.locpeaklat.size.BF <- lmBF(latency~size,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.size.BF,file=paste0("N1_locpeaklat_size_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.size.BF <- readRDS(paste0("N1_locpeaklat_size_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.N1.locpeaklat.size.BF[,k] <- exp(1)^N1.locpeaklat.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.N1.locpeaklat.size.perc.err[,k] <- N1.locpeaklat.size.BF@bayesFactor$error[1]*100
}

# summary
compare.N1.locpeaklat.size <- data.frame("model"="size",
"nar"=compare.N1.locpeaklat.size.BF[,1],"nar.p.err"=round(compare.N1.locpeaklat.size.perc.err[,1],digits=3),
"med"=compare.N1.locpeaklat.size.BF[,2],"med.p.err"=round(compare.N1.locpeaklat.size.perc.err[,2],digits=3),
"wid"=compare.N1.locpeaklat.size.BF[,3],"wid.p.err"=round(compare.N1.locpeaklat.size.perc.err[,3],digits=3))
compare.N1.locpeaklat.size <- compare.N1.locpeaklat.size[order(compare.N1.locpeaklat.size$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1.locpeaklat.size)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the `r ifelse(compare.N1.locpeaklat.size[1,4]<1,"null",as.character(compare.N1.locpeaklat.size[1,1]))` model explains the observed data `r ifelse(compare.N1.locpeaklat.size[1,4]>1,compare.N1.locpeaklat.size[1,4],1/compare.N1.locpeaklat.size[1,4])` times better than the `r ifelse(compare.N1.locpeaklat.size[1,4]>1,"null",as.character(compare.N1.locpeaklat.size[1,1]))` model.

```{r N1_models_locpeaklat_posthoc_cont}
# summarize data
summary.N1.locpeaklat.cont <- summarySEwithin(N1.locpeaklat,"latency",withinvars="cont",idvar="participant")
kable(summary.N1.locpeaklat.cont)

# N1 graph
pirateplot(formula=latency~cont, # dependent~independent variables
           data=N1.locpeaklat, # data frame
           main="contrast", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(150,260), # y-axis: limits
           ylab=expression(paste("latency (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.N1.locpeaklat.cont.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.locpeaklat.cont.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of cont 
  # N1.locpeaklat.cont.BF <- lmBF(latency~cont,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.cont.BF,file=paste0("N1_locpeaklat_cont_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.cont.BF <- readRDS(paste0("N1_locpeaklat_cont_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.N1.locpeaklat.cont.BF[,k] <- exp(1)^N1.locpeaklat.cont.BF@bayesFactor$bf[1]
  # percentage of error
  compare.N1.locpeaklat.cont.perc.err[,k] <- N1.locpeaklat.cont.BF@bayesFactor$error[1]*100
}

# summary
compare.N1.locpeaklat.cont <- data.frame("model"="cont",
"nar"=compare.N1.locpeaklat.cont.BF[,1],"nar.p.err"=round(compare.N1.locpeaklat.cont.perc.err[,1],digits=3),
"med"=compare.N1.locpeaklat.cont.BF[,2],"med.p.err"=round(compare.N1.locpeaklat.cont.perc.err[,2],digits=3),
"wid"=compare.N1.locpeaklat.cont.BF[,3],"wid.p.err"=round(compare.N1.locpeaklat.cont.perc.err[,3],digits=3))
compare.N1.locpeaklat.cont <- compare.N1.locpeaklat.cont[order(compare.N1.locpeaklat.cont$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1.locpeaklat.cont)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect conts, the `r ifelse(compare.N1.locpeaklat.cont[1,4]<1,"null",as.character(compare.N1.locpeaklat.cont[1,1]))` model explains the observed data `r ifelse(compare.N1.locpeaklat.cont[1,4]>1,compare.N1.locpeaklat.cont[1,4],1/compare.N1.locpeaklat.cont[1,4])` times better than the `r ifelse(compare.N1.locpeaklat.cont[1,4]>1,"null",as.character(compare.N1.locpeaklat.cont[1,1]))` model.

```{r N1_models_locpeaklat_posthoc_emo}
# summarize data
summary.N1.locpeaklat.emo <- summarySEwithin(N1.locpeaklat,"latency",withinvars="emo",idvar="participant")
kable(summary.N1.locpeaklat.emo)

# N1 graph
pirateplot(formula=latency~emo, # dependent~independent variables
           data=N1.locpeaklat, # data frame
           main="emotion", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(150,260), # y-axis: limits
           ylab=expression(paste("latency (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]

compare.N1.locpeaklat.emo.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.locpeaklat.emo.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of emo 
  # N1.locpeaklat.emo.BF <- lmBF(latency~emo,N1.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleemo="medium",iterations=niter,posterior=FALSE)
  # saveRDS(N1.locpeaklat.emo.BF,file=paste0("N1_locpeaklat_emo_BF_",scaling.factor[k],".rds")) # save model
  N1.locpeaklat.emo.BF <- readRDS(paste0("N1_locpeaklat_emo_BF_",scaling.factor[k],".rds")) # load model
  
  ### model comparison
  # BFs
  compare.N1.locpeaklat.emo.BF[,k] <- exp(1)^N1.locpeaklat.emo.BF@bayesFactor$bf[1]
  # percentage of error
  compare.N1.locpeaklat.emo.perc.err[,k] <- N1.locpeaklat.emo.BF@bayesFactor$error[1]*100
}

# summary
compare.N1.locpeaklat.emo <- data.frame("model"="emo",
"nar"=compare.N1.locpeaklat.emo.BF[,1],"nar.p.err"=round(compare.N1.locpeaklat.emo.perc.err[,1],digits=3),
"med"=compare.N1.locpeaklat.emo.BF[,2],"med.p.err"=round(compare.N1.locpeaklat.emo.perc.err[,2],digits=3),
"wid"=compare.N1.locpeaklat.emo.BF[,3],"wid.p.err"=round(compare.N1.locpeaklat.emo.perc.err[,3],digits=3))
compare.N1.locpeaklat.emo <- compare.N1.locpeaklat.emo[order(compare.N1.locpeaklat.emo$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1.locpeaklat.emo)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect emos, the `r ifelse(compare.N1.locpeaklat.emo[1,4]<1,"null",as.character(compare.N1.locpeaklat.emo[1,1]))` model explains the observed data `r ifelse(compare.N1.locpeaklat.emo[1,4]>1,compare.N1.locpeaklat.emo[1,4],1/compare.N1.locpeaklat.emo[1,4])` times better than the `r ifelse(compare.N1.locpeaklat.emo[1,4]>1,"null",as.character(compare.N1.locpeaklat.emo[1,1]))` model.

<center> <h1>*EPN*</h1> </center>

Time window: 300 - 464 ms   
Electrode cluster: P7 PO7 P5 PO3 O1 O2 PO4 P6 PO8 P8   
   
```{r EPN_topo}
# average across selected time points
EPN.topos.grand.avg.allbins <- summarySEwithin(subset(grand.avg.allbins,timepoint >= 300 & timepoint <= 464),"amplitude",withinvars="electrode")
# electrode locations and amplitudes in the same data frame
EPN.topos.grand.avg.allbins <- cbind(electrodeLocs,EPN.topos.grand.avg.allbins[,"amplitude"])
names(EPN.topos.grand.avg.allbins)[8] <- "amplitude" # change variable name

# plot topography
amplim <- c(-.5,.5) # min/max amplitude limit
contour.binwidth <- .1 # map contour

splineSmooth <- gam(amplitude~s(x,y,bs='ts'),data=EPN.topos.grand.avg.allbins)
GAMtopo <- data.frame(expand.grid(x=seq(min(EPN.topos.grand.avg.allbins$x)*2,
                                        max(EPN.topos.grand.avg.allbins$x)*2,
                                        length=gridRes),
                                  y=seq(min(EPN.topos.grand.avg.allbins$y)*2,
                                        max(EPN.topos.grand.avg.allbins$y)*2,
                                        length=gridRes)))
GAMtopo$amplitude <-  predict(splineSmooth,GAMtopo,type="response")
GAMtopo$incircle <- (GAMtopo$x)^2+(GAMtopo$y)^2<.7^2
# plot topography
ggplot(GAMtopo[GAMtopo$incircle,],aes(x,y,fill=amplitude)) +
  geom_raster() +
  stat_contour(aes(z=amplitude),binwidth=contour.binwidth) +
  theme_topo() +
  scale_fill_gradientn(colours=jet.colors(10),
                       limits=amplim,
                       guide="colourbar",
                       oob=squish) +
  geom_path(data=maskRing,aes(x,y,z=NULL,fill=NULL),colour="white",size=6) +
  geom_point(data=EPN.topos.grand.avg.allbins,
             aes(x,y,fill=NULL)) +
  geom_path(data=nose,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  geom_path(data=headShape,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  ggtitle("EPN (300 - 464 ms)") + 
  coord_quickmap()
```

```{r EPN_waves}
ggplot(subset(comps.grand.avg.allbins,component=="EPN" & bin!="all"),aes(timepoint,amplitude)) + # basic plot
  geom_line(aes(color=bin),size=1.5,alpha=.6) + # one line per bin
  scale_colour_brewer(palette="Dark2") + # color palette
  labs(title="EPN (300 - 464 ms)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,50),limits=c(-100,500)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # horizontal reference line
  annotate("rect",xmin=300,xmax=464,ymin=-1,ymax=1.5,alpha=.2) + # highlight time window used for analysis
  theme_pander(base_size=20,pc="white",lp=c(.8,.9)) # custom theme
```

# Analysis of local peak amplitude

```{r EPN_locpeakamp}
EPN.locpeakamp <- read.table("EPN_locpeakamp.txt",header=TRUE) # load data
EPN.locpeakamp <- EPN.locpeakamp[,c("ERPset","binlabel","value")] # subset and reorder columns
names(EPN.locpeakamp) <- c("participant","condition","amplitude") # rename columns
EPN.locpeakamp$size <- revalue(EPN.locpeakamp$condition,c("negativeLargeBright"="large","negativeLargeDark"="large","negativeSmallBright"="small","negativeSmallDark"="small","neutralLargeBright"="large","neutralLargeDark"="large","neutralSmallBright"="small","neutralSmallDark"="small")) # main effect of size
EPN.locpeakamp$cont <- revalue(factor(EPN.locpeakamp$condition),c("negativeLargeBright"="bright","negativeLargeDark"="dark","negativeSmallBright"="bright","negativeSmallDark"="dark","neutralLargeBright"="bright","neutralLargeDark"="dark","neutralSmallBright"="bright","neutralSmallDark"="dark")) # main effect of contrast
EPN.locpeakamp$emo <- revalue(factor(EPN.locpeakamp$condition),c("negativeLargeBright"="negative","negativeLargeDark"="negative","negativeSmallBright"="negative","negativeSmallDark"="negative","neutralLargeBright"="neutral","neutralLargeDark"="neutral","neutralSmallBright"="neutral","neutralSmallDark"="neutral")) # main effect of emotion

# summarize data
summary.EPN.locpeakamp <- summarySEwithin(EPN.locpeakamp,"amplitude",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.EPN.locpeakamp)

# EPN graph
pirateplot(formula=amplitude~emo+cont+size, # dependent~independent variables
           data=EPN.locpeakamp, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-5,3), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
par(mfrow=c(1,1)) # plotting environment back to one graph per graphic device
```

```{r EPN_models_locpeakamp}
compare.EPN.locpeakamp.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.EPN.locpeakamp.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  # EPN.locpeakamp.sizeplusemo.BF <- lmBF(amplitude~size+emo,EPN.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeakamp.sizeplusemo.BF,file=paste0("EPN_locpeakamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeakamp.sizeplusemo.BF <- readRDS(paste0("EPN_locpeakamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # EPN.locpeakamp.sizebyemo.BF <- lmBF(amplitude~size:emo,EPN.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeakamp.sizebyemo.BF,file=paste0("EPN_locpeakamp_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeakamp.sizebyemo.BF <- readRDS(paste0("EPN_locpeakamp_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
      
  ### main effects of contrast and emotion
  # EPN.locpeakamp.contplusemo.BF <- lmBF(amplitude~cont+emo,EPN.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeakamp.contplusemo.BF,file=paste0("EPN_locpeakamp_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeakamp.contplusemo.BF <- readRDS(paste0("EPN_locpeakamp_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # EPN.locpeakamp.contbyemo.BF <- lmBF(amplitude~cont:emo,EPN.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeakamp.contbyemo.BF,file=paste0("EPN_locpeakamp_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeakamp.contbyemo.BF <- readRDS(paste0("EPN_locpeakamp_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # EPN.locpeakamp.sizepluscontplusemo.BF <- lmBF(amplitude~size+cont+emo,EPN.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeakamp.sizepluscontplusemo.BF,file=paste0("EPN_locpeakamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeakamp.sizepluscontplusemo.BF <- readRDS(paste0("EPN_locpeakamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # EPN.locpeakamp.sizebycontbyemo.BF <- lmBF(amplitude~size:cont:emo,EPN.locpeakamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeakamp.sizebycontbyemo.BF,file=paste0("EPN_locpeakamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeakamp.sizebycontbyemo.BF <- readRDS(paste0("EPN_locpeakamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model

### model comparison
# BFs
compare.EPN.locpeakamp.BF[,k] <- c(exp(1)^EPN.locpeakamp.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeakamp.sizebyemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeakamp.contplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeakamp.contbyemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeakamp.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeakamp.sizebycontbyemo.BF@bayesFactor$bf[1])
# percentage of error
compare.EPN.locpeakamp.perc.err[,k] <- c(EPN.locpeakamp.sizeplusemo.BF@bayesFactor$error[1]*100,EPN.locpeakamp.sizebyemo.BF@bayesFactor$error[1]*100,EPN.locpeakamp.contplusemo.BF@bayesFactor$error[1]*100,EPN.locpeakamp.contbyemo.BF@bayesFactor$error[1]*100,EPN.locpeakamp.sizepluscontplusemo.BF@bayesFactor$error[1]*100,EPN.locpeakamp.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}
# summary
compare.EPN.locpeakamp <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=compare.EPN.locpeakamp.BF[,1],"nar.p.err"=round(compare.EPN.locpeakamp.perc.err[,1],digits=3),
"med"=compare.EPN.locpeakamp.BF[,2],"med.p.err"=round(compare.EPN.locpeakamp.perc.err[,2],digits=3),
"wid"=compare.EPN.locpeakamp.BF[,3],"wid.p.err"=round(compare.EPN.locpeakamp.perc.err[,3],digits=3))
compare.EPN.locpeakamp <- compare.EPN.locpeakamp[order(compare.EPN.locpeakamp$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.EPN.locpeakamp)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EPN.locpeakamp[1,4]<1,"null",as.character(compare.EPN.locpeakamp[1,1]))` explains the data `r ifelse(compare.EPN.locpeakamp[1,4]>1,compare.EPN.locpeakamp[1,4],1/compare.EPN.locpeakamp[1,4])` times better than the `r ifelse(compare.EPN.locpeakamp[1,4]>1,"null",as.character(compare.EPN.locpeakamp[1,1]))` model.

# Analysis of local peak latency

```{r EPN_locpeaklat}
EPN.locpeaklat <- read.table("EPN_locpeaklat.txt",header=TRUE) # load data
EPN.locpeaklat <- EPN.locpeaklat[,c("ERPset","binlabel","value")] # subset and reorder columns
names(EPN.locpeaklat) <- c("participant","condition","latency") # rename columns
EPN.locpeaklat$size <- revalue(EPN.locpeaklat$condition,c("negativeLargeBright"="large","negativeLargeDark"="large","negativeSmallBright"="small","negativeSmallDark"="small","neutralLargeBright"="large","neutralLargeDark"="large","neutralSmallBright"="small","neutralSmallDark"="small")) # main effect of size
EPN.locpeaklat$cont <- revalue(factor(EPN.locpeaklat$condition),c("negativeLargeBright"="bright","negativeLargeDark"="dark","negativeSmallBright"="bright","negativeSmallDark"="dark","neutralLargeBright"="bright","neutralLargeDark"="dark","neutralSmallBright"="bright","neutralSmallDark"="dark")) # main effect of contrast
EPN.locpeaklat$emo <- revalue(factor(EPN.locpeaklat$condition),c("negativeLargeBright"="negative","negativeLargeDark"="negative","negativeSmallBright"="negative","negativeSmallDark"="negative","neutralLargeBright"="neutral","neutralLargeDark"="neutral","neutralSmallBright"="neutral","neutralSmallDark"="neutral")) # main effect of emotion

# summarize data
summary.EPN.locpeaklat <- summarySEwithin(EPN.locpeaklat,"latency",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.EPN.locpeaklat)

# EPN graph
pirateplot(formula=latency~emo+cont+size, # dependent~independent variables
           data=EPN.locpeaklat, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(280,400), # y-axis: limits
           ylab="latency (ms)", # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
par(mfrow=c(1,1)) # plotting environment back to one graph per graphic device
```

```{r EPN_models_locpeaklat}
compare.EPN.locpeaklat.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.EPN.locpeaklat.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  # EPN.locpeaklat.sizeplusemo.BF <- lmBF(latency~size+emo,EPN.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeaklat.sizeplusemo.BF,file=paste0("EPN_locpeaklat_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeaklat.sizeplusemo.BF <- readRDS(paste0("EPN_locpeaklat_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # EPN.locpeaklat.sizebyemo.BF <- lmBF(latency~size:emo,EPN.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeaklat.sizebyemo.BF,file=paste0("EPN_locpeaklat_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeaklat.sizebyemo.BF <- readRDS(paste0("EPN_locpeaklat_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
      
  ### main effects of contrast and emotion
  # EPN.locpeaklat.contplusemo.BF <- lmBF(latency~cont+emo,EPN.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeaklat.contplusemo.BF,file=paste0("EPN_locpeaklat_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeaklat.contplusemo.BF <- readRDS(paste0("EPN_locpeaklat_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # EPN.locpeaklat.contbyemo.BF <- lmBF(latency~cont:emo,EPN.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeaklat.contbyemo.BF,file=paste0("EPN_locpeaklat_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeaklat.contbyemo.BF <- readRDS(paste0("EPN_locpeaklat_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # EPN.locpeaklat.sizepluscontplusemo.BF <- lmBF(latency~size+cont+emo,EPN.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeaklat.sizepluscontplusemo.BF,file=paste0("EPN_locpeaklat_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeaklat.sizepluscontplusemo.BF <- readRDS(paste0("EPN_locpeaklat_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # EPN.locpeaklat.sizebycontbyemo.BF <- lmBF(latency~size:cont:emo,EPN.locpeaklat,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(EPN.locpeaklat.sizebycontbyemo.BF,file=paste0("EPN_locpeaklat_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  EPN.locpeaklat.sizebycontbyemo.BF <- readRDS(paste0("EPN_locpeaklat_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model

### model comparison
# BFs
compare.EPN.locpeaklat.BF[,k] <- c(exp(1)^EPN.locpeaklat.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeaklat.sizebyemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeaklat.contplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeaklat.contbyemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeaklat.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.locpeaklat.sizebycontbyemo.BF@bayesFactor$bf[1])
# percentage of error
compare.EPN.locpeaklat.perc.err[,k] <- c(EPN.locpeaklat.sizeplusemo.BF@bayesFactor$error[1]*100,EPN.locpeaklat.sizebyemo.BF@bayesFactor$error[1]*100,EPN.locpeaklat.contplusemo.BF@bayesFactor$error[1]*100,EPN.locpeaklat.contbyemo.BF@bayesFactor$error[1]*100,EPN.locpeaklat.sizepluscontplusemo.BF@bayesFactor$error[1]*100,EPN.locpeaklat.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}
# summary
compare.EPN.locpeaklat <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=compare.EPN.locpeaklat.BF[,1],"nar.p.err"=round(compare.EPN.locpeaklat.perc.err[,1],digits=3),
"med"=compare.EPN.locpeaklat.BF[,2],"med.p.err"=round(compare.EPN.locpeaklat.perc.err[,2],digits=3),
"wid"=compare.EPN.locpeaklat.BF[,3],"wid.p.err"=round(compare.EPN.locpeaklat.perc.err[,3],digits=3))
compare.EPN.locpeaklat <- compare.EPN.locpeaklat[order(compare.EPN.locpeaklat$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.EPN.locpeaklat)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EPN.locpeaklat[1,4]<1,"null",as.character(compare.EPN.locpeaklat[1,1]))` explains the data `r ifelse(compare.EPN.locpeaklat[1,4]>1,compare.EPN.locpeaklat[1,4],1/compare.EPN.locpeaklat[1,4])` times better than the `r ifelse(compare.EPN.locpeaklat[1,4]>1,"null",as.character(compare.EPN.locpeaklat[1,1]))` model.

<center> <h1>*LPP*</h1> </center>

Time window: 440 - 680 ms   
Electrode cluster: C1 Cz C2 CP1 CPz CP2 P1 Pz P2   
   
```{r LPP_topo}
# average across selected time points
LPP.topos.grand.avg.allbins <- summarySEwithin(subset(grand.avg.allbins,timepoint >= 440 & timepoint <= 680),"amplitude",withinvars="electrode")
# electrode locations and amplitudes in the same data frame
LPP.topos.grand.avg.allbins <- cbind(electrodeLocs,LPP.topos.grand.avg.allbins[,"amplitude"])
names(LPP.topos.grand.avg.allbins)[8] <- "amplitude" # change variable name

# plot topography
amplim <- c(-.5,.5) # min/max amplitude limit
contour.binwidth <- .1 # map contour

splineSmooth <- gam(amplitude~s(x,y,bs='ts'),data=LPP.topos.grand.avg.allbins)
GAMtopo <- data.frame(expand.grid(x=seq(min(LPP.topos.grand.avg.allbins$x)*2,
                                        max(LPP.topos.grand.avg.allbins$x)*2,
                                        length=gridRes),
                                  y=seq(min(LPP.topos.grand.avg.allbins$y)*2,
                                        max(LPP.topos.grand.avg.allbins$y)*2,
                                        length=gridRes)))
GAMtopo$amplitude <-  predict(splineSmooth,GAMtopo,type="response")
GAMtopo$incircle <- (GAMtopo$x)^2+(GAMtopo$y)^2<.7^2
# plot topography
ggplot(GAMtopo[GAMtopo$incircle,],aes(x,y,fill=amplitude)) +
  geom_raster() +
  stat_contour(aes(z=amplitude),binwidth=contour.binwidth) +
  theme_topo() +
  scale_fill_gradientn(colours=jet.colors(10),
                       limits=amplim,
                       guide="colourbar",
                       oob=squish) +
  geom_path(data=maskRing,aes(x,y,z=NULL,fill=NULL),colour="white",size=6) +
  geom_point(data=LPP.topos.grand.avg.allbins,
             aes(x,y,fill=NULL)) +
  geom_path(data=nose,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  geom_path(data=headShape,aes(x,y,z=NULL,fill=NULL),size=1.5) +
  ggtitle("LPP (440 - 680 ms)") + 
  coord_quickmap()
```

```{r LPP_waves}
ggplot(subset(comps.grand.avg.allbins,component=="LPP" & bin!="all"),aes(timepoint,amplitude)) + # basic plot
  geom_line(aes(color=bin),size=1.5,alpha=.6) + # one line per bin
  scale_colour_brewer(palette="Dark2") + # color palette
  labs(title="LPP (440 - 680 ms)",x="time (ms)",y=expression(paste("amplitude (",mu,"V)"))) + # title & axes labels
  scale_x_continuous(breaks=seq(-200,1000,50),limits=c(-100,1000)) + # x-axis: tick marks
  scale_y_reverse(breaks=seq(-3,3,1),limits=c(3,-3)) + # y-axis: tick marks
  geom_vline(xintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # vertical reference line
  geom_hline(yintercept=0,linetype="dashed",colour="black",size=.8,alpha=.8) + # horizontal reference line
  annotate("rect",xmin=440,xmax=680,ymin=-.5,ymax=1.5,alpha=.2) + # highlight time window used for analysis
  theme_pander(base_size=20,pc="white",lp=c(.8,.8)) # custom theme
```

# Analysis of mean amplitude

```{r LPP_meanamp}
LPP.meanamp <- read.table("LPP_meanamp.txt",header=TRUE) # load data
LPP.meanamp <- LPP.meanamp[,c("ERPset","binlabel","value")] # subset and reorder columns
names(LPP.meanamp) <- c("participant","condition","amplitude") # rename columns
LPP.meanamp$size <- revalue(LPP.meanamp$condition,c("negativeLargeBright"="large","negativeLargeDark"="large","negativeSmallBright"="small","negativeSmallDark"="small","neutralLargeBright"="large","neutralLargeDark"="large","neutralSmallBright"="small","neutralSmallDark"="small")) # main effect of size
LPP.meanamp$cont <- revalue(factor(LPP.meanamp$condition),c("negativeLargeBright"="bright","negativeLargeDark"="dark","negativeSmallBright"="bright","negativeSmallDark"="dark","neutralLargeBright"="bright","neutralLargeDark"="dark","neutralSmallBright"="bright","neutralSmallDark"="dark")) # main effect of contrast
LPP.meanamp$emo <- revalue(factor(LPP.meanamp$condition),c("negativeLargeBright"="negative","negativeLargeDark"="negative","negativeSmallBright"="negative","negativeSmallDark"="negative","neutralLargeBright"="neutral","neutralLargeDark"="neutral","neutralSmallBright"="neutral","neutralSmallDark"="neutral")) # main effect of emotion

# summarize data
summary.LPP.meanamp <- summarySEwithin(LPP.meanamp,"amplitude",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.LPP.meanamp)

# LPP graph
pirateplot(formula=amplitude~emo+cont+size, # dependent~independent variables
           data=LPP.meanamp, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-1,2.5), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           inf.within="participant", # ID variable in within-subject designs
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
par(mfrow=c(1,1)) # plotting environment back to one graph per graphic device
```

```{r LPP_models_meanamp}
compare.LPP.meanamp.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.LPP.meanamp.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  # LPP.meanamp.sizeplusemo.BF <- lmBF(amplitude~size+emo,LPP.meanamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(LPP.meanamp.sizeplusemo.BF,file=paste0("LPP_meanamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.meanamp.sizeplusemo.BF <- readRDS(paste0("LPP_meanamp_sizeplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size and emotion
  # LPP.meanamp.sizebyemo.BF <- lmBF(amplitude~size:emo,LPP.meanamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(LPP.meanamp.sizebyemo.BF,file=paste0("LPP_meanamp_sizebyemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.meanamp.sizebyemo.BF <- readRDS(paste0("LPP_meanamp_sizebyemo_BF_",scaling.factor[k],".rds")) # load model
      
  ### main effects of contrast and emotion
  # LPP.meanamp.contplusemo.BF <- lmBF(amplitude~cont+emo,LPP.meanamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(LPP.meanamp.contplusemo.BF,file=paste0("LPP_meanamp_contplusemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.meanamp.contplusemo.BF <- readRDS(paste0("LPP_meanamp_contplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of contrast and emotion
  # LPP.meanamp.contbyemo.BF <- lmBF(amplitude~cont:emo,LPP.meanamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(LPP.meanamp.contbyemo.BF,file=paste0("LPP_meanamp_contbyemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.meanamp.contbyemo.BF <- readRDS(paste0("LPP_meanamp_contbyemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### main effects of size, contrast, and emotion
  # LPP.meanamp.sizepluscontplusemo.BF <- lmBF(amplitude~size+cont+emo,LPP.meanamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(LPP.meanamp.sizepluscontplusemo.BF,file=paste0("LPP_meanamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.meanamp.sizepluscontplusemo.BF <- readRDS(paste0("LPP_meanamp_sizepluscontplusemo_BF_",scaling.factor[k],".rds")) # load model
  
  ### interactive effects of size, contrast, and emotion
  # LPP.meanamp.sizebycontbyemo.BF <- lmBF(amplitude~size:cont:emo,LPP.meanamp,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  # saveRDS(LPP.meanamp.sizebycontbyemo.BF,file=paste0("LPP_meanamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # save model
  LPP.meanamp.sizebycontbyemo.BF <- readRDS(paste0("LPP_meanamp_sizebycontbyemo_BF_",scaling.factor[k],".rds")) # load model

### model comparison
# BFs
compare.LPP.meanamp.BF[,k] <- c(exp(1)^LPP.meanamp.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^LPP.meanamp.sizebyemo.BF@bayesFactor$bf[1],exp(1)^LPP.meanamp.contplusemo.BF@bayesFactor$bf[1],exp(1)^LPP.meanamp.contbyemo.BF@bayesFactor$bf[1],exp(1)^LPP.meanamp.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^LPP.meanamp.sizebycontbyemo.BF@bayesFactor$bf[1])
# percentage of error
compare.LPP.meanamp.perc.err[,k] <- c(LPP.meanamp.sizeplusemo.BF@bayesFactor$error[1]*100,LPP.meanamp.sizebyemo.BF@bayesFactor$error[1]*100,LPP.meanamp.contplusemo.BF@bayesFactor$error[1]*100,LPP.meanamp.contbyemo.BF@bayesFactor$error[1]*100,LPP.meanamp.sizepluscontplusemo.BF@bayesFactor$error[1]*100,LPP.meanamp.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}
# summary
compare.LPP.meanamp <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=compare.LPP.meanamp.BF[,1],"nar.p.err"=round(compare.LPP.meanamp.perc.err[,1],digits=3),
"med"=compare.LPP.meanamp.BF[,2],"med.p.err"=round(compare.LPP.meanamp.perc.err[,2],digits=3),
"wid"=compare.LPP.meanamp.BF[,3],"wid.p.err"=round(compare.LPP.meanamp.perc.err[,3],digits=3))
compare.LPP.meanamp <- compare.LPP.meanamp[order(compare.LPP.meanamp$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.LPP.meanamp)
```

When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.LPP.meanamp[1,4]<1,"null",as.character(compare.LPP.meanamp[1,1]))` ought to be preferred. However, the Bayes Factor is so uninformative that the null model is a more parsimonious choice.  

# Analysis of fractional peak latency

Cannot be performed due to the large number of missing values.


