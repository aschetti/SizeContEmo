---
title: "<center> <h1>***SIZECONTEMO***</h1> </center>"
author: '[Antonio Schettino](https://www.researchgate.net/profile/Antonio_Schettino2 "Antonio Schettino")'
date: '`r Sys.Date()`'
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
    toc: true
    toc_float: true
---

In this project we will investigate the electrophysiological correlates of the combined processing of basic visual properties (i.e., size and contrast) and the emotional content of simple words. 

```{r setup_environment,echo=FALSE,warning=FALSE,message=FALSE}
# setup work environment
# dev.off() # clear plots (if no plots are present, comment it out or it will throw an error)
cat("\014") # clear console
rm(list=ls()) # clear environment
set.seed(9001) # specify seed for RNG and ensure reproducible results (it's over 9000!)

expname <- "SizeContEmo" # experiment name
expphase <- "pilot" # experiment phase
wd <- paste("D:/OneDrive - UGent/",expname,"/analysis/EEG/",expphase,"/",sep="") # work directory
setwd(wd) # set work directory

# load relevant libraries
library(knitr) # dynamic report generation
library(Rmisc) # for advanced summary functions
library(yarrr) # amazing graphs
library(BayesFactor) # calculate Bayes factors
library(fitdistrplus) # fit parametric distributions to non-censored or censored data
```

```{r setup_output}
# setup report output
options(width=120,scipen=999,digits=3) # change output width (for better printing), disable scientific notation (default: scipen=0), constrain output to 4 decimals
opts_chunk$set(warning=FALSE,message=FALSE,fig.width=10,fig.height=6) # for each chunk, display the output but not the R code (echo=FALSE), no package warnings (message=FALSE), no package messages (message=FALSE), width and height of all figures
```

```{r main_data}
data.EEG.trial.all <- read.csv(paste0(expphase,"_trialEEG.csv"),header=TRUE) # load data

data.EEG.trial <- data.EEG.trial.all[data.EEG.trial.all$bin %in% c(1:8),] # subset trials main experiment

data.EEG.trial$size <- revalue(factor(data.EEG.trial$bin),c("1"="large","2"="small","3"="large","4"="small","5"="large","6"="small","7"="large","8"="small")) # main effect of size

data.EEG.trial$cont <- revalue(factor(data.EEG.trial$bin),c("1"="dark","2"="dark","3"="bright","4"="bright","5"="dark","6"="dark","7"="bright","8"="bright")) # main effect of contrast

data.EEG.trial$emo <- revalue(factor(data.EEG.trial$bin),c("1"="negative","2"="negative","3"="negative","4"="negative","5"="neutral","6"="neutral","7"="neutral","8"="neutral")) # main effect of emotion

data.EEG.trial$bin <- revalue(factor(data.EEG.trial$bin),c("1"="negativeLargeDark","2"="negativeSmallDark","3"="negativeLargeBright","4"="negativeSmallBright","5"="neutralLargeDark","6"="neutralSmallDark","7"="neutralLargeBright","8"="neutralSmallBright")) # recode bin variable

# add words for each trial 
data.EEG.trialWords <- read.csv(paste0(expphase,"_words.csv"),header=TRUE) # load data
data.EEG.trial$word <- data.EEG.trialWords[1:1434,"word"] # ends at 1434 because of a bug in extracting the trials in pilot12. hopefully we won't have this problem in the main experimental sample
rm(data.EEG.trialWords) # delete word data 

data.EEG.trial <- within(data.EEG.trial,size<-relevel(size,ref="large")) # reference: large size
data.EEG.trial <- within(data.EEG.trial,cont<-relevel(cont,ref="dark")) # reference: high contrast
data.EEG.trial <- within(data.EEG.trial,emo<-relevel(emo,ref="neutral")) # reference: neutral emotion
```

The data we will use in this demo come from a pilot experiment (N=`r length(unique(data.EEG.trial$participant))`).   
   
We will first focus on the ERP data of the main task.   

<center> <h1>***MAIN TASK***</h1> </center>   

We will calculate and compare the Bayes Factor of different linear mixed-effects models. The random factors are participants and the individual word per trial. Their variance is set as nuisance.   

<center> <h1>*P1*</h1> </center>

```{r main_P1_graph}
# summarize data
summary.data.EEG.trial <- summarySEwithin(data.EEG.trial,"P1",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.data.EEG.trial)

# P1 graph
pirateplot(formula=P1~emo+cont+size, # dependent~independent variables
           data=data.EEG.trial, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

We will compare (against the null model) the following models:   
   
1. main effects of size and emotion
2. interactive effects of size and emotion
3. main effects of contrast and emotion
4. interactive effects of contrast and emotion
5. main effects of size, contrast, and emotion
6. interactive effects of size, contrast, and emotion   
   
We will then compare the best competing models to understand which one should be preferred overall.   

```{r main_P1_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.P1.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.P1.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  P1.sizeplusemo.BF <- lmBF(P1~size+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of size and emotion
  P1.sizebyemo.BF <- lmBF(P1~size:emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of contrast and emotion
  P1.contplusemo.BF <- lmBF(P1~cont+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of contrast and emotion
  P1.contbyemo.BF <- lmBF(P1~cont:emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of size, contrast, and emotion
  P1.sizepluscontplusemo.BF <- lmBF(P1~size+cont+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of size, contrast, and emotion
  P1.sizebycontbyemo.BF <- lmBF(P1~size*cont*emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.P1.BF[,k] <- c(exp(1)^P1.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^P1.sizebyemo.BF@bayesFactor$bf[1],exp(1)^P1.contplusemo.BF@bayesFactor$bf[1],exp(1)^P1.contbyemo.BF@bayesFactor$bf[1],exp(1)^P1.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^P1.sizebycontbyemo.BF@bayesFactor$bf[1])
  # percentage of error
  compare.P1.perc.err[,k] <- c(P1.sizeplusemo.BF@bayesFactor$error[1]*100,P1.sizebyemo.BF@bayesFactor$error[1]*100,P1.contplusemo.BF@bayesFactor$error[1]*100,P1.contbyemo.BF@bayesFactor$error[1]*100,P1.sizepluscontplusemo.BF@bayesFactor$error[1]*100,P1.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}

# summary
compare.P1 <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=round(compare.P1.BF[,1],digits=3),"nar.p.err"=round(compare.P1.perc.err[,1],digits=3),
"med"=round(compare.P1.BF[,2],digits=3),"med.p.err"=round(compare.P1.perc.err[,2],digits=3),
"wid"=round(compare.P1.BF[,3],digits=3),"wid.p.err"=round(compare.P1.perc.err[,3],digits=3))
compare.P1 <- compare.P1[order(compare.P1$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.P1)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.P1[1,4]<1,"null",as.character(compare.P1[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.P1[1,1])`) explains the observed data `r ifelse(compare.P1[1,4]>1,compare.P1[1,4]/compare.P1[2,4],1/compare.P1[1,4])` times better than the second best model (`r as.character(compare.P1[2,1])`).   

<center> <h1>*N1*</h1> </center>

```{r main_N1_graph}
# summarize data
summary.data.EEG.trial <- summarySEwithin(data.EEG.trial,"N1",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.data.EEG.trial)

# N1 graph
pirateplot(formula=N1~emo+cont+size, # dependent~independent variables
           data=data.EEG.trial, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r main_N1_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.N1.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.N1.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  N1.sizeplusemo.BF <- lmBF(N1~size+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of size and emotion
  N1.sizebyemo.BF <- lmBF(N1~size:emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of contrast and emotion
  N1.contplusemo.BF <- lmBF(N1~cont+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of contrast and emotion
  N1.contbyemo.BF <- lmBF(N1~cont:emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of size, contrast, and emotion
  N1.sizepluscontplusemo.BF <- lmBF(N1~size+cont+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of size, contrast, and emotion
  N1.sizebycontbyemo.BF <- lmBF(N1~size*cont*emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.N1.BF[,k] <- c(exp(1)^N1.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^N1.sizebyemo.BF@bayesFactor$bf[1],exp(1)^N1.contplusemo.BF@bayesFactor$bf[1],exp(1)^N1.contbyemo.BF@bayesFactor$bf[1],exp(1)^N1.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^N1.sizebycontbyemo.BF@bayesFactor$bf[1])
  # percentage of error
  compare.N1.perc.err[,k] <- c(N1.sizeplusemo.BF@bayesFactor$error[1]*100,N1.sizebyemo.BF@bayesFactor$error[1]*100,N1.contplusemo.BF@bayesFactor$error[1]*100,N1.contbyemo.BF@bayesFactor$error[1]*100,N1.sizepluscontplusemo.BF@bayesFactor$error[1]*100,N1.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}

# summary
compare.N1 <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=round(compare.N1.BF[,1],digits=3),"nar.p.err"=round(compare.N1.perc.err[,1],digits=3),
"med"=round(compare.N1.BF[,2],digits=3),"med.p.err"=round(compare.N1.perc.err[,2],digits=3),
"wid"=round(compare.N1.BF[,3],digits=3),"wid.p.err"=round(compare.N1.perc.err[,3],digits=3))
compare.N1 <- compare.N1[order(compare.N1$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.N1)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.N1[1,4]<1,"null",as.character(compare.N1[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.N1[1,1])`) explains the observed data `r ifelse(compare.N1[1,4]>1,compare.N1[1,4]/compare.N1[2,4],1/compare.N1[1,4])` times better than the second best model (`r as.character(compare.N1[2,1])`).   
  
<center> <h1>*EPN*</h1> </center>

```{r main_EPN_graph}
# summarize data
summary.data.EEG.trial <- summarySEwithin(data.EEG.trial,"EPN",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.data.EEG.trial)

# EPN graph
pirateplot(formula=EPN~emo+cont+size, # dependent~independent variables
           data=data.EEG.trial, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r main_EPN_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.EPN.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.EPN.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  EPN.sizeplusemo.BF <- lmBF(EPN~size+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of size and emotion
  EPN.sizebyemo.BF <- lmBF(EPN~size:emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of contrast and emotion
  EPN.contplusemo.BF <- lmBF(EPN~cont+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of contrast and emotion
  EPN.contbyemo.BF <- lmBF(EPN~cont:emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of size, contrast, and emotion
  EPN.sizepluscontplusemo.BF <- lmBF(EPN~size+cont+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of size, contrast, and emotion
  EPN.sizebycontbyemo.BF <- lmBF(EPN~size*cont*emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.EPN.BF[,k] <- c(exp(1)^EPN.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.sizebyemo.BF@bayesFactor$bf[1],exp(1)^EPN.contplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.contbyemo.BF@bayesFactor$bf[1],exp(1)^EPN.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^EPN.sizebycontbyemo.BF@bayesFactor$bf[1])
  # percentage of error
  compare.EPN.perc.err[,k] <- c(EPN.sizeplusemo.BF@bayesFactor$error[1]*100,EPN.sizebyemo.BF@bayesFactor$error[1]*100,EPN.contplusemo.BF@bayesFactor$error[1]*100,EPN.contbyemo.BF@bayesFactor$error[1]*100,EPN.sizepluscontplusemo.BF@bayesFactor$error[1]*100,EPN.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}

# summary
compare.EPN <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=round(compare.EPN.BF[,1],digits=3),"nar.p.err"=round(compare.EPN.perc.err[,1],digits=3),
"med"=round(compare.EPN.BF[,2],digits=3),"med.p.err"=round(compare.EPN.perc.err[,2],digits=3),
"wid"=round(compare.EPN.BF[,3],digits=3),"wid.p.err"=round(compare.EPN.perc.err[,3],digits=3))
compare.EPN <- compare.EPN[order(compare.EPN$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.EPN)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EPN[1,4]<1,"null",as.character(compare.EPN[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.EPN[1,1])`) explains the observed data `r ifelse(compare.EPN[1,4]>1,compare.EPN[1,4]/compare.EPN[2,4],1/compare.EPN[1,4])` times better than the second best model (`r as.character(compare.EPN[2,1])`).   

<center> <h1>*LPP*</h1> </center>

```{r main_LPP_graph}
# summarize data
summary.data.EEG.trial <- summarySEwithin(data.EEG.trial,"LPP",withinvars=c("size","cont","emo"),idvar="participant")
kable(summary.data.EEG.trial)

# LPP graph
pirateplot(formula=LPP~emo+cont+size, # dependent~independent variables
           data=data.EEG.trial, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r main_LPP_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.LPP.BF <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all BF10
compare.LPP.perc.err <- matrix(NA,6,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effects of size and emotion
  LPP.sizeplusemo.BF <- lmBF(LPP~size+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of size and emotion
  LPP.sizebyemo.BF <- lmBF(LPP~size:emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of contrast and emotion
  LPP.contplusemo.BF <- lmBF(LPP~cont+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of contrast and emotion
  LPP.contbyemo.BF <- lmBF(LPP~cont:emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of size, contrast, and emotion
  LPP.sizepluscontplusemo.BF <- lmBF(LPP~size+cont+emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### interactive effects of size, contrast, and emotion
  LPP.sizebycontbyemo.BF <- lmBF(LPP~size*cont*emo,data.EEG.trial,whichRandom=c("participant","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.LPP.BF[,k] <- c(exp(1)^LPP.sizeplusemo.BF@bayesFactor$bf[1],exp(1)^LPP.sizebyemo.BF@bayesFactor$bf[1],exp(1)^LPP.contplusemo.BF@bayesFactor$bf[1],exp(1)^LPP.contbyemo.BF@bayesFactor$bf[1],exp(1)^LPP.sizepluscontplusemo.BF@bayesFactor$bf[1],exp(1)^LPP.sizebycontbyemo.BF@bayesFactor$bf[1])
  # percentage of error
  compare.LPP.perc.err[,k] <- c(LPP.sizeplusemo.BF@bayesFactor$error[1]*100,LPP.sizebyemo.BF@bayesFactor$error[1]*100,LPP.contplusemo.BF@bayesFactor$error[1]*100,LPP.contbyemo.BF@bayesFactor$error[1]*100,LPP.sizepluscontplusemo.BF@bayesFactor$error[1]*100,LPP.sizebycontbyemo.BF@bayesFactor$error[1]*100)
}

# summary
compare.LPP <- data.frame("model"=c("size + emo","size x emo","contr + emo","cont x emo","size + cont + emo","size x cont x emo"),
"nar"=round(compare.LPP.BF[,1],digits=3),"nar.p.err"=round(compare.LPP.perc.err[,1],digits=3),
"med"=round(compare.LPP.BF[,2],digits=3),"med.p.err"=round(compare.LPP.perc.err[,2],digits=3),
"wid"=round(compare.LPP.BF[,3],digits=3),"wid.p.err"=round(compare.LPP.perc.err[,3],digits=3))
compare.LPP <- compare.LPP[order(compare.LPP$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.LPP)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.LPP[1,4]<1,"null",as.character(compare.LPP[1,1]))` ought to be preferred.   
The best model (`r as.character(compare.LPP[1,1])`) explains the observed data `r ifelse(compare.LPP[1,4]>1,compare.LPP[1,4]/compare.LPP[2,4],1/compare.LPP[1,4])` times better than the second best model (`r as.character(compare.LPP[2,1])`).   

We will now move on to the ERP data of the localizers.   

<center> <h1>**SIZE LOCALIZER**</h1> </center>   

```{r sizeloc_data}
data.EEG.trial.SizeLoc <- data.EEG.trial.all[data.EEG.trial.all$bin %in% c(9:10),] # subset trials size localizer

data.EEG.trial.SizeLoc$bin <- revalue(factor(data.EEG.trial.SizeLoc$bin),c("9"="LocSmall","10"="LocLarge")) # recode bin variable

data.EEG.trial.SizeLoc <- within(data.EEG.trial.SizeLoc,bin<-relevel(bin,ref="LocLarge"))  # reference: large size
```

<center> <h1>*P1*</h1> </center>

```{r sizeloc_P1_graph}
# summarize data
summary.data.EEG.trial.SizeLoc <- summarySEwithin(data.EEG.trial.SizeLoc,"P1",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.SizeLoc)

# P1 graph
pirateplot(formula=P1~bin, # dependent~independent variables
           data=data.EEG.trial.SizeLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

We will compare the model with the main effect of size vs. the null model.   

```{r sizeloc_P1_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.SizeLoc.P1.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.SizeLoc.P1.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of size
  SizeLoc.P1.size.BF <- lmBF(P1~bin,data.EEG.trial.SizeLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.SizeLoc.P1.BF[,k] <- exp(1)^SizeLoc.P1.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.SizeLoc.P1.perc.err[,k] <- SizeLoc.P1.size.BF@bayesFactor$error[1]*100
}

# summary
compare.SizeLoc.P1 <- data.frame("model"="size",
"nar"=round(compare.SizeLoc.P1.BF[,1],digits=3),"nar.p.err"=round(compare.SizeLoc.P1.perc.err[,1],digits=3),
"med"=round(compare.SizeLoc.P1.BF[,2],digits=3),"med.p.err"=round(compare.SizeLoc.P1.perc.err[,2],digits=3),
"wid"=round(compare.SizeLoc.P1.BF[,3],digits=3),"wid.p.err"=round(compare.SizeLoc.P1.perc.err[,3],digits=3))
kable(compare.SizeLoc.P1)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.SizeLoc.P1[1,4]<1,"null",as.character(compare.SizeLoc.P1[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.SizeLoc.P1[1,4]`).   

<center> <h1>*N1*</h1> </center>

```{r sizeloc_N1_graph}
# summarize data
summary.data.EEG.trial.SizeLoc <- summarySEwithin(data.EEG.trial.SizeLoc,"N1",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.SizeLoc)

# N1 graph
pirateplot(formula=N1~bin, # dependent~independent variables
           data=data.EEG.trial.SizeLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r sizeloc_N1_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.SizeLoc.N1.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.SizeLoc.N1.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of size
  SizeLoc.N1.size.BF <- lmBF(N1~bin,data.EEG.trial.SizeLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.SizeLoc.N1.BF[,k] <- exp(1)^SizeLoc.N1.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.SizeLoc.N1.perc.err[,k] <- SizeLoc.N1.size.BF@bayesFactor$error[1]*100
}

# summary
compare.SizeLoc.N1 <- data.frame("model"="size",
"nar"=round(compare.SizeLoc.N1.BF[,1],digits=3),"nar.p.err"=round(compare.SizeLoc.N1.perc.err[,1],digits=3),
"med"=round(compare.SizeLoc.N1.BF[,2],digits=3),"med.p.err"=round(compare.SizeLoc.N1.perc.err[,2],digits=3),
"wid"=round(compare.SizeLoc.N1.BF[,3],digits=3),"wid.p.err"=round(compare.SizeLoc.N1.perc.err[,3],digits=3))
kable(compare.SizeLoc.N1)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.SizeLoc.N1[1,4]<1,"null",as.character(compare.SizeLoc.N1[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.SizeLoc.N1[1,4]`).   

<center> <h1>*EPN*</h1> </center>

```{r sizeloc_EPN_graph}
# summarize data
summary.data.EEG.trial.SizeLoc <- summarySEwithin(data.EEG.trial.SizeLoc,"EPN",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.SizeLoc)

# EPN graph
pirateplot(formula=EPN~bin, # dependent~independent variables
           data=data.EEG.trial.SizeLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r sizeloc_EPN_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.SizeLoc.EPN.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.SizeLoc.EPN.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of size
  SizeLoc.EPN.size.BF <- lmBF(EPN~bin,data.EEG.trial.SizeLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.SizeLoc.EPN.BF[,k] <- exp(1)^SizeLoc.EPN.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.SizeLoc.EPN.perc.err[,k] <- SizeLoc.EPN.size.BF@bayesFactor$error[1]*100
}

# summary
compare.SizeLoc.EPN <- data.frame("model"="size",
"nar"=round(compare.SizeLoc.EPN.BF[,1],digits=3),"nar.p.err"=round(compare.SizeLoc.EPN.perc.err[,1],digits=3),
"med"=round(compare.SizeLoc.EPN.BF[,2],digits=3),"med.p.err"=round(compare.SizeLoc.EPN.perc.err[,2],digits=3),
"wid"=round(compare.SizeLoc.EPN.BF[,3],digits=3),"wid.p.err"=round(compare.SizeLoc.EPN.perc.err[,3],digits=3))
kable(compare.SizeLoc.EPN)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.SizeLoc.EPN[1,4]<1,"null",as.character(compare.SizeLoc.EPN[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.SizeLoc.EPN[1,4]`).   

<center> <h1>*LPP*</h1> </center>

```{r sizeloc_LPP_graph}
# summarize data
summary.data.EEG.trial.SizeLoc <- summarySEwithin(data.EEG.trial.SizeLoc,"LPP",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.SizeLoc)

# LPP graph
pirateplot(formula=LPP~bin, # dependent~independent variables
           data=data.EEG.trial.SizeLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r sizeloc_LPP_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.SizeLoc.LPP.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.SizeLoc.LPP.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of size
  SizeLoc.LPP.size.BF <- lmBF(LPP~bin,data.EEG.trial.SizeLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.SizeLoc.LPP.BF[,k] <- exp(1)^SizeLoc.LPP.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.SizeLoc.LPP.perc.err[,k] <- SizeLoc.LPP.size.BF@bayesFactor$error[1]*100
}

# summary
compare.SizeLoc.LPP <- data.frame("model"="size",
"nar"=round(compare.SizeLoc.LPP.BF[,1],digits=3),"nar.p.err"=round(compare.SizeLoc.LPP.perc.err[,1],digits=3),
"med"=round(compare.SizeLoc.LPP.BF[,2],digits=3),"med.p.err"=round(compare.SizeLoc.LPP.perc.err[,2],digits=3),
"wid"=round(compare.SizeLoc.LPP.BF[,3],digits=3),"wid.p.err"=round(compare.SizeLoc.LPP.perc.err[,3],digits=3))
kable(compare.SizeLoc.LPP)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.SizeLoc.LPP[1,4]<1,"null",as.character(compare.SizeLoc.LPP[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.SizeLoc.LPP[1,4]`).   

<center> <h1>**CONTRAST LOCALIZER**</h1> </center>   

```{r contloc_data}
data.EEG.trial.ContLoc <- data.EEG.trial.all[data.EEG.trial.all$bin %in% c(11:12),] # subset trials contrast localizer

data.EEG.trial.ContLoc$bin <- revalue(factor(data.EEG.trial.ContLoc$bin),c("11"="LowCon","12"="HighCon")) # recode bin variable

data.EEG.trial.ContLoc <- within(data.EEG.trial.ContLoc,bin<-relevel(bin,ref="HighCon")) # reference: high contrast
```

<center> <h1>*P1*</h1> </center>

```{r contloc_P1_graph}
# summarize data
summary.data.EEG.trial.ContLoc <- summarySEwithin(data.EEG.trial.ContLoc,"P1",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.ContLoc)

# P1 graph
pirateplot(formula=P1~bin, # dependent~independent variables
           data=data.EEG.trial.ContLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

We will compare the model with the main effect of contrast vs. the null model.   

```{r contloc_P1_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.ContLoc.P1.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.ContLoc.P1.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of contrast
  ContLoc.P1.size.BF <- lmBF(P1~bin,data.EEG.trial.ContLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.ContLoc.P1.BF[,k] <- exp(1)^ContLoc.P1.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.ContLoc.P1.perc.err[,k] <- ContLoc.P1.size.BF@bayesFactor$error[1]*100
}

# summary
compare.ContLoc.P1 <- data.frame("model"="contrast",
"nar"=round(compare.ContLoc.P1.BF[,1],digits=3),"nar.p.err"=round(compare.ContLoc.P1.perc.err[,1],digits=3),
"med"=round(compare.ContLoc.P1.BF[,2],digits=3),"med.p.err"=round(compare.ContLoc.P1.perc.err[,2],digits=3),
"wid"=round(compare.ContLoc.P1.BF[,3],digits=3),"wid.p.err"=round(compare.ContLoc.P1.perc.err[,3],digits=3))
kable(compare.ContLoc.P1)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.ContLoc.P1[1,4]<1,"null",as.character(compare.ContLoc.P1[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.ContLoc.P1[1,4]`).   

<center> <h1>*N1*</h1> </center>

```{r contloc_N1_graph}
# summarize data
summary.data.EEG.trial.ContLoc <- summarySEwithin(data.EEG.trial.ContLoc,"N1",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.ContLoc)

# N1 graph
pirateplot(formula=N1~bin, # dependent~independent variables
           data=data.EEG.trial.ContLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
``` 

```{r contloc_N1_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.ContLoc.N1.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.ContLoc.N1.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of contrast
  ContLoc.N1.size.BF <- lmBF(N1~bin,data.EEG.trial.ContLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.ContLoc.N1.BF[,k] <- exp(1)^ContLoc.N1.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.ContLoc.N1.perc.err[,k] <- ContLoc.N1.size.BF@bayesFactor$error[1]*100
}

# summary
compare.ContLoc.N1 <- data.frame("model"="contrast",
"nar"=round(compare.ContLoc.N1.BF[,1],digits=3),"nar.p.err"=round(compare.ContLoc.N1.perc.err[,1],digits=3),
"med"=round(compare.ContLoc.N1.BF[,2],digits=3),"med.p.err"=round(compare.ContLoc.N1.perc.err[,2],digits=3),
"wid"=round(compare.ContLoc.N1.BF[,3],digits=3),"wid.p.err"=round(compare.ContLoc.N1.perc.err[,3],digits=3))
kable(compare.ContLoc.N1)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.ContLoc.N1[1,4]<1,"null",as.character(compare.ContLoc.N1[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.ContLoc.N1[1,4]`).   

<center> <h1>*EPN*</h1> </center>

```{r contloc_EPN_graph}
# summarize data
summary.data.EEG.trial.ContLoc <- summarySEwithin(data.EEG.trial.ContLoc,"EPN",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.ContLoc)

# EPN graph
pirateplot(formula=EPN~bin, # dependent~independent variables
           data=data.EEG.trial.ContLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
``` 

```{r contloc_EPN_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.ContLoc.EPN.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.ContLoc.EPN.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of contrast
  ContLoc.EPN.size.BF <- lmBF(EPN~bin,data.EEG.trial.ContLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.ContLoc.EPN.BF[,k] <- exp(1)^ContLoc.EPN.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.ContLoc.EPN.perc.err[,k] <- ContLoc.EPN.size.BF@bayesFactor$error[1]*100
}

# summary
compare.ContLoc.EPN <- data.frame("model"="contrast",
"nar"=round(compare.ContLoc.EPN.BF[,1],digits=3),"nar.p.err"=round(compare.ContLoc.EPN.perc.err[,1],digits=3),
"med"=round(compare.ContLoc.EPN.BF[,2],digits=3),"med.p.err"=round(compare.ContLoc.EPN.perc.err[,2],digits=3),
"wid"=round(compare.ContLoc.EPN.BF[,3],digits=3),"wid.p.err"=round(compare.ContLoc.EPN.perc.err[,3],digits=3))
kable(compare.ContLoc.EPN)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.ContLoc.EPN[1,4]<1,"null",as.character(compare.ContLoc.EPN[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.ContLoc.EPN[1,4]`).   

<center> <h1>*LPP*</h1> </center>

```{r contloc_LPP_graph}
# summarize data
summary.data.EEG.trial.ContLoc <- summarySEwithin(data.EEG.trial.ContLoc,"LPP",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.ContLoc)

# LPP graph
pirateplot(formula=LPP~bin, # dependent~independent variables
           data=data.EEG.trial.ContLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
``` 

```{r contloc_LPP_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.ContLoc.LPP.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.ContLoc.LPP.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of contrast
  ContLoc.LPP.size.BF <- lmBF(LPP~bin,data.EEG.trial.ContLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.ContLoc.LPP.BF[,k] <- exp(1)^ContLoc.LPP.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.ContLoc.LPP.perc.err[,k] <- ContLoc.LPP.size.BF@bayesFactor$error[1]*100
}

# summary
compare.ContLoc.LPP <- data.frame("model"="contrast",
"nar"=round(compare.ContLoc.LPP.BF[,1],digits=3),"nar.p.err"=round(compare.ContLoc.LPP.perc.err[,1],digits=3),
"med"=round(compare.ContLoc.LPP.BF[,2],digits=3),"med.p.err"=round(compare.ContLoc.LPP.perc.err[,2],digits=3),
"wid"=round(compare.ContLoc.LPP.BF[,3],digits=3),"wid.p.err"=round(compare.ContLoc.LPP.perc.err[,3],digits=3))
kable(compare.ContLoc.LPP)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.ContLoc.LPP[1,4]<1,"null",as.character(compare.ContLoc.LPP[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.ContLoc.LPP[1,4]`).   

<center> <h1>**EMOTION LOCALIZER**</h1> </center>   

```{r emoloc_data}
data.EEG.trial.EmoLoc <- data.EEG.trial.all[data.EEG.trial.all$bin %in% c(13:14),] # subset trials emotion localizer

data.EEG.trial.EmoLoc$bin <- revalue(factor(data.EEG.trial.EmoLoc$bin),c("13"="LocNeut","14"="LocNeg")) # recode bin variable

data.EEG.trial.EmoLoc <- within(data.EEG.trial.EmoLoc,bin<-relevel(bin,ref="LocNeut")) # reference: neutral
```

<center> <h1>*P1*</h1> </center>

```{r emoloc_P1_graph}
# summarize data
summary.data.EEG.trial.EmoLoc <- summarySEwithin(data.EEG.trial.EmoLoc,"P1",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.EmoLoc)

# P1 graph
pirateplot(formula=P1~bin, # dependent~independent variables
           data=data.EEG.trial.EmoLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

We will compare the model with the main effect of emotion vs. the null model.   

```{r emoloc_P1_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.EmoLoc.P1.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.EmoLoc.P1.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of emotion
  EmoLoc.P1.size.BF <- lmBF(P1~bin,data.EEG.trial.EmoLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.EmoLoc.P1.BF[,k] <- exp(1)^EmoLoc.P1.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.EmoLoc.P1.perc.err[,k] <- EmoLoc.P1.size.BF@bayesFactor$error[1]*100
}

# summary
compare.EmoLoc.P1 <- data.frame("model"="contrast",
"nar"=round(compare.EmoLoc.P1.BF[,1],digits=3),"nar.p.err"=round(compare.EmoLoc.P1.perc.err[,1],digits=3),
"med"=round(compare.EmoLoc.P1.BF[,2],digits=3),"med.p.err"=round(compare.EmoLoc.P1.perc.err[,2],digits=3),
"wid"=round(compare.EmoLoc.P1.BF[,3],digits=3),"wid.p.err"=round(compare.EmoLoc.P1.perc.err[,3],digits=3))
kable(compare.EmoLoc.P1)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EmoLoc.P1[1,4]<1,"null",as.character(compare.EmoLoc.P1[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.EmoLoc.P1[1,4]`).   

<center> <h1>*N1*</h1> </center>

```{r emoloc_N1_graph}
# summarize data
summary.data.EEG.trial.EmoLoc <- summarySEwithin(data.EEG.trial.EmoLoc,"N1",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.EmoLoc)

# N1 graph
pirateplot(formula=N1~bin, # dependent~independent variables
           data=data.EEG.trial.EmoLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r emoloc_N1_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.EmoLoc.N1.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.EmoLoc.N1.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of emotion
  EmoLoc.N1.size.BF <- lmBF(N1~bin,data.EEG.trial.EmoLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.EmoLoc.N1.BF[,k] <- exp(1)^EmoLoc.N1.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.EmoLoc.N1.perc.err[,k] <- EmoLoc.N1.size.BF@bayesFactor$error[1]*100
}

# summary
compare.EmoLoc.N1 <- data.frame("model"="contrast",
"nar"=round(compare.EmoLoc.N1.BF[,1],digits=3),"nar.p.err"=round(compare.EmoLoc.N1.perc.err[,1],digits=3),
"med"=round(compare.EmoLoc.N1.BF[,2],digits=3),"med.p.err"=round(compare.EmoLoc.N1.perc.err[,2],digits=3),
"wid"=round(compare.EmoLoc.N1.BF[,3],digits=3),"wid.p.err"=round(compare.EmoLoc.N1.perc.err[,3],digits=3))
kable(compare.EmoLoc.N1)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EmoLoc.N1[1,4]<1,"null",as.character(compare.EmoLoc.N1[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.EmoLoc.N1[1,4]`).   

<center> <h1>*EPN*</h1> </center>

```{r emoloc_EPN_graph}
# summarize data
summary.data.EEG.trial.EmoLoc <- summarySEwithin(data.EEG.trial.EmoLoc,"EPN",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.EmoLoc)

# EPN graph
pirateplot(formula=EPN~bin, # dependent~independent variables
           data=data.EEG.trial.EmoLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r emoloc_EPN_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide, ultrawide)

compare.EmoLoc.EPN.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.EmoLoc.EPN.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of emotion
  EmoLoc.EPN.size.BF <- lmBF(EPN~bin,data.EEG.trial.EmoLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.EmoLoc.EPN.BF[,k] <- exp(1)^EmoLoc.EPN.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.EmoLoc.EPN.perc.err[,k] <- EmoLoc.EPN.size.BF@bayesFactor$error[1]*100
}

# summary
compare.EmoLoc.EPN <- data.frame("model"="contrast",
"nar"=round(compare.EmoLoc.EPN.BF[,1],digits=3),"nar.p.err"=round(compare.EmoLoc.EPN.perc.err[,1],digits=3),
"med"=round(compare.EmoLoc.EPN.BF[,2],digits=3),"med.p.err"=round(compare.EmoLoc.EPN.perc.err[,2],digits=3),
"wid"=round(compare.EmoLoc.EPN.BF[,3],digits=3),"wid.p.err"=round(compare.EmoLoc.EPN.perc.err[,3],digits=3))
kable(compare.EmoLoc.EPN)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EmoLoc.EPN[1,4]<1,"null",as.character(compare.EmoLoc.EPN[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.EmoLoc.EPN[1,4]`).   

<center> <h1>*LPP*</h1> </center>

```{r emoloc_LPP_graph}
# summarize data
summary.data.EEG.trial.EmoLoc <- summarySEwithin(data.EEG.trial.EmoLoc,"LPP",withinvars="bin",idvar="participant")
kable(summary.data.EEG.trial.EmoLoc)

# LPP graph
pirateplot(formula=LPP~bin, # dependent~independent variables
           data=data.EEG.trial.EmoLoc, # data frame
           main="", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(-20,20), # y-axis: limits
           ylab=expression(paste("amplitude (",mu,"V)")), # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r emoloc_LPP_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.EmoLoc.LPP.BF <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all BF10
compare.EmoLoc.LPP.perc.err <- matrix(NA,1,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of emotion
  EmoLoc.LPP.size.BF <- lmBF(LPP~bin,data.EEG.trial.EmoLoc,whichRandom="participant",rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.EmoLoc.LPP.BF[,k] <- exp(1)^EmoLoc.LPP.size.BF@bayesFactor$bf[1]
  # percentage of error
  compare.EmoLoc.LPP.perc.err[,k] <- EmoLoc.LPP.size.BF@bayesFactor$error[1]*100
}

# summary
compare.EmoLoc.LPP <- data.frame("model"="contrast",
"nar"=round(compare.EmoLoc.LPP.BF[,1],digits=3),"nar.p.err"=round(compare.EmoLoc.LPP.perc.err[,1],digits=3),
"med"=round(compare.EmoLoc.LPP.BF[,2],digits=3),"med.p.err"=round(compare.EmoLoc.LPP.perc.err[,2],digits=3),
"wid"=round(compare.EmoLoc.LPP.BF[,3],digits=3),"wid.p.err"=round(compare.EmoLoc.LPP.perc.err[,3],digits=3))
kable(compare.EmoLoc.LPP)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.EmoLoc.LPP[1,4]<1,"null",as.character(compare.EmoLoc.LPP[1,1]))` ought to be preferred ($\sf{BF_{10}}$=`r compare.EmoLoc.LPP[1,4]`).   


