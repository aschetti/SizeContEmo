---
title: "<center> <h1>***SIZECONTEMO - BEHAVIOR***</h1> </center>"
author: '[Antonio Schettino](https://www.researchgate.net/profile/Antonio_Schettino2 "Antonio Schettino")'
date: '`r Sys.Date()`'
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

Analysis of behavioral data.

```{r setup_environment,echo=FALSE,warning=FALSE,message=FALSE}
# setup work environment
# dev.off() # clear plots (if no plots are present, comment it out or it will throw an error)
cat("\014") # clear console
rm(list=ls()) # clear environment
set.seed(9001) # specify seed for RNG and ensure reproducible results (it's over 9000!)

expname <- "SizeContEmo" # experiment name
expphase <- "main" # experiment phase
wd <- paste0("D:/OneDrive - UGent/",expname,"/analysis/behavior/",expphase,"/") # work directory
setwd(wd) # set work directory

# load relevant libraries
library(knitr) # dynamic report generation
library(Rmisc) # for advanced summary functions
library(yarrr) # amazing graphs
library(BayesFactor) # calculate Bayes factors

# setup report output
options(width=120,scipen=999,digits=3) # change output width (for better printing), disable scientific notation (default: scipen=0), constrain output to 4 decimals
opts_chunk$set(warning=FALSE,message=FALSE,fig.width=10,fig.height=6) # for each chunk, display the output but not the R code (echo=FALSE), no package warnings (message=FALSE), no package messages (message=FALSE), width and height of all figures
```

```{r main_data}
data.behav <- read.csv(paste0(expphase,"_behavior.csv"),header=TRUE,check.names=FALSE) # load data (check.names=FALSE eliminates the "X" at the beginning of each timepoint)

data.behav <- within(data.behav,size<-relevel(size,ref="large")) # reference: large size
data.behav <- within(data.behav,cont<-relevel(cont,ref="dark")) # reference: high contrast
```

We will calculate and compare the Bayes Factor of different linear mixed-effects models. The random factors are participants and words, and their variance set as nuisance.   
   
We will compare (against the null model) the following models:   
   
1. main effect of size
2. main effect of contrast
3. main effects of size and contrast
4. interactive effects of size and contrast
   
We will then compare the best competing models to understand which one should be preferred overall.   

<center> <h1>*RT*</h1> </center>

```{r rt_graph}
# summarize data
data.rt <- data.behav[complete.cases(data.behav),]
summary.data.rt <- summarySEwithin(data.rt,"RT",withinvars=c("size","cont"),idvar="ssj",na.rm=TRUE)
kable(summary.data.rt)

# RT graph
pirateplot(formula=RT~cont+size, # dependent~independent variables
           data=data.behav, # data frame
           main="RTs", # main title
           xlim=NULL, # x-axis: limits
           xlab="",  # x-axis: label
           ylim=c(100,1000), # y-axis: limits
           ylab="ms", # y-axis: label
           inf.method="hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
           hdi.iter=5000, # number of iterations for 95% HDI
           cap.beans=TRUE, # max and min values of bean densities are capped at the limits found in the data
           pal="xmen") # color palette [see piratepal(palette="all")]
```  

```{r rt_models}

niter <- 10000 # number of MonteCarlo iterations
scaling.factor <- c(.5,sqrt(2)/2,1) # scaling factors of JZS prior: narrow, medium, wide)

compare.rt.BF <- matrix(NA,4,length(scaling.factor)) # preallocate matrix with all BF10
compare.rt.perc.err <- matrix(NA,4,length(scaling.factor)) # preallocate matrix with all % errors

for(k in 1:length(scaling.factor)) { # loop through scaling factors
  
  ### main effect of size
  rt.size.BF <- lmBF(RT~size,data.rt,whichRandom=c("ssj","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effect of contrast
  rt.cont.BF <- lmBF(RT~cont,data.rt,whichRandom=c("ssj","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### main effects of size and contrast
  rt.sizepluscont.BF <- lmBF(RT~size+cont,data.rt,whichRandom=c("ssj","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
 
  ### full model: main effects of size and contrast + their interaction
  rt.full.BF <- lmBF(RT~size*cont,data.rt,whichRandom=c("ssj","word"),rscaleFixed=scaling.factor[k],rscaleRandom="nuisance",rscaleCont="medium",iterations=niter,posterior=FALSE)
  
  ### model comparison
  # BFs
  compare.rt.BF[,k] <- c(exp(1)^rt.size.BF@bayesFactor$bf[1],exp(1)^rt.cont.BF@bayesFactor$bf[1],exp(1)^rt.sizepluscont.BF@bayesFactor$bf[1],exp(1)^rt.full.BF@bayesFactor$bf[1])
  # percentage of error
  compare.rt.perc.err[,k] <- c(rt.size.BF@bayesFactor$error[1]*100,rt.cont.BF@bayesFactor$error[1]*100,rt.sizepluscont.BF@bayesFactor$error[1]*100,rt.full.BF@bayesFactor$error[1]*100)
  
}

# summary
compare.rt <- data.frame("model"=c("size","contr","size + cont","full"),
"nar"=round(compare.rt.BF[,1],digits=3),"nar.p.err"=round(compare.rt.perc.err[,1],digits=3),
"med"=round(compare.rt.BF[,2],digits=3),"med.p.err"=round(compare.rt.perc.err[,2],digits=3),
"wid"=round(compare.rt.BF[,3],digits=3),"wid.p.err"=round(compare.rt.perc.err[,3],digits=3))
compare.rt <- compare.rt[order(compare.rt$med,decreasing=TRUE),] # sort according to medium scaling factor (in descending order)
kable(compare.rt)
```
   
When using a JZS prior with scaling factor r=`r scaling.factor[2]` placed on standardized effect sizes, the model `r ifelse(compare.rt[1,4]<1,"null",as.character(compare.rt[1,1]))` ought to be preferred.   
The best model (`r ifelse(compare.rt[1,4]>1,as.character(compare.rt[1,1]),"null")`) explains the observed data `r ifelse(compare.rt[1,4]>1,compare.rt[1,4]/compare.rt[2,4],1/compare.rt[1,4])` times better than the second best model (`r ifelse(compare.rt[1,4]>1,as.character(compare.rt[2,1]),as.character(compare.rt[1,1]))`).   


