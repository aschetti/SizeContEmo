---
title: "<center> <h1>***ANALYSIS BEHAVIORAL DATA***</h1> </center>"
author: '[Antonio Schettino](https://osf.io/zbv65/ "Antonio Schettino")'
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: show
    highlight: tango
    theme: united
    toc: yes
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

Analysis of behavioral data.

```{r setup_environment, include = FALSE}

# ## install packages
# install.packages("here")
# install.packages("knitr")
# install.packages("tidyverse")
# install.packages("Rmisc")
# install.packages("yarrr")
# install.packages("BayesFactor")

## load packages
library(here)
library(knitr)
library(tidyverse)
library(Rmisc)
library(yarrr)
library(BayesFactor)

set.seed(3) # 'a gatta

# report output
options(width = 120, # change output width (for better printing)
        scipen = 999, # disable scientific notation (default: scipen = 0)
        digits = 6) # constrain output to 6 decimals

# chunk options
opts_chunk$set(
  warning = FALSE, # no package warnings
  message = FALSE, # no package messages
  fig.dim = c(10, 6) # width and height of all figures
  )

niter <- 100000 # number of MCMC iterations for calculation of Bayes Factors
scaling.factor <- c(.5, .707, 1) # scaling factors of JZS prior: narrow, medium, wide

```

```{r data}

data.behav <- read_csv(here::here("behavior/main/data_behavior.csv")) %>% # load data
  mutate(
    cond = as.factor(paste(size, cont, sep = "_")), # variable with merged conditions
    cont = recode(factor(cont), "dark" = "high", "bright" = "low") # recode contrast levels
  )

```

Calculate and compare the Bayes Factor of different linear mixed-effects models. The random factors are participants and words, and their variance set as nuisance.   
   
Compare (against the null model) the following models:   
   
1. main effect of size
2. main effect of contrast
3. main effects of size and contrast
4. interactive effects of size and contrast
   
Afterwards, compare the best competing models to understand which one should be preferred overall.

# RT

```{r rt_pirateplot}

# average across trials
summary.rt <-
  data.behav %>%
  group_by(ssj, size, cont, cond) %>%
  dplyr::summarize(
    N = n(),
    RT = mean(RT, na.rm = TRUE)
  )

# average across participants
summary.rt.plot <-
  summary.rt %>%
  summarySEwithin(
    data = .,
    measurevar = "RT",
    withinvars = c("size", "cont"),
    idvar = "ssj",
    na.rm = TRUE
  )

#  nicer table
kable(summary.rt.plot, digits = 2)

# pirateplot
pirateplot(
  formula = RT ~ cont + size, # dependent~independent variables
  data = summary.rt, # data frame
  main = "RTs", # main title
  xlim = NULL, # x-axis: limits
  xlab = "", # x-axis: label
  ylim = c(450, 850), # y-axis: limits
  ylab = "ms", # y-axis: label
  inf.method = "hdi", # type of inference: 95% Bayesian Highest Density Interval (HDI)
  hdi.iter = 5000, # number of iterations for 95% HDI
  cap.beans = TRUE, # bean densities capped at data limits
  point.cex = 1.3, # points: size
  pal = "southpark" # color palette [see piratepal(palette="all")]
)

```  

```{r rt_models}

# preallocate matrix with all BFs
compare.rt.BF <- matrix(NA, 4, length(scaling.factor))

# preallocate matrix with all % errors
compare.rt.perc.err <- matrix(NA, 4, length(scaling.factor))

for (k in 1:length(scaling.factor)) { # loop through scaling factors

  ### main effect of size
  rt.BF.size <-
    lmBF(
      RT ~ size + ssj, # formula
      summary.rt, # data (omit missing values)
      whichRandom = "ssj", # random effects
      rscaleFixed = scaling.factor[k], # scaling factor of prior on effect size
      rscaleRandom = "nuisance", # prior scale for standardized random effects
      rscaleCont = "medium", # prior scale for standardized slopes
      method = "simple", # MCMC sampling
      iterations = niter # number of MCMC iterations
    )

  ### main effect of contrast
  rt.BF.cont <-
    lmBF(
      RT ~ cont + ssj,
      summary.rt,
      whichRandom = "ssj",
      rscaleFixed = scaling.factor[k],
      rscaleRandom = "nuisance",
      rscaleCont = "medium",
      method = "simple",
      iterations = niter
    )

  ### main effects of size and contrast
  rt.BF.sizepluscont <-
    lmBF(
      RT ~ size + cont + ssj,
      summary.rt,
      whichRandom = "ssj",
      rscaleFixed = scaling.factor[k],
      rscaleRandom = "nuisance",
      rscaleCont = "medium",
      method = "simple",
      iterations = niter
    )

  ### full model: main effects of size and contrast + their interaction
  rt.BF.full <-
    lmBF(
      RT ~ size * cont + ssj,
      summary.rt,
      whichRandom = "ssj",
      rscaleFixed = scaling.factor[k],
      rscaleRandom = "nuisance",
      rscaleCont = "medium",
      method = "simple",
      iterations = niter
    )

  ### model comparison
  # BFs
  compare.rt.BF[, k] <-
    c(
      rt.BF.size@bayesFactor$bf,
      rt.BF.cont@bayesFactor$bf,
      rt.BF.sizepluscont@bayesFactor$bf,
      rt.BF.full@bayesFactor$bf
    )

  # percentage of error
  compare.rt.perc.err[, k] <-
    c(
      rt.BF.size@bayesFactor$error * 100,
      rt.BF.cont@bayesFactor$error * 100,
      rt.BF.sizepluscont@bayesFactor$error * 100,
      rt.BF.full@bayesFactor$error * 100
    )
}

# summary confirmatory analysis
compare.rt <-
  data.frame(
    "model" = c("size", "contr", "size + contr", "size x cont"),
    "nar" = compare.rt.BF[, 1], "nar.p.err" = compare.rt.perc.err[, 1],
    "med" = compare.rt.BF[, 2], "med.p.err" = compare.rt.perc.err[, 2],
    "wid" = compare.rt.BF[, 3], "wid.p.err" = compare.rt.perc.err[, 3]
  )

# sort according to medium scaling factor (in descending order)
compare.rt <- compare.rt[order(compare.rt$med, decreasing = TRUE), ]

# nicer table
kable(compare.rt)

```
   
When using a JZS prior with scaling factor *r* = `r scaling.factor[2]` placed on standardized effect sizes, the model *`r as.character(compare.rt[1, 1])`* ought to be preferred.   
The best model (*`r as.character(compare.rt[1, 1])`*) explains the observed data `r format(exp(compare.rt[1, 4] - compare.rt[2, 4]), scientific = TRUE)` times better than the second best model (*`r as.character(compare.rt[2, 1])`*).   

## Paired comparisons

```{r rt_posthoc}

data.rt <-
  summary.rt %>%
  split(.$cond) # split according to condition

compare.rt.posthocBF <- matrix(NA, 4, length(scaling.factor))
compare.rt.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor))

for (k in 1:length(scaling.factor)) {

  # large, dark vs. bright
  rt.posthocBF.large.darkVSbright <-
    ttestBF(
      data.rt$large_dark$RT, # first condition
      data.rt$large_bright$RT, # second condition
      mu = 0, # null hypothesis (mean difference = 0)
      paired = TRUE, # paired sample test
      method = "simple",
      iterations = niter, # number of MCMC iterations
      rscale = scaling.factor[k] # scaling factor
    )

  # small, dark vs. bright
  rt.posthocBF.small.darkVSbright <-
    ttestBF(
      data.rt$small_dark$RT,
      data.rt$small_bright$RT,
      mu = 0,
      paired = TRUE,
      method = "simple",
      iterations = niter,
      rscale = scaling.factor[k]
    )

  # dark, large vs. small
  rt.posthocBF.dark.largeVSsmall <-
    ttestBF(
      data.rt$large_dark$RT,
      data.rt$small_dark$RT,
      mu = 0,
      paired = TRUE,
      method = "simple",
      iterations = niter,
      rscale = scaling.factor[k]
    )

  # bright, large vs. small
  rt.posthocBF.bright.largeVSsmall <-
    ttestBF(
      data.rt$large_bright$RT,
      data.rt$small_bright$RT,
      mu = 0,
      paired = TRUE,
      method = "simple",
      iterations = niter,
      rscale = scaling.factor[k]
    )

  ### model comparison
  compare.rt.posthocBF[, k] <-
    c(
      rt.posthocBF.large.darkVSbright@bayesFactor$bf,
      rt.posthocBF.small.darkVSbright@bayesFactor$bf,
      rt.posthocBF.dark.largeVSsmall@bayesFactor$bf,
      rt.posthocBF.bright.largeVSsmall@bayesFactor$bf
    )

  compare.rt.posthocBF.perc.err[, k] <-
    c(
      rt.posthocBF.large.darkVSbright@bayesFactor$error * 100,
      rt.posthocBF.small.darkVSbright@bayesFactor$error * 100,
      rt.posthocBF.dark.largeVSsmall@bayesFactor$error * 100,
      rt.posthocBF.bright.largeVSsmall@bayesFactor$error * 100
    )
}

compare.rt.posthocBF <-
  data.frame(
    "comparison" = c(
      "large.highVSlow", "small.highVSlow",
      "high.largeVSsmall", "low.largeVSsmall"
    ),
    "nar" = compare.rt.posthocBF[, 1],
    "nar.p.err" = compare.rt.posthocBF.perc.err[, 1],
    "med" = compare.rt.posthocBF[, 2],
    "med.p.err" = compare.rt.posthocBF.perc.err[, 2],
    "wid" = compare.rt.posthocBF[, 3],
    "wid.p.err" = compare.rt.posthocBF.perc.err[, 3]
  )

compare.rt.posthocBF <- compare.rt.posthocBF[order(compare.rt.posthocBF$med, decreasing = TRUE), ]

kable(compare.rt.posthocBF)

```

When using a JZS prior with scaling factor *r* = `r scaling.factor[2]` placed on standardized effect sizes, we observe longer RTs for:

* words in *small* font presented in *low vs. high* contrast ($\sf{BF_{10}}$ = `r format(exp(compare.rt.posthocBF[1, 4]), scientific = TRUE)` $\pm$`r compare.rt.posthocBF[1, 5]`);
* words in *low* contrast presented in *small vs. large* font ($\sf{BF_{10}}$ = `r format(exp(compare.rt.posthocBF[2, 4]), scientific = TRUE)` $\pm$`r compare.rt.posthocBF[2, 5]`);
* words in *large* font presented in *low vs. high* contrast ($\sf{BF_{10}}$ = `r exp(compare.rt.posthocBF[3, 4])` $\pm$`r compare.rt.posthocBF[3, 5]`).

The difference between words in *high* contrast presented in *large vs. small* font is non-conclusive ($\sf{BF_{10}}$ = `r exp(compare.rt.posthocBF[4, 4])` $\pm$ `r compare.rt.posthocBF[4, 5]`).

***
***

# ACCURACY

```{r acc_pirateplot}

# calculate proportion of correct responses per participant and condition
data.acc <-
  data.behav %>%
  group_by(ssj, size, cont, cond) %>%
  dplyr::summarize(
    N = n(),
    freqs = length(which(resp == "hit")) / length(resp)
  )

# average across participants
summary.acc <-
  data.acc %>%
  summarySEwithin(
    data = .,
    measurevar = "freqs",
    withinvars = c("size", "cont"),
    idvar = "ssj", na.rm = TRUE
  )

# nicer table
kable(summary.acc, digits = 2)

# pirateplot
pirateplot(
  formula = freqs ~ cont + size,
  data = data.acc,
  main = "accuracy",
  xlim = NULL,
  xlab = "",
  ylim = c(.8, 1),
  ylab = "proportion of correct responses",
  inf.method = "hdi",
  hdi.iter = 5000,
  cap.beans = TRUE,
  pal = "southpark"
)

```

```{r acc_models}

compare.acc.BF <- matrix(NA, 4, length(scaling.factor))
compare.acc.perc.err <- matrix(NA, 4, length(scaling.factor))

for (k in 1:length(scaling.factor)) {

  ### main effect of size
  acc.BF.size <-
    lmBF(
      freqs ~ size + ssj,
      data.acc,
      whichRandom = "ssj",
      rscaleFixed = scaling.factor[k],
      rscaleRandom = "nuisance",
      rscaleCont = "medium",
      method = "simple",
      iterations = niter
    )

  ### main effect of contrast
  acc.BF.cont <-
    lmBF(
      freqs ~ cont + ssj,
      data.acc,
      whichRandom = "ssj",
      rscaleFixed = scaling.factor[k],
      rscaleRandom = "nuisance",
      rscaleCont = "medium",
      method = "simple",
      iterations = niter
    )

  ### main effects of size and contrast
  acc.BF.sizepluscont <-
    lmBF(
      freqs ~ size + cont + ssj,
      data.acc,
      whichRandom = "ssj",
      rscaleFixed = scaling.factor[k],
      rscaleRandom = "nuisance",
      rscaleCont = "medium",
      method = "simple",
      iterations = niter
    )

  ### full model: main effects of size and contrast + their interaction
  acc.BF.full <-
    lmBF(
      freqs ~ size * cont + ssj,
      data.acc,
      whichRandom = "ssj",
      rscaleFixed = scaling.factor[k],
      rscaleRandom = "nuisance",
      rscaleCont = "medium",
      method = "simple",
      iterations = niter
    )

  ### model comparison
  compare.acc.BF[, k] <-
    c(
      acc.BF.size@bayesFactor$bf,
      acc.BF.cont@bayesFactor$bf,
      acc.BF.sizepluscont@bayesFactor$bf,
      acc.BF.full@bayesFactor$bf
    )

  compare.acc.perc.err[, k] <-
    c(
      acc.BF.size@bayesFactor$error * 100,
      acc.BF.cont@bayesFactor$error * 100,
      acc.BF.sizepluscont@bayesFactor$error * 100,
      acc.BF.full@bayesFactor$error * 100
    )
}

compare.acc <-
  data.frame(
    "model" = c("size", "contr", "size + contr", "size x cont"),
    "nar" = compare.acc.BF[, 1], "nar.p.err" = compare.acc.perc.err[, 1],
    "med" = compare.acc.BF[, 2], "med.p.err" = compare.acc.perc.err[, 2],
    "wid" = compare.acc.BF[, 3], "wid.p.err" = compare.acc.perc.err[, 3]
  )

compare.acc <- compare.acc[order(compare.acc$med, decreasing = TRUE), ]

kable(compare.acc)

```
   
When using a JZS prior with scaling factor *r* = `r scaling.factor[2]` placed on standardized effect sizes, the model *`r as.character(compare.acc[1, 1])`* ought to be preferred.   
The best model (*`r as.character(compare.acc[1, 1])`*) explains the observed data `r format(exp(compare.acc[1, 4] - compare.acc[2, 4]), scientific = TRUE)` times better than the second best model (*`r as.character(compare.acc[2, 1])`*).

## Paired comparisons

```{r acc_posthoc}

data.acc <-
  data.acc %>%
  split(.$cond)

compare.acc.posthocBF <- matrix(NA, 4, length(scaling.factor))
compare.acc.posthocBF.perc.err <- matrix(NA, 4, length(scaling.factor))

for (k in 1:length(scaling.factor)) {

  # large, dark vs. bright
  acc.posthocBF.large.darkVSbright <-
    ttestBF(
      data.acc$large_dark$freqs,
      data.acc$large_bright$freqs,
      mu = 0,
      paired = TRUE,
      method = "simple",
      iterations = niter,
      rscale = scaling.factor[k]
    )

  # small, dark vs. bright
  acc.posthocBF.small.darkVSbright <-
    ttestBF(
      data.acc$small_dark$freqs,
      data.acc$small_bright$freqs,
      mu = 0,
      paired = TRUE,
      method = "simple",
      iterations = niter,
      rscale = scaling.factor[k]
    )

  # dark, large vs. small
  acc.posthocBF.dark.largeVSsmall <-
    ttestBF(
      data.acc$large_dark$freqs,
      data.acc$small_dark$freqs,
      mu = 0,
      paired = TRUE,
      method = "simple",
      iterations = niter,
      rscale = scaling.factor[k]
    )

  # bright, large vs. small
  acc.posthocBF.bright.largeVSsmall <-
    ttestBF(
      data.acc$large_bright$freqs,
      data.acc$small_bright$freqs,
      mu = 0,
      paired = TRUE,
      method = "simple",
      iterations = niter,
      rscale = scaling.factor[k]
    )

  ### model comparison
  compare.acc.posthocBF[, k] <-
    c(
      acc.posthocBF.large.darkVSbright@bayesFactor$bf,
      acc.posthocBF.small.darkVSbright@bayesFactor$bf,
      acc.posthocBF.dark.largeVSsmall@bayesFactor$bf,
      acc.posthocBF.bright.largeVSsmall@bayesFactor$bf
    )

  compare.acc.posthocBF.perc.err[, k] <-
    c(
      acc.posthocBF.large.darkVSbright@bayesFactor$error * 100,
      acc.posthocBF.small.darkVSbright@bayesFactor$error * 100,
      acc.posthocBF.dark.largeVSsmall@bayesFactor$error * 100,
      acc.posthocBF.bright.largeVSsmall@bayesFactor$error * 100
    )
}

compare.acc.posthocBF <-
  data.frame(
    "comparison" = c(
      "large.highVSlow", "small.highVSlow",
      "high.largeVSsmall", "low.largeVSsmall"
    ),
    "nar" = compare.acc.posthocBF[, 1],
    "nar.p.err" = compare.acc.posthocBF.perc.err[, 1],
    "med" = compare.acc.posthocBF[, 2],
    "med.p.err" = compare.acc.posthocBF.perc.err[, 2],
    "wid" = compare.acc.posthocBF[, 3],
    "wid.p.err" = compare.acc.posthocBF.perc.err[, 3]
  )

compare.acc.posthocBF <- compare.acc.posthocBF[order(compare.acc.posthocBF$med, decreasing = TRUE), ]

kable(compare.acc.posthocBF)

```

When using a JZS prior with scaling factor *r* = `r scaling.factor[2]` placed on standardized effect sizes, we observe lower accuracy for:

* words in *small* font presented in *low vs. high* contrast ($\sf{BF_{10}}$ = `r format(exp(compare.acc.posthocBF[1, 4]), scientific = TRUE)` $\pm$`r compare.acc.posthocBF[1, 5]`);
* words in *low* contrast presented in *small vs. large* font ($\sf{BF_{10}}$ = `r format(exp(compare.acc.posthocBF[2, 4]), scientific = TRUE)` $\pm$`r compare.acc.posthocBF[2, 5]`).

No reliable accuracy difference is observed between words in *large* font presented in *low vs. high* contrast ($\sf{BF_{10}}$ = `r exp(compare.acc.posthocBF[3, 4])` $\pm$`r compare.acc.posthocBF[3, 5]`) as well as words in *low* contrast presented in *large vs. small* font ($\sf{BF_{10}}$ = `r exp(compare.acc.posthocBF[4, 4])` $\pm$`r compare.acc.posthocBF[4, 5]`).

***
***
